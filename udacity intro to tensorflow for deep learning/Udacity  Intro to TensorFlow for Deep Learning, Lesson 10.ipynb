{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Udacity  Intro to TensorFlow for Deep Learning, Lesson 10.ipynb ","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyNjSym2x1MM/xdt3+TyjzSD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# **Udacity: Intro to TensorFlow for Deep Learning**\n","## **Lesson 10 NLP: Recurrent Neural Networks**\n","\n","This lessons extends on what was covered in lesson 9. It introduces recurrent neural networks, which are able to capture temporal dependences,that change over time.\n","\n","This lesson would covers\n","- Different RNNs: Simple RNN, LSTMS, GRUs\n","- Text generation using NLP models.\n"],"metadata":{"id":"CakMRRpBlwnH"}},{"cell_type":"markdown","source":["##**Simple RNNS**\n","\n","Simple recurrent neural networks, are networks which use outputs from previous time steps as additional inputs, alongside the current input.\n","\n","for example   \n","- Inputs: $X_t + Y_{t-1}$\n","- Ouput: $Y_t$\n","\n","I'm a bit effy around th calculation of the output.\n","\n","But...\n","\n","The general idea is that, previous output from the last time step are fed as additional inputs. The previous output is referred to as the state vector.\n","\n","<br>\n","\n","While simple RNN architecture are able to consider the past output when calculating it's new output, it is limited by how far back it can relate dependencies and for dependencies which occur over long period of time, a simple RNN would struggle to capture these dependencies."],"metadata":{"id":"aRKgF0f9m6_Z"}},{"cell_type":"markdown","source":["## **Long term short term Memory**\n","\n","LSTMs, were introduced to capture temporal dependencies which spam over longer periods of time. Unlike simple RNNS which have a single state vector, LSTMS have 2 state vectors, a Long term memory and a short term memory.\n","\n","<br>\n","\n","**Features of an LSTM**\n","- It's able to capture temporal dependencies spaming a long period of time\n","- It has 2 state vectors, long term and short term memory, which are used in calculating a new input\n","- LSTM feature gates: Forget, learn, remember and use gates.\n","\n","<br>\n","\n","**Workflow for an LSTM**\n","- At each time step, the LSTM has 2 state vectors: A long term memory and a short term memory\n","- The current time step input alongside the 2 state vectors are used to determine an output.\n","- The calculated output from the current time step, would be used as the short term memory for the next timestep\n","- The long term memory from the previous time step is updated:\n","  - Any pieces of the previous long term memory which is no longer relevant is removed, using the forget gate\n","  - Any new piece of relevant information is added to the long term memory, using the remember gate\n","\n","<br>\n","\n","**LSTM Gates**\n","- Forget gate: Determines which parts of the long term memory are no longer relevant and should be removed from memory.\n","- Learn gate: Learns new piece of informations using the current input and short term memory.\n","\n","- Remember gate: Adds any relevant information that was learnt to the long term memory. The output of this gate is the new long term memory\n","\n","- Use gate: This uses, the relevants parts of the long term memory and newly learnt information to calculate an output. The output is also used as the new short term memory for the next timestep.\n","\n"],"metadata":{"id":"sfn-5JjQrdEQ"}},{"cell_type":"markdown","source":["##**Import Dependencies**"],"metadata":{"id":"r8YH_1oFx0lD"}},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","\n","print(tf.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O-IeCkjWrcIl","executionInfo":{"status":"ok","timestamp":1658254235529,"user_tz":-60,"elapsed":2186,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"d4cde762-ed33-47e0-ef91-ccbbf202818e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["2.8.2\n"]}]},{"cell_type":"markdown","source":["## **RNNs and LSTMs in code**\n","\n","The LSTM layer is within `tf.keras.Layers.LSTM` [docs](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM). likewise with the RNN layer `tf.keras.Layers.SimpleRNN`.\n","\n","<br>\n","\n","Worth noting:\n","- We can directly pass, the output of an embedding layer to an LSTM layer without adding a flatten or GlobalAverage1D layer inbetween.\n","\n","<br>\n","\n","**Further resources:**   \n","The [recurrent neural network (RNN) with keras guide](https://www.tensorflow.org/guide/keras/rnn) is a really good supplementary introduction to RNNs.\n","\n","Notes from the guide\n","- 3 built-in RNN layers: SimpleRNN, GRU, LSTM\n","- RNN can process input sequences in reverse.\n","- Feature recurrent dropout\n","- By default returns output at the last time step, but it can be configured to return a sequence instead for each time step.\n","- The layer can also be configured to return the final internal state vectors.\n","- Likewise we can also set the initial state of the RNN layer.\n","\n","<br>\n","\n","**Difference between layer and cell layer**\n","- \"*the RNN cell process only a single timestep*\""],"metadata":{"id":"LiptnBXSyAlA"}},{"cell_type":"markdown","source":["### **Preparing text for SimpleRNN and LSTM layer**\n","\n","Simplified look at using the SimpleRNN and LSTM layers. Both these layers would take inputs from the Embedding layer, which would return a vector in n dimensions for each token in the sequence.\n","\n","To take a look at the input and given output, lets try it out on a simple dataset."],"metadata":{"id":"SD3FndIDgGNL"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"CmqDPNFLuELj","executionInfo":{"status":"ok","timestamp":1658254240967,"user_tz":-60,"elapsed":12,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}}},"outputs":[],"source":["# sample text\n","# The great pretender - The Platters\n","lyrics = [\"Oh-oh, yes, I'm the great pretender\",\n","          \"Pretending that I'm doing well\",\n","          \"My need is such I pretend too much\",\n","          \"I'm lonely, but no one can tell\",\n","          \"Oh-oh, yes, I'm the great pretender\",\n","          \"Adrift in a world of my own\",\n","          \"I've played the game but to my real shame\",\n","          \"You've left me to grieve all alone\",\n","          \"Too real is this feeling of make-believe\",\n","          \"Too real when I feel what my heart can't conceal\",\n","          \"Yes, I'm the great pretender\",\n","          \"Just laughin' and gay like a clown\",\n","          \"I seem to be what I'm not, you see\",\n","          \"I'm wearing my heart like a crown\",\n","          \"Pretending that you're still around\"\n","          \"Too real is this feeling of make-believe\",\n","          \"Too real when I feel what my heart can't conceal\",\n","          \"Yes, I'm the great pretender\",\n","          \"Just laughin' and gay like a clown\",\n","          \"I seem to be what I'm not, you see\",\n","          \"I'm wearing my heart like a crown\",\n","          \"Pretending that you're still around (still around)\"]\n"]},{"cell_type":"code","source":["# tokenize and pad the text\n","\n","# deprecated in version 2.9.1\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","\n","# define a tokenizer and fit it to the text\n","The_great_pretender = Tokenizer(num_words=150, oov_token=\"<OOV>\")\n","The_great_pretender.fit_on_texts(lyrics)\n"],"metadata":{"id":"Yies0OUAgRF2","executionInfo":{"status":"ok","timestamp":1658254250107,"user_tz":-60,"elapsed":12,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# display the word index\n","word_index = The_great_pretender.word_index\n","print(word_index)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RlnOAgUBjYG_","executionInfo":{"status":"ok","timestamp":1658254251755,"user_tz":-60,"elapsed":13,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"4ce5bb2a-b5d3-4274-a330-6b811d7a9aa3"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["{'<OOV>': 1, \"i'm\": 2, 'my': 3, 'the': 4, 'i': 5, 'a': 6, 'real': 7, 'oh': 8, 'yes': 9, 'great': 10, 'pretender': 11, 'too': 12, 'to': 13, 'what': 14, 'heart': 15, 'like': 16, 'pretending': 17, 'that': 18, 'is': 19, 'of': 20, 'still': 21, 'but': 22, 'this': 23, 'feeling': 24, 'make': 25, 'believe': 26, 'when': 27, 'feel': 28, \"can't\": 29, 'conceal': 30, 'just': 31, \"laughin'\": 32, 'and': 33, 'gay': 34, 'clown': 35, 'seem': 36, 'be': 37, 'not': 38, 'you': 39, 'see': 40, 'wearing': 41, 'crown': 42, \"you're\": 43, 'around': 44, 'doing': 45, 'well': 46, 'need': 47, 'such': 48, 'pretend': 49, 'much': 50, 'lonely': 51, 'no': 52, 'one': 53, 'can': 54, 'tell': 55, 'adrift': 56, 'in': 57, 'world': 58, 'own': 59, \"i've\": 60, 'played': 61, 'game': 62, 'shame': 63, \"you've\": 64, 'left': 65, 'me': 66, 'grieve': 67, 'all': 68, 'alone': 69, 'aroundtoo': 70}\n"]}]},{"cell_type":"code","source":["# convert the lyrics to sequences\n","lyrics_sequence = The_great_pretender.texts_to_sequences(lyrics)\n","\n","length_of_sequence = []\n","for sequence in lyrics_sequence:\n","  print(sequence)\n","  break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i78foHRgjV5b","executionInfo":{"status":"ok","timestamp":1658254253655,"user_tz":-60,"elapsed":14,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"e4cbbc67-6700-473a-c4fe-03dce839fcf5"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["[8, 8, 9, 2, 4, 10, 11]\n"]}]},{"cell_type":"code","source":["# display the average length of each sequence\n","length_of_sequence = []\n","for sequence in lyrics_sequence:\n","  length_of_sequence.append(len(sequence))\n","\n","\n","#src: https://www.geeksforgeeks.org/find-average-list-python/\n","def Average(lst):\n","    return sum(lst) / len(lst)\n","  \n","\n","print(Average(length_of_sequence))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gxz1XF3DkcMt","executionInfo":{"status":"ok","timestamp":1658254255299,"user_tz":-60,"elapsed":579,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"64f87f7b-9541-4743-818e-0d127067d935"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["7.619047619047619\n"]}]},{"cell_type":"code","source":["# Apply padding to the sequences\n","lyrics_sequence_padded = pad_sequences(lyrics_sequence, maxlen=7, padding='pre',\n","                                      truncating='post')\n"],"metadata":{"id":"jjrkhRa-j2-4","executionInfo":{"status":"ok","timestamp":1658254256009,"user_tz":-60,"elapsed":3,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# define an embedding layer\n","Embedding = tf.keras.layers.Embedding(input_dim=150, output_dim=4, input_length=7)"],"metadata":{"id":"oy5CyKbMgTpF","executionInfo":{"status":"ok","timestamp":1658254258281,"user_tz":-60,"elapsed":6,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# pass in a sequence from the lyric_sequence_padded to the embedding layer\n","output = Embedding(np.array(sequence))\n","print(output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jLSH6BrRltrB","executionInfo":{"status":"ok","timestamp":1658254262897,"user_tz":-60,"elapsed":3597,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"bfbe7688-2827-4e40-d5a2-f7ba7534c353"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[[-0.03605381 -0.04465077 -0.03381597 -0.03534323]\n"," [ 0.01556465 -0.03940675  0.01276333  0.00853235]\n"," [ 0.00911007 -0.04884337  0.01232371 -0.02719672]\n"," [-0.0399784  -0.02804041  0.02798759 -0.04888147]\n"," [-0.02194605 -0.00159215  0.04856716 -0.01162859]\n"," [-0.0399784  -0.02804041  0.02798759 -0.04888147]\n"," [-0.02194605 -0.00159215  0.04856716 -0.01162859]], shape=(7, 4), dtype=float32)\n"]}]},{"cell_type":"markdown","source":["we now have a vector of 4 dimensions representing of each tokens in the sequence.\n","\n","A thought on the embedding layer\n","- i don't think the embedding layer is trainable, provided it's function is to simply convert the tokens into a vector representation, i can't really see how any optimization is needed.\n","\n","Unless the scale or way in which the conversion is done needs to be different to get better results, i'm not sure."],"metadata":{"id":"bnlNt3ZwmJaz"}},{"cell_type":"markdown","source":["Looking into the above text, *i don't think the embedding layer is trainable*\n","\n","<br>\n","\n","**Is the embedding layer trainable?**\n","\n","The short answer is that, the embedding layer is trainable, it is not enough to just map each token to vector.\n","<br>\n","\n","- At it's core, the embedding layer maps positive integers (tokens) into dense vectors of fixed size (word embeddings).\n","- ideally we would like words with similar semantic context or sentiment, to have similar vector representations, so words like man and woman should have fairly similar vectors. Likewise words like apple, orange, banana, pears should be within the same general cluster, in our n dimensional space for our word embedding.\n","- We would not be able to achieve this by randomly mapping our tokens into vectors. Hence our vector representation would need to be optimzied to group similar words to be within the same latent space in our word embedding.\n","\n","<br>\n","\n","**Resources**\n","- https://stats.stackexchange.com/questions/324992/how-the-embedding-layer-is-trained-in-keras-embedding-layer\n","- https://www.youtube.com/watch?v=5MaWmXwxFNQ\n","\n","<br>\n","\n","**More questions**\n","- What is word2Vec, skip-gram?"],"metadata":{"id":"zJvOvFqg-sFf"}},{"cell_type":"markdown","source":["### **Understanding the keras LSTM layer**"],"metadata":{"id":"450-KEHjCD7V"}},{"cell_type":"code","source":["# pass the output of the embedding layer to the LSTM layer\n","LSTM = tf.keras.layers.LSTM(units=4)\n","\n","embedding_output = Embedding(np.array([sequence]))\n","LSTM_output = LSTM(embedding_output)\n","\n","print(\"Input: {}\".format(np.array([sequence])))\n","print(\"\\nEmbedding layer output: \")\n","print(embedding_output)\n","print(\"\\nLSTM layer output: \")\n","print(LSTM_output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zTjFQHX8mx49","executionInfo":{"status":"ok","timestamp":1658254266384,"user_tz":-60,"elapsed":2842,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"2a67a8b1-6085-4156-e98a-7726f99e2eb2"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: [[17 18 43 21 44 21 44]]\n","\n","Embedding layer output: \n","tf.Tensor(\n","[[[-0.03605381 -0.04465077 -0.03381597 -0.03534323]\n","  [ 0.01556465 -0.03940675  0.01276333  0.00853235]\n","  [ 0.00911007 -0.04884337  0.01232371 -0.02719672]\n","  [-0.0399784  -0.02804041  0.02798759 -0.04888147]\n","  [-0.02194605 -0.00159215  0.04856716 -0.01162859]\n","  [-0.0399784  -0.02804041  0.02798759 -0.04888147]\n","  [-0.02194605 -0.00159215  0.04856716 -0.01162859]]], shape=(1, 7, 4), dtype=float32)\n","\n","LSTM layer output: \n","tf.Tensor([[-0.00894124  0.02133395  0.00866948  0.00472196]], shape=(1, 4), dtype=float32)\n"]}]},{"cell_type":"markdown","source":["So what has happened??\n","- it looks like the number of units correspond to the shape of the output, so if there is 1 unit it would produce a shape of (1, 1) and if there are 4 units it would produce a shape of (1, 4).\n","- recap output of embedding layer is vector of n dimension representation of a sequence.\n","\n","<br/>\n","\n","Still doesn't answer what exactly its doing??\n","- What does the output of the LSTM layer mean??\n","\n","<br/>\n","\n","what happens if we ask it to \n","- return sequences\n","- return state\n","- go backwards"],"metadata":{"id":"V7k0DNwBpokm"}},{"cell_type":"markdown","source":["**Set return_sequences to True**"],"metadata":{"id":"bzNqvbsXU3uR"}},{"cell_type":"code","source":["# lstm layer with return sequence = True\n","LSTM_return_sequence = tf.keras.layers.LSTM(units=4, return_sequences=True)\n","LSTM_return_sequence_output = LSTM_return_sequence(embedding_output)\n","\n","print(\"Input: {}\".format(np.array([sequence])))\n","print(\"\\nLSTM layer output: \")\n","print(LSTM_return_sequence_output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VnoRVg_Dpizp","executionInfo":{"status":"ok","timestamp":1658254266387,"user_tz":-60,"elapsed":52,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"2082ba40-b277-4e94-b55d-b2ecd7442bc2"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: [[17 18 43 21 44 21 44]]\n","\n","LSTM layer output: \n","tf.Tensor(\n","[[[-0.00890752  0.00129125 -0.00724328 -0.00319293]\n","  [-0.00538249  0.00093071 -0.00432462 -0.00776296]\n","  [-0.00702416 -0.00165671 -0.00709613 -0.01226564]\n","  [-0.00721529 -0.00339077 -0.01583953 -0.01056521]\n","  [ 0.00088901 -0.00384751 -0.01626903 -0.00681015]\n","  [-0.00045053 -0.00519655 -0.02308342 -0.00636325]\n","  [ 0.0067431  -0.005319   -0.02191803 -0.00356569]]], shape=(1, 7, 4), dtype=float32)\n"]}]},{"cell_type":"markdown","source":["with return sequence set to True as it iterates through the sequence, it would return a value for each timestep, as there are 7 tokens in a sequence, it returns 7 values and since we have 4 units in our LSTM for each time step it returned 4 value.\n","\n","still don't fully understand what the output mean"],"metadata":{"id":"erL0O6lqs-_D"}},{"cell_type":"markdown","source":["**Understanding the output of an LSTM layer**\n","\n","Notes from machine learning mastery.\n","- The LSTM is a class of recurrent neural networks which contains internal gates (Learn, forget, remember and use gates).\n","- This class of recurrent neural networks are designed to resolve the vanishing gradient problem, as it is able to capture longer temporal dependencies.\n","- An LSTM layer can be defined with n number of LSTMs cell. each cell contains,\n","  - an internal cell state, *c*\n","  - outputs a hidden state *h*\n","\n","So the output of an LSTM is the hidden state *h*.\n","\n","<br>\n","\n","By setting \n","- **return_sequence to True**, we are able to access the hidden state at each time step, in our sequence.\n","- **return_state to True**, this would return the final internal cell states of each cell in the LSTM layer. So it would return *c* and *h*.\n","\n","We would typically set the `return_state to True`, when we want to initialize the states of another LSTM layer with the same number of cells.\n","\n","<br>\n","\n","Cool...\n","\n","But this has still not answered the question of what the internal cell state and hidden cell states are.\n","\n","\n","\n","\n","<br>\n","\n","**Resources**\n","- https://stackoverflow.com/questions/67970519/what-does-tensorflow-lstm-return\n","\n","- https://machinelearningmastery.com/return-sequences-and-return-states-for-lstms-in-keras/\n"," "],"metadata":{"id":"rRTL0ZN-zl3B"}},{"cell_type":"code","source":["# Example used in stackoverflow question\n","# Set return_sequence and return_states to True\n","\n","# input shape: Batch size, length of sequence, embedding dimension\n","tensor = tf.random.normal(shape=[2, 2, 2])\n","lstm = tf.keras.layers.LSTM(units=4, return_sequences=True, return_state=True)\n","hidden_state_at_each_time_step, final_hidden_state, final_cell_state = lstm(tensor)\n","\n","print(\"Input: {}\".format(tensor))\n","print(\"\\nHidden_state_at_each_time_step:\\n\", hidden_state_at_each_time_step)\n","print(\"\\nFinal hidden state: \\n\", final_hidden_state)\n","print(\"\\nFinal cell state: \\n\", final_cell_state)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JypRlC2L0Bnp","executionInfo":{"status":"ok","timestamp":1658254266388,"user_tz":-60,"elapsed":47,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"3677a13a-32e9-4b41-da80-e5698798ceb8"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: [[[-1.4442931  -0.10136034]\n","  [ 1.1435893   0.13428247]]\n","\n"," [[-0.10974066  0.32672334]\n","  [-0.62598217  0.93750346]]]\n","\n","Hidden_state_at_each_time_step:\n"," tf.Tensor(\n","[[[ 0.21792501  0.14318192 -0.15826057  0.0583761 ]\n","  [ 0.01737139 -0.01054842  0.04750073 -0.04627062]]\n","\n"," [[ 0.04343653 -0.02368674  0.00332432  0.01399184]\n","  [ 0.20665176 -0.06394225 -0.01999095  0.07628803]]], shape=(2, 2, 4), dtype=float32)\n","\n","Final hidden state: \n"," tf.Tensor(\n","[[ 0.01737139 -0.01054842  0.04750073 -0.04627062]\n"," [ 0.20665176 -0.06394225 -0.01999095  0.07628803]], shape=(2, 4), dtype=float32)\n","\n","Final cell state: \n"," tf.Tensor(\n","[[ 0.04193182 -0.02323447  0.10621233 -0.08096145]\n"," [ 0.41175985 -0.1119123  -0.05270814  0.1616236 ]], shape=(2, 4), dtype=float32)\n"]}]},{"cell_type":"markdown","source":["**WTF...**\n","\n","**Breakdown of the output**\n","\n","\n","For an input of shape `[2, 2, 2]`, we have 2 batches of 2 sentences.\n","``` python\n","[[[-0.4942633   1.0938902 ], [-0.27461976 -0.2292373 ]]\n"," [[-0.34839615 -0.39708054], [ 0.21653225  2.0741708 ]]]\n","```\n","Where `[-0.4942633   1.0938902 ]` for example is our word embedding for a single token.\n","\n","So an example input for the above word embedding is\n","``` python\n","example sequence of tokens = [[10, 11], [12, 13]]\n","\n","# 10 -> [-0.4942633   1.0938902 ]\n","# 11 -> [-0.27461976 -0.2292373 ]\n","# 12 -> [-0.34839615 -0.39708054]\n","# 13 -> [ 0.21653225  2.0741708 ]\n","\n","# decoded even futher as another example \n","[\"hello, you\"], [\"Good food\"]\n","\n","# hell0 -> 10\n","# you -> 11\n","# Good -> 12\n","# food -> 13\n","```\n","\n","With return sequence and state set to True. We have\n","- The hidden state $h_{t}$ returned at each time step.\n","- The final hidden cell state $h$ returned\n","- The final cell state $c$ returned.\n","\n","\n","Looking carefully at the output, you should see that the final hidden cell state is just the last hidden cell state for each sentence."],"metadata":{"id":"465fKcRMo5bp"}},{"cell_type":"markdown","source":["**A quick note on the dimensions.**\n","\n","For  a given input dimension [X, Y, Z]. X would be the batch dimension and determines the number of initial element in the array. So if\n","- X = 2 we would have an array containing 2 elements. $[1, 2]$\n","- X = 5, we would have 5 elements in the array. $[1, 2, 3, 4, 5]$\n","\n","The next dimension Y would determine the number of element within the initial set of elements. so if our dimensions are\n","- [1, 2, Z], we would have an array structured like this $[ [[], []] ]$\n","Admittedly it looks confusing, but the array would contain a single element, which in turn contains 2 elements.\n","\n","stacking that further, the 3rd dimension determines the number of elements within the last set. For example an array with a dimension of\n","\n","- [1, 2, 3] could like this, [[[1, 2, 3], [4, 5, 6]]]\n","- [3, 4, 6] could look like this \n","\n","```\n","[[[1, 2, 3, 4, 5, 6], [7, 8, 9, 10, 11, 12], [13, 14, 15, 16, 17, 18], [19, 20, 21, 22, 23, 24]],\n","[[11, 12, 13, 14, 15, 16], [17, 18, 19, 20, 21, 22], [23, 24, 25, 26, 27, 28], [29, 30, 31, 32, 33, 24]],\n","[[21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32], [33, 34, 35, 36, 37, 38], [39, 40, 41, 42, 43, 44]]]\n","```\n","\n"],"metadata":{"id":"CgITAORytyNU"}},{"cell_type":"code","source":["# lets try passing in the example sequence above to an LSTM layer and view what the output is\n","\n","# single batch with sequence length of 4 and 6 embedding dimensions.\n","test_sequence = np.array([[[1, 2, 3, 4, 5, 6], [7, 8, 9, 10, 11, 12], [13, 14, 15, 16, 17, 18], [19, 20, 21, 22, 23, 24]]], dtype=np.float32)\n","LSTM_test_2 = tf.keras.layers.LSTM(2)\n","\n","test_sequence_output = LSTM_test_2(test_sequence)\n","\n","print(\"Results: {}\".format(test_sequence_output))\n"],"metadata":{"id":"ypDvm68T0QsF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658254266390,"user_tz":-60,"elapsed":45,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"4571a4f9-d121-4234-920b-ed7c9b722f72"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Results: [[ 3.7682990e-18 -7.6085186e-01]]\n"]}]},{"cell_type":"code","source":["# set go_backwards to True\n","LSTM_test_3 = tf.keras.layers.LSTM(2, go_backwards=True)\n","\n","test_sequence_output_1 = LSTM_test_3(test_sequence)\n","\n","print(\"Results: {}\".format(test_sequence_output_1))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lu9JDaxe0KcB","executionInfo":{"status":"ok","timestamp":1658254266392,"user_tz":-60,"elapsed":41,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"7e452acd-d0c7-4975-bdea-a8392846309c"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Results: [[ 0.08352461 -0.00242911]]\n"]}]},{"cell_type":"markdown","source":["reading the docs, it would process the sequence backwards and returns the reversed sequence."],"metadata":{"id":"3htvUv4J1Z_K"}},{"cell_type":"code","source":["# set return sequence to True\n","\n","LSTM_test_4 = tf.keras.layers.LSTM(2, return_sequences=True)\n","\n","test_sequence_output_2 = LSTM_test_4(test_sequence)\n","\n","print(\"Results: {}\".format(test_sequence_output_2))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pXdFxyZ10o62","executionInfo":{"status":"ok","timestamp":1658254266393,"user_tz":-60,"elapsed":37,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"9d0522c5-e19e-4695-9c05-ac1ed9e64a37"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Results: [[[-1.6088609e-02  1.3590582e-01]\n","  [-9.9099570e-06  1.4932834e-02]\n","  [-5.1123448e-09  1.3205848e-03]\n","  [-2.5271356e-12  1.0443183e-04]]]\n"]}]},{"cell_type":"markdown","source":["Looking at the output,\n","```\n","[[[ 4.5328138e-06 -1.6741604e-03] --> Output for the 2 units on the first word embedding in the batch.\n","  [ 2.3820494e-09 -1.7256550e-03] --> Output for the 2 units on the second word embedding in the batch.\n","  [ 1.2384534e-12 -1.8277960e-03] --> Output for the 2 units on the third word embedding in the batch.\n","  [ 6.4388152e-16 -1.9796446e-03] --> Output for the 2 units on the fourth sequence in the batch.]]\n","```\n"],"metadata":{"id":"strt35Db269a"}},{"cell_type":"code","source":["# set return state to True\n","LSTM_test_5 = tf.keras.layers.LSTM(2, return_state=True)\n","\n","test_sequence_output_5 = LSTM_test_5(test_sequence)\n","\n","print(\"Results: {}\".format(test_sequence_output_5))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cm-CyqOi3XY3","executionInfo":{"status":"ok","timestamp":1658254266395,"user_tz":-60,"elapsed":35,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"bc0b6873-fa10-466c-d0ad-da7a48db2352"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Results: [<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[-0.7615941 , -0.00511423]], dtype=float32)>, <tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[-0.7615941 , -0.00511423]], dtype=float32)>, <tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[-0.9999999, -3.9807653]], dtype=float32)>]\n"]}]},{"cell_type":"markdown","source":["### **Understanding the SimpleRNN Layer**\n","\n","**Quick recap**   \n","SimpleRNN are the basic implementation of recurrent neural networks (A class of neural networks which is able to handle sequential data such as text, time series, speech, etc..)\n","\n","<br>\n","\n","At each time step, the SimpleRNN output a prediction and a state vector. The state vector from previous time steps is then used as an additional input in calculating the next prediction at the next time step.\n","\n","<br>\n","\n","SimpleRNN are limited in it's capacity to capture dependencies spaning long periods of time.\n","\n","\n","Resources   \n","- https://machinelearningmastery.com/an-introduction-to-recurrent-neural-networks-and-the-math-that-powers-them/\n","- https://machinelearningmastery.com/understanding-simple-recurrent-neural-networks-in-keras/\n"],"metadata":{"id":"IDIoRTBB1Ia6"}},{"cell_type":"markdown","source":["Looking at the docs for simpleRNN there are loads of different option that we can play with. For now i think the basic input argument we need to care about are\n","\n","- units: Number of SimpleRNN in the layer\n","\n","- activation: Activation function used,\n","\n","- use_bias: (Boolean), decides if layer should use a bias vector.\n","\n","- dropout: (float) decides number of units to drop during forward pass\n","\n","- recurrent_dropout: (float) decides number of units to drop during forward pass of recurrent state???\n","\n","- return_sequences: (Boolean), returns the last output or return full sequence\n","\n","- return_state: (Boolean), returns last state\n","\n","- go_backwards: (Boolean), process input_sequence backwards and returns reversed sequence\n","\n","- stateful: (Boolean), return last state for each sample in the batch\n"],"metadata":{"id":"L05R4Wi6wPif"}},{"cell_type":"code","source":["# play around with a SimpleRNN\n","\n","# input sequence\n","sample_sequence = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])\n","\n","# define an embedding layer\n","embedding_layer = tf.keras.layers.Embedding(input_dim=100, output_dim=8, input_length=4)\n","\n","embedding_output = embedding_layer(sample_sequence)\n","\n","print(f\"Input_sequence: {sample_sequence}\")\n","print(f\"embedding_output: {embedding_output}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"38MhEw3duXp9","executionInfo":{"status":"ok","timestamp":1658257922773,"user_tz":-60,"elapsed":418,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"35749436-228a-4943-e098-7fa628ddfef1"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Input_sequence: [[1 2 3 4]\n"," [5 6 7 8]]\n","embedding_output: [[[ 0.0071786  -0.02770999 -0.01056663  0.03591186  0.03259296\n","   -0.0434543   0.00465118 -0.04895863]\n","  [ 0.04632975 -0.00595964 -0.03106047 -0.00852524 -0.0071097\n","    0.02627807  0.03068611 -0.04760075]\n","  [ 0.01149998  0.04637103 -0.04353411  0.03820454 -0.0167288\n","    0.04148007  0.02381236 -0.01381072]\n","  [-0.00913991  0.02020909 -0.02490957  0.017342   -0.01278111\n","    0.01980628 -0.01485886  0.02753275]]\n","\n"," [[ 0.01001146  0.01278545  0.03155548 -0.04833524 -0.02118723\n","   -0.03614746  0.00069385  0.0216359 ]\n","  [ 0.03733946  0.04492016  0.01998489 -0.00531695  0.0302333\n","   -0.02009546 -0.00944006  0.02976966]\n","  [-0.02754343 -0.01465994  0.0043788   0.00353374  0.02820127\n","    0.04190229  0.01130612  0.00886506]\n","  [-0.00214953 -0.02354258 -0.02432892 -0.02066363 -0.01827277\n","    0.03656251  0.03536358 -0.04086025]]]\n"]}]},{"cell_type":"code","source":["# basic SimpleRNN\n","simpleRNN_layer_0 = tf.keras.layers.SimpleRNN(units=5)\n","simpleRNN_layer_0_output = simpleRNN_layer_0(embedding_output)\n","\n","print(f\"Output of simpleRNN: {simpleRNN_layer_0_output}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qb17ef6U4HOs","executionInfo":{"status":"ok","timestamp":1658258186382,"user_tz":-60,"elapsed":2317,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"5e0f5418-1a48-404e-bb3e-7277686db5b7"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Output of simpleRNN: [[-0.0035262   0.00762389 -0.00519237 -0.02459231  0.05055945]\n"," [-0.03090524  0.03047003 -0.0064576   0.11406601  0.08437794]]\n"]}]},{"cell_type":"markdown","source":["output from the 5 simpleRNN in the layer, for the 2 samples in the batch."],"metadata":{"id":"EDU9Z5A95Z4h"}},{"cell_type":"code","source":["# SimpleRNN with return sequence set to True\n","\n","simpleRNN_layer_1 = tf.keras.layers.SimpleRNN(units=7, return_sequences=True)\n","simpleRNN_layer_1_output = simpleRNN_layer_1(embedding_output)\n","\n","print(f\"Output of simpleRNN: f{simpleRNN_layer_1_output}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jkbTuUay5jGe","executionInfo":{"status":"ok","timestamp":1658258583359,"user_tz":-60,"elapsed":1101,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"f844058d-9b05-4854-ce39-5c4eb8dc98c3"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Output of simpleRNN: f[[[ 4.67170514e-02  2.57526711e-02  2.19654310e-02 -7.40337968e-02\n","   -3.85756120e-02 -1.63747054e-02 -2.88166408e-03]\n","  [-3.39741930e-02  7.66357686e-03 -3.74802686e-02 -4.72790487e-02\n","    4.18617809e-03  1.86630897e-02 -7.19470456e-02]\n","  [-3.36450413e-02  8.45279172e-02  7.30351405e-03  6.56275600e-02\n","   -3.30622005e-03 -2.46235561e-02  1.13326246e-02]\n","  [ 4.19856124e-02  6.94798827e-02  5.03926985e-02 -2.04432793e-02\n","    5.17919920e-02 -5.59812237e-04 -5.30481860e-02]]\n","\n"," [[-7.80791370e-03 -5.34884445e-02 -4.55878153e-02  4.10600640e-02\n","   -5.71024092e-03  3.20048258e-02  1.91510711e-02]\n","  [ 3.83636951e-02 -3.65029946e-02 -4.65968624e-05  3.88131700e-02\n","   -7.57143274e-02  2.90241241e-02  8.19245279e-02]\n","  [ 6.81796297e-02  1.02709548e-03 -1.34778265e-02 -8.17172416e-03\n","   -3.13379727e-02  1.39801670e-02  3.46749835e-02]\n","  [ 3.24992128e-02 -4.28902637e-03 -4.15240116e-02 -3.92574398e-03\n","   -5.29155368e-03 -3.94932553e-02 -3.66065167e-02]]]\n"]}]},{"cell_type":"markdown","source":["output from a simpleRNN layer containing 7 units. For each batch and each sample in the batch it produces 7 output. Hence final shape is [2, 4, 7]"],"metadata":{"id":"CAwVlq1L61rm"}},{"cell_type":"code","source":["# SimpleRNN with return state set to True\n","\n","simpleRNN_layer_2 = tf.keras.layers.SimpleRNN(units=11, return_state=True)\n","simpleRNN_layer_2_output, final_state = simpleRNN_layer_2(embedding_output)\n","\n","print(f\"output of simpleRNN with return state set to True\")\n","print(f\"{simpleRNN_layer_2_output}\")\n","print(f\"{final_state}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VPuHju1p7Fl4","executionInfo":{"status":"ok","timestamp":1658259056465,"user_tz":-60,"elapsed":393,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"ab281518-d473-4e0e-94c9-556192cae572"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["output of simpleRNN with return state set to True\n","f[[-0.00899099 -0.08651289 -0.06966928 -0.06566335 -0.02472426  0.02238877\n","  -0.05144454 -0.02784575  0.08847877 -0.0409691  -0.03349891]\n"," [ 0.00236626  0.13123365  0.05066454  0.00946779  0.06558042 -0.04847437\n","   0.0884525   0.0780066  -0.05067851  0.07823572 -0.02735425]]\n","f[[-0.00899099 -0.08651289 -0.06966928 -0.06566335 -0.02472426  0.02238877\n","  -0.05144454 -0.02784575  0.08847877 -0.0409691  -0.03349891]\n"," [ 0.00236626  0.13123365  0.05066454  0.00946779  0.06558042 -0.04847437\n","   0.0884525   0.0780066  -0.05067851  0.07823572 -0.02735425]]\n"]}]},{"cell_type":"markdown","source":["it looks like the final states are the same as the outputs. 😒\n","\n","I wonder if my understanding of the state vector is wrong?? Could it be that the state vector or just the states are the same as the output of the SimpleRNN??"],"metadata":{"id":"UFgS9WEy8zKm"}},{"cell_type":"code","source":["# SimpleRNN with return states and return sequence set to True\n","\n","simpleRNN_layer_3 = tf.keras.layers.SimpleRNN(units=5, return_sequences=True, return_state=True)\n","simpleRNN_layer_3_output, final_state = simpleRNN_layer_3(embedding_output)\n","\n","print(f\"Output of simpleRNN with return sequences and states set to True\")\n","print(f\"{simpleRNN_layer_3_output}\")\n","print(f\"\\n{final_state}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GeN1PIQ39McJ","executionInfo":{"status":"ok","timestamp":1658259662631,"user_tz":-60,"elapsed":455,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"8a4b6045-8394-4269-f775-299f4ef19bb3"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Output of simpleRNN with return sequences and states set to True\n","[[[ 0.03062244 -0.02164007 -0.01669262  0.02174721  0.0110234 ]\n","  [-0.06658126 -0.0384743  -0.00944478  0.06394269 -0.03552142]\n","  [-0.0083191  -0.01397501  0.05373615 -0.02540039  0.0011354 ]\n","  [-0.03204141  0.08703158  0.0084386  -0.00434022 -0.00166453]]\n","\n"," [[ 0.0048805   0.00900241 -0.00591772 -0.05879032 -0.04276478]\n","  [ 0.0667311   0.04170684 -0.07011628 -0.09220314 -0.06993692]\n","  [ 0.07790264  0.00506384 -0.07255677  0.04522913 -0.00602574]\n","  [-0.01184071 -0.08007074  0.00045335  0.12782802 -0.00818433]]]\n","\n","[[-0.03204141  0.08703158  0.0084386  -0.00434022 -0.00166453]\n"," [-0.01184071 -0.08007074  0.00045335  0.12782802 -0.00818433]]\n"]}]},{"cell_type":"markdown","source":["yeah it looks like the output and states are the same.\n","\n","Question why are states not passed between batches?\n","- Looking at the output it seems that the outputs are the same as the states. For a batch containing multiple samples which we assume as independent from each other it would not make any sense to use the last prediction from the previous sample as the input state.\n","\n","<br>\n","\n","Just like with the LSTM, the final output and the hidden states are the same, I'm still not entirely sure about the final cell state in an LSTM layer."],"metadata":{"id":"0xA1c8f--oAY"}},{"cell_type":"markdown","source":["### **Understanding GRU Layers**"],"metadata":{"id":"BMA5QR0e1c8q"}},{"cell_type":"markdown","source":["##**Using Conv1D Layers**\n"],"metadata":{"id":"jkS4IW17preW"}}]}