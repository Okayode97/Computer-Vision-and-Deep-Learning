{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Udacity  Intro to TensorFlow for Deep Learning, Lesson 10.ipynb ","provenance":[],"collapsed_sections":["r8YH_1oFx0lD","SD3FndIDgGNL","HKBlXO8_nblk"],"authorship_tag":"ABX9TyM5uJgJnuxhRmIOnRZQrbP9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# **Udacity: Intro to TensorFlow for Deep Learning**\n","## **Lesson 10 NLP: Recurrent Neural Networks**\n","\n","This lessons extends on what was covered in lesson 9. It introduces recurrent neural networks, which are able to capture temporal dependences,that change over time.\n","\n","This lesson would covers\n","- Different RNNs: Simple RNN, LSTMS, GRUs\n","- Text generation using NLP models.\n"],"metadata":{"id":"CakMRRpBlwnH"}},{"cell_type":"markdown","source":["##**Simple RNNS**\n","\n","Simple recurrent neural networks, are networks which use outputs from previous time steps as additional inputs, alongside the current input.\n","\n","for example   \n","- Inputs: $X_t + Y_{t-1}$\n","- Ouput: $Y_t$\n","\n","I'm a bit effy around th calculation of the output.\n","\n","But...\n","\n","The general idea is that, previous output from the last time step are fed as additional inputs. The previous output is referred to as the state vector.\n","\n","<br>\n","\n","While simple RNN architecture are able to consider the past output when calculating it's new output, it is limited by how far back it can relate dependencies and for dependencies which occur over long period of time, a simple RNN would struggle to capture these dependencies."],"metadata":{"id":"aRKgF0f9m6_Z"}},{"cell_type":"markdown","source":["## **Long term short term Memory**\n","\n","LSTMs, were introduced to capture temporal dependencies which spam over longer periods of time. Unlike simple RNNS which have a single state vector, LSTMS have 2 state vectors, a Long term memory and a short term memory.\n","\n","<br>\n","\n","**Features of an LSTM**\n","- It's able to capture temporal dependencies spaming a long period of time\n","- It has 2 state vectors, long term and short term memory, which are used in calculating a new input\n","- LSTM feature gates: Forget, learn, remember and use gates.\n","\n","<br>\n","\n","**Workflow for an LSTM**\n","- At each time step, the LSTM has 2 state vectors: A long term memory and a short term memory\n","- The current time step input alongside the 2nd state vectors are used to determine an output.\n","- The calculated output from the current time step input, would be used as the short term memory for the next timestep\n","- The long term memory from the previous time step is updated:\n","  - Any pieces of the previous long term memory which is no longer relevant is removed, using the forget gate\n","  - Any new piece of relevant information is added to the long term memory, using the remember gate\n","\n","<br>\n","\n","**LSTM Gates**\n","- Forget gate: Determines which parts of the long term memory are no longer relevant and should be removed from memory.\n","- Learn gate: Learns new piece of informations using the current input and short term memory.\n","\n","- Remember gate: Adds any relevant information that was learnt to the long term memory. The output of this gate is the new long term memory\n","\n","- Use gate: This uses, the relevants parts of the long term memory and newly learnt information to calculate an output. The output is also used as the new short term memory for the next timestep.\n","\n"],"metadata":{"id":"sfn-5JjQrdEQ"}},{"cell_type":"markdown","source":["## **Gated Recurrent Units**\n","\n","Gated recurrent units were introduced in 2014, with the aim of solving the vanishing gradient problem, an issue that plagues standard recurrent networks.\n","<br>\n","\n","To solve this GRU features gates (An update and reset gate) similar to LSTMS.\n","- **Reset gate**: Decides how much of the previous information is relevant. The relevant portion of the previous information is then added to the current input, to create an intermidary state vector.\n","\n","- **Update gate**: Decides how much of the previous state should be kept and should then be added to the intermidary state vector.\n","\n","<br>\n","\n","Difference between GRUs and LSTMS\n","- GRU have fewer parameters (2 gates: update and reset) so are much faster to train and require less data to generalize to new samples.\n","\n","- In comparison LSTMS have more parameters with it's 4 gates (Learn, forget, use and remember), as such it would take relatively longer to train. But the increased gated connections provides better expressiveness which could lead to better results.\n","\n","<br>\n","\n","**Resources used**\n","- Helpful in grasping the maths behind GRU, [Understanding GRU networks](https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be)\n","- https://www.kaggle.com/code/thebrownviking20/intro-to-recurrent-neural-networks-lstm-gru/notebook\n"],"metadata":{"id":"BMA5QR0e1c8q"}},{"cell_type":"markdown","source":["## **RNNs in code**\n","\n","The LSTM layer is within `tf.keras.Layers.LSTM` [docs](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM). likewise with the RNN layer `tf.keras.Layers.SimpleRNN`.\n","\n","<br>\n","\n","Worth noting:\n","- We can directly pass, the output of an embedding layer to an LSTM layer without adding a flatten or GlobalAverage1D layer inbetween.\n","\n","<br>\n","\n","**Further resources:**   \n","The [recurrent neural network (RNN) with keras guide](https://www.tensorflow.org/guide/keras/rnn) is a really good supplementary introduction to RNNs.\n","\n","Notes from the guide\n","- 3 built-in RNN layers: SimpleRNN, GRU, LSTM\n","- RNN can process input sequences in reverse.\n","- Feature recurrent dropout\n","- By default returns output at the last time step, but it can be configured to return a sequence instead for each time step.\n","- The layer can also be configured to return the final internal state vectors.\n","- Likewise we can also set the initial state of the RNN layer.\n","\n","<br>\n","\n","**Difference between layer and cell layer**\n","- \"*the RNN cell process only a single timestep*\""],"metadata":{"id":"LiptnBXSyAlA"}},{"cell_type":"markdown","source":["### **Import Dependencies**\n","\n","import tensorflow and numpy"],"metadata":{"id":"r8YH_1oFx0lD"}},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","\n","print(tf.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O-IeCkjWrcIl","executionInfo":{"status":"ok","timestamp":1658573562821,"user_tz":-60,"elapsed":1507,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"652d573d-d922-4b32-a329-99d18a63d157"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["2.8.2\n"]}]},{"cell_type":"markdown","source":["### **Preparing text for SimpleRNN, LSTM and GRU layers**\n","\n","Simplified look at using the SimpleRNN, LSTM and GRU layers.\n","In this section, the layers would take inputs from an Embedding layer, we would then look at the output of each layer for a given embedding.\n","\n","<br>\n","\n","**Note**   \n","we would not train a full network yet, this is just to gain an understanding of what the output of each layer would be, when we change the parameters of each layer.\n","\n","<br>\n","\n","**Prepare text**   \n","We would begin by preparing some text: Tokenize and padd\n"],"metadata":{"id":"SD3FndIDgGNL"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"CmqDPNFLuELj","executionInfo":{"status":"ok","timestamp":1658573562823,"user_tz":-60,"elapsed":29,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}}},"outputs":[],"source":["# sample text\n","# The great pretender - The Platters\n","lyrics = [\"Oh-oh, yes, I'm the great pretender\",\n","          \"Pretending that I'm doing well\",\n","          \"My need is such I pretend too much\",\n","          \"I'm lonely, but no one can tell\",\n","          \"Oh-oh, yes, I'm the great pretender\",\n","          \"Adrift in a world of my own\",\n","          \"I've played the game but to my real shame\",\n","          \"You've left me to grieve all alone\",\n","          \"Too real is this feeling of make-believe\",\n","          \"Too real when I feel what my heart can't conceal\",\n","          \"Yes, I'm the great pretender\",\n","          \"Just laughin' and gay like a clown\",\n","          \"I seem to be what I'm not, you see\",\n","          \"I'm wearing my heart like a crown\",\n","          \"Pretending that you're still around\"\n","          \"Too real is this feeling of make-believe\",\n","          \"Too real when I feel what my heart can't conceal\",\n","          \"Yes, I'm the great pretender\",\n","          \"Just laughin' and gay like a clown\",\n","          \"I seem to be what I'm not, you see\",\n","          \"I'm wearing my heart like a crown\",\n","          \"Pretending that you're still around (still around)\"]\n"]},{"cell_type":"code","source":["# tokenize and pad the text\n","\n","# deprecated in version 2.9.1\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","\n","# define a tokenizer and fit it to the text\n","The_great_pretender = Tokenizer(num_words=150, oov_token=\"<OOV>\")\n","The_great_pretender.fit_on_texts(lyrics)\n"],"metadata":{"id":"Yies0OUAgRF2","executionInfo":{"status":"ok","timestamp":1658573562824,"user_tz":-60,"elapsed":28,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# display the word index\n","word_index = The_great_pretender.word_index\n","print(word_index)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RlnOAgUBjYG_","executionInfo":{"status":"ok","timestamp":1658573562826,"user_tz":-60,"elapsed":28,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"0fd4dc57-82db-4504-8e8e-21382216f20f"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["{'<OOV>': 1, \"i'm\": 2, 'my': 3, 'the': 4, 'i': 5, 'a': 6, 'real': 7, 'oh': 8, 'yes': 9, 'great': 10, 'pretender': 11, 'too': 12, 'to': 13, 'what': 14, 'heart': 15, 'like': 16, 'pretending': 17, 'that': 18, 'is': 19, 'of': 20, 'still': 21, 'but': 22, 'this': 23, 'feeling': 24, 'make': 25, 'believe': 26, 'when': 27, 'feel': 28, \"can't\": 29, 'conceal': 30, 'just': 31, \"laughin'\": 32, 'and': 33, 'gay': 34, 'clown': 35, 'seem': 36, 'be': 37, 'not': 38, 'you': 39, 'see': 40, 'wearing': 41, 'crown': 42, \"you're\": 43, 'around': 44, 'doing': 45, 'well': 46, 'need': 47, 'such': 48, 'pretend': 49, 'much': 50, 'lonely': 51, 'no': 52, 'one': 53, 'can': 54, 'tell': 55, 'adrift': 56, 'in': 57, 'world': 58, 'own': 59, \"i've\": 60, 'played': 61, 'game': 62, 'shame': 63, \"you've\": 64, 'left': 65, 'me': 66, 'grieve': 67, 'all': 68, 'alone': 69, 'aroundtoo': 70}\n"]}]},{"cell_type":"code","source":["# convert the lyrics to sequences\n","lyrics_sequence = The_great_pretender.texts_to_sequences(lyrics)\n","\n","length_of_sequence = []\n","for sequence in lyrics_sequence:\n","  print(sequence)\n","  break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i78foHRgjV5b","executionInfo":{"status":"ok","timestamp":1658573562827,"user_tz":-60,"elapsed":25,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"d0edf716-22d1-4d51-b8b1-0872472cd3ec"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["[8, 8, 9, 2, 4, 10, 11]\n"]}]},{"cell_type":"code","source":["# display the average length of each sequence\n","length_of_sequence = []\n","for sequence in lyrics_sequence:\n","  length_of_sequence.append(len(sequence))\n","\n","\n","#src: https://www.geeksforgeeks.org/find-average-list-python/\n","def Average(lst):\n","    return sum(lst) / len(lst)\n","  \n","\n","print(Average(length_of_sequence))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gxz1XF3DkcMt","executionInfo":{"status":"ok","timestamp":1658573562836,"user_tz":-60,"elapsed":32,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"fa4caca2-48d6-4422-d196-d4f12a8c137b"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["7.619047619047619\n"]}]},{"cell_type":"code","source":["# Apply padding to the sequences\n","lyrics_sequence_padded = pad_sequences(lyrics_sequence, maxlen=7, padding='pre',\n","                                      truncating='post')\n"],"metadata":{"id":"jjrkhRa-j2-4","executionInfo":{"status":"ok","timestamp":1658573562838,"user_tz":-60,"elapsed":31,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["### **Define an embedding layer**\n","\n","Create an embedding from the padded and tokenized sequences.\n","\n","I'd probably not use this in later parts of the notebook, but it is still a good practice to remember how to prepare text and use word embeddings"],"metadata":{"id":"HKBlXO8_nblk"}},{"cell_type":"code","source":["# define an embedding layer\n","Embedding = tf.keras.layers.Embedding(input_dim=150, output_dim=4, input_length=7)"],"metadata":{"id":"oy5CyKbMgTpF","executionInfo":{"status":"ok","timestamp":1658573562841,"user_tz":-60,"elapsed":33,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# pass in a sequence from the lyric_sequence_padded to the embedding layer\n","output = Embedding(np.array(sequence))\n","print(output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jLSH6BrRltrB","executionInfo":{"status":"ok","timestamp":1658573565087,"user_tz":-60,"elapsed":2278,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"4ab89c7d-9789-4c93-e4ba-e930559fd53f"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[[-0.01425667  0.03933812 -0.00957012 -0.0029873 ]\n"," [ 0.0455013  -0.00408681 -0.01951443  0.04865884]\n"," [ 0.02904112 -0.02296771  0.02500412  0.03320162]\n"," [-0.00348942 -0.03319496  0.0226015   0.02124378]\n"," [-0.00146838  0.0180063   0.02366808 -0.02330911]\n"," [-0.00348942 -0.03319496  0.0226015   0.02124378]\n"," [-0.00146838  0.0180063   0.02366808 -0.02330911]], shape=(7, 4), dtype=float32)\n"]}]},{"cell_type":"markdown","source":["we now have a vector of 4 dimensions representing of each tokens in the sequence.\n","\n","A thought on the embedding layer\n","- i don't think the embedding layer is trainable, provided it's function is to simply convert the tokens into a vector representation, i can't really see how any optimization is needed.\n","\n","Unless the scale or way in which the conversion is done needs to be different to get better results, i'm not sure."],"metadata":{"id":"bnlNt3ZwmJaz"}},{"cell_type":"markdown","source":["Looking into the above text, *i don't think the embedding layer is trainable*\n","\n","<br>\n","\n","**Is the embedding layer trainable?**\n","\n","The short answer is that, the embedding layer is trainable, it is not enough to just map each token to vector.\n","<br>\n","\n","- At it's core, the embedding layer maps positive integers (tokens) into dense vectors of fixed size (word embeddings).\n","- ideally we would like words with similar semantic context or sentiment, to have similar vector representations, so words like man and woman should have fairly similar vectors. Likewise words like apple, orange, banana, pears should be within the same general cluster, in our n dimensional space for our word embedding.\n","- We would not be able to achieve this by randomly mapping our tokens into vectors. Hence our vector representation would need to be optimzied to group similar words to be within the same latent space in our word embedding.\n","\n","<br>\n","\n","**Resources**\n","- https://stats.stackexchange.com/questions/324992/how-the-embedding-layer-is-trained-in-keras-embedding-layer\n","- https://www.youtube.com/watch?v=5MaWmXwxFNQ\n","\n","<br>\n","\n","**More questions**\n","- What is word2Vec, skip-gram?"],"metadata":{"id":"zJvOvFqg-sFf"}},{"cell_type":"markdown","source":["### **Using the SimpleRNN Layer**\n","\n","**Quick recap**   \n","SimpleRNN are the basic implementation of recurrent neural networks (A class of neural networks which is able to handle sequential data such as text, time series, speech, etc..).   \n","At each time step, the SimpleRNN output a prediction and a state vector. The state vector from previous time steps is then used as an additional input in calculating the next prediction at the next time step.\n","\n","**limitatons**   \n","- SimpleRNN are limited in it's capacity to capture dependencies spaning long periods of time.\n","- Vanishing graident problem\n","\n","<br>\n","\n","**Resources**\n","- https://machinelearningmastery.com/an-introduction-to-recurrent-neural-networks-and-the-math-that-powers-them/\n","- https://machinelearningmastery.com/understanding-simple-recurrent-neural-networks-in-keras/\n","\n","<br>\n","\n","**Question**\n","- Is the state vector the same as the output produced at each time step?"],"metadata":{"id":"IDIoRTBB1Ia6"}},{"cell_type":"markdown","source":["**Define a basic implementation of SimpleRNN**"],"metadata":{"id":"mQ9jwwf6ppxF"}},{"cell_type":"code","source":["# input sequence\n","sample_sequence = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])\n","\n","# define an embedding layer\n","embedding_layer = tf.keras.layers.Embedding(input_dim=100, output_dim=8,\n","                                            input_length=4)\n","\n","embedding_output = embedding_layer(sample_sequence)\n","\n","print(f\"Input_sequence: \\n{sample_sequence}\")\n","print(f\"\\nembedding_output: \\n{embedding_output}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"38MhEw3duXp9","executionInfo":{"status":"ok","timestamp":1658573612998,"user_tz":-60,"elapsed":506,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"a04b06ef-fbde-4f91-c1e5-3df73eef4512"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Input_sequence: \n","[[1 2 3 4]\n"," [5 6 7 8]]\n","\n","embedding_output: \n","[[[-0.04436916 -0.046588   -0.03033881 -0.04012107 -0.04228991\n","   -0.01611384 -0.0452862  -0.03635208]\n","  [-0.03163145  0.028487   -0.00798888  0.01625302 -0.00956733\n","    0.02072776 -0.00356535 -0.00335278]\n","  [-0.0281114   0.04394294 -0.00869752 -0.01702369  0.04539898\n","    0.00076826 -0.00525911 -0.01790025]\n","  [-0.02550764 -0.02603803  0.0375783  -0.04038745 -0.02591337\n","    0.03442175  0.04278809 -0.03333489]]\n","\n"," [[ 0.01197816 -0.03638438 -0.04979093  0.00194967 -0.00377122\n","   -0.01964084 -0.01276795  0.04086879]\n","  [ 0.00198022 -0.03651668  0.00650264  0.0292205   0.02930614\n","   -0.00053935  0.01651588  0.0496464 ]\n","  [-0.02612044 -0.00718763 -0.03799029 -0.00346025 -0.03092719\n","   -0.04868176  0.02475161  0.02923426]\n","  [ 0.01994821  0.01585681 -0.03392265  0.00387371  0.02482668\n","    0.03193602 -0.01098223  0.03082924]]]\n"]}]},{"cell_type":"code","source":["# basic SimpleRNN\n","simpleRNN_layer_0 = tf.keras.layers.SimpleRNN(units=5)\n","simpleRNN_layer_0_output = simpleRNN_layer_0(embedding_output)\n","\n","print(f\"Output of simpleRNN: {simpleRNN_layer_0_output}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qb17ef6U4HOs","executionInfo":{"status":"ok","timestamp":1658573623237,"user_tz":-60,"elapsed":1968,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"deecd309-b52b-43fd-e610-ad493795affe"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Output of simpleRNN: [[ 0.14154036 -0.03116032 -0.02066625 -0.11908543  0.01602411]\n"," [-0.16496156 -0.02635418 -0.01401711 -0.0731071   0.07373834]]\n"]}]},{"cell_type":"markdown","source":["output from the 5 simpleRNN in the layer, for the 2 samples in the batch."],"metadata":{"id":"EDU9Z5A95Z4h"}},{"cell_type":"markdown","source":["**SimpleRNN with return sequence set to True**"],"metadata":{"id":"UwrdDltFqdG6"}},{"cell_type":"code","source":["# SimpleRNN with return sequence set to True\n","simpleRNN_layer_1 = tf.keras.layers.SimpleRNN(units=7, return_sequences=True)\n","simpleRNN_layer_1_output = simpleRNN_layer_1(embedding_output)\n","\n","print(f\"Output of simpleRNN \\n: {simpleRNN_layer_1_output}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jkbTuUay5jGe","executionInfo":{"status":"ok","timestamp":1658573638341,"user_tz":-60,"elapsed":697,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"8d16630f-23c8-441c-a3f8-ff2e08d50220"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Output of simpleRNN: [[[-0.00791446  0.00531016  0.02833577 -0.10240722  0.04435795\n","    0.04338466 -0.03927782]\n","  [-0.02294649  0.05608001  0.06695591  0.01919121 -0.07094719\n","    0.05240041 -0.01179952]\n","  [ 0.00049517 -0.00886351  0.03744813  0.07296041  0.05648455\n","    0.01337563  0.06164669]\n","  [-0.08059626 -0.07067633 -0.02609253 -0.01824237  0.13309442\n","    0.08805474 -0.02784048]]\n","\n"," [[ 0.00964613 -0.00414358 -0.01301007 -0.0483936  -0.04030683\n","    0.01482623  0.00629307]\n","  [ 0.04720924  0.01849745 -0.07449772  0.0350161  -0.01889437\n","   -0.00786987  0.01177997]\n","  [ 0.05065968 -0.05938216 -0.0648331  -0.05308506 -0.01010802\n","    0.04277499 -0.01339542]\n","  [ 0.02397647  0.03595821 -0.08856503  0.00908809 -0.12199629\n","    0.00020513  0.00293914]]]\n"]}]},{"cell_type":"markdown","source":["output from a simpleRNN layer containing 7 units, with a sequence length of 4.   \n","For each sample in the batch it produces 7 output. Hence final shape is [2, 4, 7].   \n","The final output for each sample in the batch is the last element in the array."],"metadata":{"id":"CAwVlq1L61rm"}},{"cell_type":"code","source":["print(f\"final output for the first sample in the batch: \\n {simpleRNN_layer_1_output[0][-1]}\")\n","print(f\"\\nfinal output for the second sample in the batch: \\n {simpleRNN_layer_1_output[1][-1]}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lDH7hS_TsaG4","executionInfo":{"status":"ok","timestamp":1658573806533,"user_tz":-60,"elapsed":1922,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"8bbcd6d7-49e4-4ae4-b466-9630bb7a5f2c"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["final output for the first sample in the batch: \n"," [-0.08059626 -0.07067633 -0.02609253 -0.01824237  0.13309442  0.08805474\n"," -0.02784048]\n","final output for the second sample in the batch: \n"," [ 0.02397647  0.03595821 -0.08856503  0.00908809 -0.12199629  0.00020513\n","  0.00293914]\n"]}]},{"cell_type":"markdown","source":["**SimpleRNN with return state set to True**"],"metadata":{"id":"V1RtnadJqzj_"}},{"cell_type":"code","source":["# SimpleRNN with return state set to True\n","simpleRNN_layer_2 = tf.keras.layers.SimpleRNN(units=11, return_state=True)\n","simpleRNN_layer_2_output, final_state = simpleRNN_layer_2(embedding_output)\n","\n","\n","print(f\"SimpleRNN_layer_2_output final output: \\n{simpleRNN_layer_2_output}\")\n","print(f\"\\nSimpleRNN_layer_2_output final state: \\n{final_state}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VPuHju1p7Fl4","executionInfo":{"status":"ok","timestamp":1658574092427,"user_tz":-60,"elapsed":1970,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"76d33d47-1a61-4b60-d19a-3bf12e763dc4"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["SimpleRNN_layer_2_output final output: \n","[[-0.06191324 -0.04811127 -0.07531374 -0.02578576 -0.09219531  0.00095944\n","  -0.04507505 -0.05979072  0.045462    0.00225019  0.16151163]\n"," [-0.02583531  0.10042801  0.02006783 -0.00474388  0.08194724  0.06866762\n","   0.02788192 -0.04119573  0.02103317 -0.05415137  0.02626269]]\n","\n","SimpleRNN_layer_2_output final state: \n","[[-0.06191324 -0.04811127 -0.07531374 -0.02578576 -0.09219531  0.00095944\n","  -0.04507505 -0.05979072  0.045462    0.00225019  0.16151163]\n"," [-0.02583531  0.10042801  0.02006783 -0.00474388  0.08194724  0.06866762\n","   0.02788192 -0.04119573  0.02103317 -0.05415137  0.02626269]]\n"]}]},{"cell_type":"markdown","source":["***it looks like the final states are the same as the outputs***. So this answers the question as to if the state vectors are the same as the output. It looks like they are.\n","\n"],"metadata":{"id":"UFgS9WEy8zKm"}},{"cell_type":"markdown","source":["**SimpleRNN with return sequence and state set to True**"],"metadata":{"id":"FOBOGtKktaoB"}},{"cell_type":"code","source":["# SimpleRNN with return states and return sequence set to True\n","\n","simpleRNN_layer_3 = tf.keras.layers.SimpleRNN(units=5, return_sequences=True, return_state=True)\n","simpleRNN_layer_3_output, final_state = simpleRNN_layer_3(embedding_output)\n","\n","print(f\"SimpleRNN_layer_3_output at each time step: \\n {simpleRNN_layer_3_output}\")\n","print(f\"\\nSimpleRNN_layer_3_final state: \\n{final_state}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GeN1PIQ39McJ","executionInfo":{"status":"ok","timestamp":1658574184439,"user_tz":-60,"elapsed":8,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"b47dd4c3-b52d-43b7-f1bd-f3a7377c5014"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["SimpleRNN_layer_3_output at each time step: \n"," [[[ 0.04475474  0.08183377  0.03800399 -0.00740108 -0.0329938 ]\n","  [-0.02409583 -0.06263659  0.0736509  -0.05587266 -0.03042615]\n","  [ 0.01214191 -0.01820896 -0.00401788  0.00358409  0.12225598]\n","  [ 0.09843498  0.02812253 -0.02506265 -0.04060108  0.04456408]]\n","\n"," [[-0.01349652  0.03701126  0.02167615 -0.02576507 -0.03183632]\n","  [-0.08951548 -0.05968942 -0.0057901   0.01342212  0.02970805]\n","  [ 0.05061521  0.10648205 -0.0067666  -0.09623881 -0.02535432]\n","  [-0.03010683 -0.16157256  0.003481    0.00620044 -0.00710471]]]\n","\n","SimpleRNN_layer_3_final state: \n","[[ 0.09843498  0.02812253 -0.02506265 -0.04060108  0.04456408]\n"," [-0.03010683 -0.16157256  0.003481    0.00620044 -0.00710471]]\n"]}]},{"cell_type":"markdown","source":["yeah it looks like the output and states are the same.\n","\n","<br>\n","\n","Question why are states not passed between batches?\n","- Looking at the output it seems that the outputs are the same as the states. For a batch containing multiple samples which we assume as independent from each other it would not make any sense to use the last prediction from the previous sample as the input state.\n"],"metadata":{"id":"0xA1c8f--oAY"}},{"cell_type":"markdown","source":["### **Using the LSTM layer**"],"metadata":{"id":"450-KEHjCD7V"}},{"cell_type":"markdown","source":["**Define a basic LSTM layer**"],"metadata":{"id":"bZPlOe5Fvihm"}},{"cell_type":"code","source":["# pass the output of the embedding layer to the LSTM layer\n","LSTM = tf.keras.layers.LSTM(units=4)\n","\n","embedding_output = Embedding(np.array([sequence]))\n","LSTM_output = LSTM(embedding_output)\n","\n","print(\"Input: {}\".format(np.array([sequence])))\n","print(\"\\nEmbedding layer output: \")\n","print(embedding_output)\n","print(\"\\nLSTM layer output: \")\n","print(LSTM_output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zTjFQHX8mx49","executionInfo":{"status":"ok","timestamp":1658575617907,"user_tz":-60,"elapsed":2250,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"afcac49a-b353-448c-9b5f-92d8f430f6a7"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: [[17 18 43 21 44 21 44]]\n","\n","Embedding layer output: \n","tf.Tensor(\n","[[[-0.01425667  0.03933812 -0.00957012 -0.0029873 ]\n","  [ 0.0455013  -0.00408681 -0.01951443  0.04865884]\n","  [ 0.02904112 -0.02296771  0.02500412  0.03320162]\n","  [-0.00348942 -0.03319496  0.0226015   0.02124378]\n","  [-0.00146838  0.0180063   0.02366808 -0.02330911]\n","  [-0.00348942 -0.03319496  0.0226015   0.02124378]\n","  [-0.00146838  0.0180063   0.02366808 -0.02330911]]], shape=(1, 7, 4), dtype=float32)\n","\n","LSTM layer output: \n","tf.Tensor([[ 0.01005772  0.00248262 -0.00588322 -0.00934658]], shape=(1, 4), dtype=float32)\n"]}]},{"cell_type":"markdown","source":["So what has happened??\n","- it looks like the number of units correspond to the shape of the output, so if there is 1 unit it would produce a shape of (1, 1) and if there are 4 units it would produce a shape of (1, 4).\n","- recap output of embedding layer is vector of n dimension representation of a sequence.\n"],"metadata":{"id":"V7k0DNwBpokm"}},{"cell_type":"markdown","source":["**Set return_sequences to True**"],"metadata":{"id":"bzNqvbsXU3uR"}},{"cell_type":"code","source":["# lstm layer with return sequence = True\n","LSTM_return_sequence = tf.keras.layers.LSTM(units=4, return_sequences=True)\n","LSTM_return_sequence_output = LSTM_return_sequence(embedding_output)\n","\n","print(\"Input: {}\".format(np.array([sequence])))\n","print(\"\\nLSTM layer output: \")\n","print(LSTM_return_sequence_output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VnoRVg_Dpizp","executionInfo":{"status":"ok","timestamp":1658575623022,"user_tz":-60,"elapsed":455,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"fd354e2f-4c43-4a54-eee4-1df0385431a8"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: [[17 18 43 21 44 21 44]]\n","\n","LSTM layer output: \n","tf.Tensor(\n","[[[ 0.00025353  0.00134016 -0.00142952 -0.00233571]\n","  [ 0.00298489 -0.00426727  0.00681078 -0.00389279]\n","  [ 0.00747593 -0.00740302  0.00727068 -0.00465844]\n","  [ 0.00612443 -0.00683046  0.00517538 -0.00313806]\n","  [ 0.0091947  -0.00362551  0.00142917 -0.00327655]\n","  [ 0.00676546 -0.00364445  0.00064056 -0.00262688]\n","  [ 0.00902891 -0.0010586  -0.0021648  -0.00334409]]], shape=(1, 7, 4), dtype=float32)\n"]}]},{"cell_type":"markdown","source":["with return sequence set to True as it iterates through the sequence, and returns a value for each token, as there are 7 tokens in a sequence, it returns 7 values and since we have 4 units in our LSTM for each time step it returned 4 value.\n","\n","still don't fully understand what the output mean"],"metadata":{"id":"erL0O6lqs-_D"}},{"cell_type":"markdown","source":["**Understanding the output of an LSTM layer**\n","\n","Notes from machine learning mastery.\n","- The LSTM is a class of recurrent neural networks which contains internal gates (Learn, forget, remember and use gates).\n","- This class of recurrent neural networks are designed to resolve the vanishing gradient problem, as it is able to capture longer temporal dependencies.\n","- An LSTM layer can be defined with n number of LSTMs cell. each cell contains,\n","  - an internal cell state, *c*\n","  - outputs a hidden state *h*\n","\n","The output of an LSTM is the hidden state *h*.\n","\n","<br>\n","\n","By setting \n","- **return_sequence to True**, we are able to access the hidden state at each time step, in our sequence.\n","- **return_state to True**, this would return the final hidden state *c* and the internal cell state *h* of each cell in the LSTM layer.\n","\n","We would typically set the `return_state to True`, when we want to initialize the states of another LSTM layer with the same number of cells.\n","\n","<br>\n","\n","Cool...\n","\n","But this has still not answered the question of what the internal cell state and hidden cell states are.\n","\n","\n","<br>\n","\n","**Resources**\n","- https://stackoverflow.com/questions/67970519/what-does-tensorflow-lstm-return\n","\n","- https://machinelearningmastery.com/return-sequences-and-return-states-for-lstms-in-keras/\n"," "],"metadata":{"id":"rRTL0ZN-zl3B"}},{"cell_type":"markdown","source":["**Setting return state and sequences to True**"],"metadata":{"id":"rsPj5EZ3xAFv"}},{"cell_type":"code","source":["# Example used in stackoverflow question\n","# Set return_sequence and return_states to True\n","\n","# input shape: Batch size, length of sequence, embedding dimension\n","tensor = tf.random.normal(shape=[2, 2, 2])\n","lstm = tf.keras.layers.LSTM(units=4, return_sequences=True, return_state=True)\n","hidden_state_at_each_time_step, final_hidden_state, final_cell_state = lstm(tensor)\n","\n","print(\"Input: {}\".format(tensor))\n","print(\"\\nHidden_state_at_each_time_step (output at each time step):\\n\", hidden_state_at_each_time_step)\n","print(\"\\nFinal hidden state (output): \\n\", final_hidden_state)\n","print(\"\\nFinal cell state: \\n\", final_cell_state)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JypRlC2L0Bnp","executionInfo":{"status":"ok","timestamp":1658575627640,"user_tz":-60,"elapsed":10,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"de977f75-5d1d-4234-a0a6-f66b3011fd6d"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: [[[-1.071289    1.987392  ]\n","  [-0.09516488 -1.952016  ]]\n","\n"," [[ 1.2150242   0.78332025]\n","  [-1.4531772  -0.29592833]]]\n","\n","Hidden_state_at_each_time_step (output at each time step):\n"," tf.Tensor(\n","[[[-0.1533716   0.05992407 -0.41533175 -0.09892309]\n","  [ 0.00826846  0.00213334 -0.07077234 -0.10955881]]\n","\n"," [[-0.16051902 -0.02591506 -0.04823894  0.09310576]\n","  [ 0.02331617  0.00899057 -0.05557375 -0.06233778]]], shape=(2, 2, 4), dtype=float32)\n","\n","Final hidden state (output): \n"," tf.Tensor(\n","[[ 0.00826846  0.00213334 -0.07077234 -0.10955881]\n"," [ 0.02331617  0.00899057 -0.05557375 -0.06233778]], shape=(2, 4), dtype=float32)\n","\n","Final cell state: \n"," tf.Tensor(\n","[[ 0.02242753  0.00674389 -0.25265494 -0.16699997]\n"," [ 0.04713709  0.03350394 -0.11022087 -0.12426493]], shape=(2, 4), dtype=float32)\n"]}]},{"cell_type":"markdown","source":["**WTF...**\n","\n","**Breakdown of the output**\n","\n","\n","For an input of shape `[2, 2, 2]`, we have a batches of 2 sentences.\n","``` python\n","[[[-0.4942633   1.0938902 ], [-0.27461976 -0.2292373 ]]\n"," [[-0.34839615 -0.39708054], [ 0.21653225  2.0741708 ]]]\n","```\n","Where `[-0.4942633   1.0938902 ]` for example is our word embedding for a single token.\n","\n","So an example input that could create the above word embedding is\n","``` python\n","example sequence of tokens = [[10, 11], [12, 13]]\n","\n","# 10 -> [-0.4942633   1.0938902 ]\n","# 11 -> [-0.27461976 -0.2292373 ]\n","# 12 -> [-0.34839615 -0.39708054]\n","# 13 -> [ 0.21653225  2.0741708 ]\n","\n","# decoded even futher as another example \n","[\"hello, you\"], [\"Good food\"]\n","\n","# hell0 -> 10\n","# you -> 11\n","# Good -> 12\n","# food -> 13\n","```\n","\n","With return sequence and state set to True. We have\n","- The hidden state $h_{t}$ returned at each time step.\n","- The final hidden cell state $h$ returned\n","- The final cell state $c$ returned.\n","\n","<br>\n","\n","**Note**   \n","- Looking carefully at the output, you should see that the final hidden cell state is just the last hidden cell state for each sequence.\n","- ***The final cell state is different from the hidden cell state***"],"metadata":{"id":"465fKcRMo5bp"}},{"cell_type":"code","source":["# lets try passing in the example sequence above to an LSTM layer and view what the output is\n","\n","# single batch containing a single sample with a sequence length of 4 \n","# and an embedding dimension of 6 \n","test_embedding = np.array([[[1, 2, 3, 4, 5, 6],\n","                            [7, 8, 9, 10, 11, 12],\n","                            [13, 14, 15, 16, 17, 18],\n","                            [19, 20, 21, 22, 23, 24]]], dtype=np.float32)\n","LSTM_test_2 = tf.keras.layers.LSTM(2)\n","\n","test_sequence_output = LSTM_test_2(test_embedding)\n","print(\"Results: {}\".format(test_sequence_output))\n"],"metadata":{"id":"ypDvm68T0QsF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658575650468,"user_tz":-60,"elapsed":851,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"038c1965-3ede-4f7f-9ba5-8ba1f14ec55f"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Results: [[-9.9916792e-01 -1.8543489e-16]]\n"]}]},{"cell_type":"markdown","source":["**LSTM with go backwards set to True. This would process the sequence backwards and return the reversed sequence**"],"metadata":{"id":"cJDRhKCNzqe3"}},{"cell_type":"code","source":["# set go_backwards to True\n","LSTM_test_3 = tf.keras.layers.LSTM(2, go_backwards=True)\n","\n","test_sequence_output_1 = LSTM_test_3(test_embedding)\n","\n","print(\"Results: {}\".format(test_sequence_output_1))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lu9JDaxe0KcB","executionInfo":{"status":"ok","timestamp":1658575654199,"user_tz":-60,"elapsed":3,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"21a58a31-5d38-45d4-a762-ebdee0e9e77d"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Results: [[0.08762532 0.00098983]]\n"]}]},{"cell_type":"markdown","source":["**LSTM with return state set to True. Returns the last state in addition to the output and the internal cell state**"],"metadata":{"id":"eD2ggBrS1pip"}},{"cell_type":"code","source":["# set return state to True\n","LSTM_test_5 = tf.keras.layers.LSTM(2, return_state=True)\n","\n","Ouput, final_hidden_cell_state, final_internal_cell_state = LSTM_test_5(test_embedding)\n","\n","print(\"Final output: \\n{}\".format(Ouput))\n","print(\"\\nFinal hidden cell state: \\n{}\".format(final_hidden_cell_state))\n","print(\"\\nFinal internal cell state: \\n{}\".format(final_internal_cell_state))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cm-CyqOi3XY3","executionInfo":{"status":"ok","timestamp":1658576568537,"user_tz":-60,"elapsed":516,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"1460bbef-f1f4-4167-d65c-d0bde5529b62"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Final output: \n","[[ 0.5078768  -0.99681455]]\n","\n","Final hidden cell state: \n","[[ 0.5078768  -0.99681455]]\n","\n","Final internal cell state: \n","[[ 0.55986565 -3.22036   ]]\n"]}]},{"cell_type":"markdown","source":["### **A quick note on the dimensions.**\n","\n","For  a given input dimension [X, Y, Z]. X would be the batch dimension and determines the number of initial element in the array. So if\n","- X = 2 we would have an array containing 2 elements. $[1, 2]$\n","- X = 5, we would have 5 elements in the array. $[1, 2, 3, 4, 5]$\n","\n","The next dimension Y would determine the number of element within the initial set of elements. so if our dimensions are\n","- [1, 2, Z], we would have an array structured like this $[ [[], []] ]$\n","Admittedly it looks confusing, but the array would contain a single element, which in turn contains 2 elements.\n","\n","stacking that further, the 3rd dimension determines the number of elements within the last set. For example an array with a dimension of\n","\n","- [1, 2, 3] could like this, [[[1, 2, 3], [4, 5, 6]]]\n","- [3, 4, 6] could look like this \n","\n","```\n","[[[1, 2, 3, 4, 5, 6], [7, 8, 9, 10, 11, 12], [13, 14, 15, 16, 17, 18], [19, 20, 21, 22, 23, 24]],\n","[[11, 12, 13, 14, 15, 16], [17, 18, 19, 20, 21, 22], [23, 24, 25, 26, 27, 28], [29, 30, 31, 32, 33, 24]],\n","[[21, 22, 23, 24, 25, 26], [27, 28, 29, 30, 31, 32], [33, 34, 35, 36, 37, 38], [39, 40, 41, 42, 43, 44]]]\n","```\n","\n"],"metadata":{"id":"CgITAORytyNU"}},{"cell_type":"markdown","source":["### **Using the GRU layer**\n","Link to documentation: https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU\n","\n","Some noes from the documentation\n","- 2 variants of GRU implementation\n","  - v3 of the GRU, which has it's reset gate applied to the hidden state before matrix multiplication.\n","  - initial GRU implementation, which has the reset gate applied to the hidden state after matrix multiplication. (Only compatible with GPU enabled devices)\n","\n"],"metadata":{"id":"WKQwXifdu55s"}},{"cell_type":"markdown","source":["**SimpleGRU**"],"metadata":{"id":"IML-71QP8Rgk"}},{"cell_type":"code","source":["# taken from the documentation example\n","\n","# Define a batch containing 5 samples, each with a length of 4 and an embedding\n","# dimension of 3\n","fake_embedding = tf.random.normal([5, 4, 3])\n","Simple_GRU_layer_0 = tf.keras.layers.GRU(units=4)\n","\n","Simple_GRU_layer_0_output = Simple_GRU_layer_0(fake_embedding)\n","print(f\"Fake embedding: \\n {fake_embedding}\")\n","print(f\"\\n Output of simple GRU layer:\\n {Simple_GRU_layer_0_output}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Z0PvdMY5Vt_","executionInfo":{"status":"ok","timestamp":1658578471208,"user_tz":-60,"elapsed":609,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"1c10242e-20f6-4433-b431-e8cd480d271d"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Fake embedding: \n"," [[[ 0.02024975 -0.5242584   0.41571057]\n","  [-0.54333377 -0.1240209  -1.0034183 ]\n","  [ 1.548015   -1.1159978   0.69902265]\n","  [-0.01268816  1.304217    1.0540898 ]]\n","\n"," [[ 0.4442007  -0.27238685  1.398242  ]\n","  [-0.5863187   0.79228     1.1279312 ]\n","  [ 0.14102115  0.5674381   0.7040402 ]\n","  [-0.95412934 -0.04099366  1.5230407 ]]\n","\n"," [[-1.0843962   1.3383615   0.8556613 ]\n","  [-0.32472858  1.8674307   0.7401377 ]\n","  [-1.2507063   0.5137581  -1.6594754 ]\n","  [ 0.50820273 -0.5033321   0.49034518]]\n","\n"," [[-1.3087839   0.7153914  -0.23905785]\n","  [-0.78726137 -1.8308866  -0.03049529]\n","  [ 1.9921625  -0.18866095  1.0221355 ]\n","  [-0.19604047 -1.2710748   0.6273832 ]]\n","\n"," [[-0.15179242 -0.38491833  0.33628368]\n","  [-1.0579001  -0.03693665 -0.46901795]\n","  [ 1.145693   -0.4075045  -0.8039029 ]\n","  [-0.59372663  0.3016597  -0.4172142 ]]]\n","\n"," Output of simple GRU layer:\n"," [[-0.2949918  -0.0547712  -0.02378956 -0.16269396]\n"," [-0.56058127 -0.19093616  0.16273935 -0.6636913 ]\n"," [-0.05660305  0.12945607  0.11812124  0.10879359]\n"," [-0.24801932 -0.4632343   0.5425491  -0.10810438]\n"," [ 0.11448577  0.23570038 -0.11392375  0.2992285 ]]\n"]}]},{"cell_type":"markdown","source":["The output of the GRU layer containing 4, for a batch containing 5 samples."],"metadata":{"id":"YipOg3uB-x2j"}},{"cell_type":"markdown","source":["**Simple GRU layer with return state set to True**"],"metadata":{"id":"ynYAKpoS_BVd"}},{"cell_type":"code","source":["# just for bants, i'll try to pass a batch containing 2 samples, each with a embedding dimension of 5, but with different lengths\n","\n","Simple_GRU_layer_1 = tf.keras.layers.GRU(units=4, return_state=True)\n","\n","try:\n","  fake_embedding = np.array([[[1, 2, 3, 4, 5], [6, 7, 8, 9, 10],\n","                            [11, 12, 13, 14, 15]],\n","                            [20, 21, 22, 23, 24]], dtype=np.float32)\n","  \n","  Simple_GRU_layer_1_output = Simple_GRU_layer_1(fake_embedding)\n","\n","except Exception as e:\n","  print(f\"Error: {e}\")\n","  fake_embedding = np.array([[[1, 2, 3, 4, 5], [6, 7, 8, 9, 10],\n","                            [11, 12, 13, 14, 15]],\n","                            [[20, 21, 22, 23, 24], [25, 26, 27, 28, 29],\n","                            [30, 31, 32, 33, 34]]], dtype=np.float32)\n","  \n","  Simple_GRU_layer_1_output, Simple_GRU_layer_1_state = Simple_GRU_layer_1(fake_embedding)\n","\n","print(f\"\\nFake embedding: \\n {fake_embedding}\")\n","print(f\"\\n Output of simple GRU layer:\\n {Simple_GRU_layer_1_output}\")\n","print(f\"\\n Simple GRU layer final cell state:\\n {Simple_GRU_layer_1_state}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2nDTeSQT_H9a","executionInfo":{"status":"ok","timestamp":1658579107442,"user_tz":-60,"elapsed":9,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"08e51308-70da-4e34-92c7-a24b2db7b545"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Error: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.\n","\n","Fake embedding: \n"," [[[ 1.  2.  3.  4.  5.]\n","  [ 6.  7.  8.  9. 10.]\n","  [11. 12. 13. 14. 15.]]\n","\n"," [[20. 21. 22. 23. 24.]\n","  [25. 26. 27. 28. 29.]\n","  [30. 31. 32. 33. 34.]]]\n","\n"," Output of simple GRU layer:\n"," [[ 1.5408228e-01  9.9987435e-01  2.8782127e-02 -1.4678789e-02]\n"," [ 7.1525574e-07  1.0000000e+00 -1.9500955e-04  1.6018833e-04]]\n","\n"," Simple GRU layer final cell state:\n"," [[ 1.5408228e-01  9.9987435e-01  2.8782127e-02 -1.4678789e-02]\n"," [ 7.1525574e-07  1.0000000e+00 -1.9500955e-04  1.6018833e-04]]\n"]}]},{"cell_type":"markdown","source":["Consistent with the previous trend, the final hidden cell state is the same output of the GRU layer"],"metadata":{"id":"IhYWYyYzBODA"}},{"cell_type":"markdown","source":["So far it seems the hidden cell state is the same as the output of the RNN layer, with only the LSTM layer providing an additional internal cell state. I don't think there would be any benefit in going through the process of viewing the output for return_sequences and go_backwards set to True.\n"," "],"metadata":{"id":"lWwt4mbcBY5F"}},{"cell_type":"markdown","source":["## **Summay on RNNs**\n","\n","**SimpleRNN**   \n","SimpleRNN are the basic implementation of RNN which feature recurrent connections in which the outputs from previous time steps are fed back in as additional inputs for the next time steps.\n","\n","While simpleRNN are able to capture temporal relations in sequential data, the range in which it is able to retain this temporal relationship is limited. It is good at retaining only the latest information and not earlier information. So informaton introduced at the begining of long sequences are eroded after multiple time steps.\n","\n","Similarly it suffers vanishing gradient for lon sequential data in which the gradients propagated from the start decay after multiple backwards pass that earlier cells are unable to learn anything.\n","\n","<br>\n","\n","**LSTMS and GRU**   \n","The limitations of simpleRNNs were addressed in LSTMs and GRU, which feature recurrent gated connections. LSTMs and GRU operate in the same way as simpleRNN, in the sense that it uses the previous output is used as additional inputs for the current input.   \n","\n","Unlike simpleRNN, gated connections are used determine how the previous output is used (what to retain/forget) and how to combine the previous output with the current input.   \n","\n","The difference between LSTMS and GRU are in the number of gate connections used and state vectors produced at each time step. LSTM are computationally much more expensive and take longer to train, but they are much more suited to larger datasets with longer sequences. GRU in comparison, require less parameters to update and are quicker to train.\n","\n","<br>\n","\n","**Note**\n","- I have some issues with the functionality of each gate in the LSTM and GRU, might be something to address again later. But above i have tried to describe their functionality without going into details on the individual gates.\n","\n","<br>\n","\n","**Using RNNs in Tensorflow**\n","- There are multiple options in tensorflow, that allow you to define the behaviour of the layer and it's output.\n","- The input to RNN layers are typically the output of the embedding layers. The output of the embedding can be passed directly without needing the flatten or globalaverage pooling layers.\n","- Using return_sequence, returns the RNN output for each token in the sequence, this is useful when stacking multiple RNN layers together in a network.\n","- Using return_state, would return the final state (states for LSTM) of the RNN layer. The final states can then be used as initial states for the next RNN layer in more complex architecture\n","- Other features like go_backwards, dropout, recurrent_dropout, stateful and unroll exist to control the behaviour of an RNN layers. (check out the docs)\n","\n"],"metadata":{"id":"XLHkb3w3CP6c"}},{"cell_type":"markdown","source":["### **Using Conv1D Layers**\n"],"metadata":{"id":"jkS4IW17preW"}}]}