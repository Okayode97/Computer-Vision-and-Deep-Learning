{"cells":[{"cell_type":"markdown","metadata":{"id":"z68tEydbgOja"},"source":["# **Third Attempt at generating text using RNN**\n","\n","So far i've tried to generate shakespeare like text using Tensorflow. ith my first few attempts i went of the Udacity course and tried to train my own model to perfom text generation. I didn't get very far as the models i tried to train were far to complex and i saw very little results. Following the guide on tensorflow, the trained model was far simplier and was successfully trained.\n","\n","I thought i'd give it another go at training my own text generation model/Something a bit intresting...\n","\n","Text Generation Model trained on [Anime Quotes](https://www.kaggle.com/datasets/tarundalal/anime-quotes)\n","\n","\n","P.s\n","I'm most likely going to steal some stuff from both the Udacity and Tensorflow guide"]},{"cell_type":"markdown","metadata":{"id":"WdSvTrv9oo-3"},"source":["# **Import Dependencies**"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8723,"status":"ok","timestamp":1660511885153,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"},"user_tz":-60},"id":"GVYvO1grgFsK","outputId":"773a5b41-edcf-4bc8-db43-8844c0b457a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.8.2\n"]}],"source":["import tensorflow as tf\n","import numpy as np\n","import urllib.request\n","import csv\n","\n","print(tf.__version__)\n"]},{"cell_type":"markdown","metadata":{"id":"0momWAi_pjQj"},"source":["# **Download the dataset**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"WpDxBph2pBb4"},"outputs":[],"source":["# i downloaded the dataset from this link\n","url = \"https://www.kaggle.com/datasets/tarundalal/anime-quotes/download?datasetVersionNumber=1\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MVth_xV8ye0U"},"outputs":[],"source":["!pwd"]},{"cell_type":"markdown","metadata":{"id":"so1lJZj6zneg"},"source":["Extracted the csv file and loaded it into the contents folder"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":320,"status":"ok","timestamp":1660511890057,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"},"user_tz":-60},"id":"7zlvR_RTztBa","outputId":"9460b5ae-7fee-4fd9-d15d-676a84443880"},"outputs":[{"output_type":"stream","name":"stdout","text":["['Quote', 'People’s lives don’t end when they die, it ends when they lose faith.', 'If you don’t take risks, you can’t create a future!', 'If you don’t like your destiny, don’t accept it.', 'When you give up, that’s when the game ends.', 'All we can do is live until the day we die. Control what we can…and fly free.', 'Forgetting is like a wound. The wound may heal, but it has already left a scar.', 'It’s just pathetic to give up on something before you even give it a shot.”', 'If you don’t share someone’s pain, you can never understand them.', 'Whatever you lose, you’ll find it again. But what you throw away you’ll never get back.']\n"]}],"source":["# read the csvfile\n","anime_quotes = []\n","\n","# the csv file contains Quote, character, Anime. For this task we are only\n","# interested in the quote so we would only get the first column from each row.\n","with open('AnimeQuotes.csv') as csv_file:\n","  csv_reader = csv.reader(csv_file, delimiter=',')\n","  for row in csv_reader:\n","    anime_quotes.append(row[0])\n","\n","print(anime_quotes[:10])\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1660511892386,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"},"user_tz":-60},"id":"yo3DdZdf0zqK","outputId":"7a4f3c87-82b7-49ee-9195-b7677769a892"},"outputs":[{"output_type":"stream","name":"stdout","text":["['People’s lives don’t end when they die, it ends when they lose faith.', 'If you don’t take risks, you can’t create a future!', 'If you don’t like your destiny, don’t accept it.', 'When you give up, that’s when the game ends.', 'All we can do is live until the day we die. Control what we can…and fly free.', 'Forgetting is like a wound. The wound may heal, but it has already left a scar.', 'It’s just pathetic to give up on something before you even give it a shot.”', 'If you don’t share someone’s pain, you can never understand them.', 'Whatever you lose, you’ll find it again. But what you throw away you’ll never get back.', 'We don’t have to know what tomorrow holds! That’s why we can live for everything we’re worth today!”']\n","121\n"]}],"source":["# remove the header\n","anime_quotes = anime_quotes[1:]\n","\n","print(anime_quotes[:10])\n","print(len(anime_quotes))\n"]},{"cell_type":"markdown","metadata":{"id":"sKSlbYTX1C1B"},"source":["# **Prepare the text**\n","\n","The main task is here is to be able to generate anime quotes from our own seed text. Towards this we need, a set of feature and labels to train the model on.\n","\n","<br>\n","\n","**Set features and labels**   \n","The feature and labels need to reflect the task, so the feature should be a set of initial text and the label should be the next set of text.\n","\n","From what i've seen there are 2 ways we can approach this, we can create a model which Predicts the next char or predicts the next word. I'll try out the differmt methods to prepare the text\n","- Predicting next char \n","- Predicting the next probable word\n","\n","\n","In this collab i'll generate a model to predict the next probable char.\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":587,"status":"ok","timestamp":1660511896050,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"},"user_tz":-60},"id":"gfuzrYg50_hP","outputId":"fc26dfd3-96ca-4c9f-dcc8-c3d86533eef3"},"outputs":[{"output_type":"stream","name":"stdout","text":["People’s lives don’t end when they die, it ends when they lose faith. If you don’t take risks, you can’t create a future! If you don’t like your destiny, don’t accept it. When you give up, that’s when the game ends. All we can do is live until the day we die. Control what we can…and fly free. Forgetting is like a wound. The wound may heal, but it has already left a scar. It’s just pathetic to give up on something before you even give it a shot.” If you don’t share someone’s pain, you can never understand them. Whatever you lose, you’ll find it again. But what you throw away you’ll never get back. We don’t have to know what tomorrow holds! That’s why we can live for everything we’re worth today!” Why should I apologize for being a monster? Has anyone ever apologized for turning me into one? People become stronger because they have memories they can’t forget. I’ll leave tomorrow’s problems to tomorrow’s me. If you wanna make people dream, you’ve gotta start by believing in that dream yourself! Being lonely is more painful then getting hurt. There’s no shame in falling down! True shame is to not stand up again! Simplicity is the easiest path to true beauty. If you can’t do something, then don’t. Focus on what you can. Giving up kills people. When people reject giving up… they finally win the right to transcend humanity. You can die anytime, but living takes true courage.” Every journey begins with a single step. We just have to have patience. It doesn’t do any good to pretend you can’t see what’s going on. Being weak is nothing to be ashamed of… Staying weak is !! To act is not necessarily compassion. True compassion sometimes comes from inaction. A dropout will beat a genius through hard work. Reject common sense to make the impossible possible. Whatever you lose, you’ll find it again. But what you throw away you’ll never get back. If you really want to be strong… Stop caring about what your surrounding thinks of you! Vision is not what your eyes see, but an image that your brain comprehends. Sometimes, people are just mean. Don’t fight mean with mean. Hold your head high. The ticket to the future is always open. Hard work is worthless for those that don’t believe in themselves. A place where someone still thinks about you is a place you can call home. Life comes at a cost. Wouldn’t it be arrogant to die before you’ve repaid that debt? You can die anytime, but living takes true courage. Every journey begins with a single step. We just have to have patience. If you just submit yourself to fate, then that’s the end of it.” It is at the moment of death that humanity has value. People, who can’t throw something important away, can never hope to change anything. Whatever you do, enjoy it to the fullest. That is the secret of life.” Power comes in response to a need, not a desire. You have to create that need. There are no regrets. If one can be proud of one’s life, one should not wish for another chance.” You can’t always hold on to the things that are important. By letting them go we gain something else.” If you don’t like your destiny, don’t accept it. Instead, have the courage to change it the way you want it to be. Don’t beg for things. Do it yourself, or else you won’t get anything. I refuse to let my fear control me anymore.” If you can’t find a reason to fight, then you shouldn’t be fighting.” You should never give up on life, no matter how you feel. No matter how badly you want to give up.” People who can’t throw something important away, can never hope to change anything. We can’t waste time worrying about the what if’s.” Fools who don’t respect the past are likely to repeat it. That’s why I can’t make a change. Everything I do is so… Half-assed.” Sometimes it’s necessary to do unnecessary things. An excellent leader must be passionate because it’s their duty to keep everyone moving forward. Protecting someone means giving them a place to belong. Giving them a place where they can be happy. Thinking you’re no-good and worthless is the worst thing you can do Sometimes I do feel like I’m a failure. Like there’s no hope for me. But even so, I’m not gonna give up. Ever!” If you can’t do something, then don’t. Focus on what you can do.” When you lose sight of your path, listen for the destination in your heart. The moment you think of giving up, think of the reason why you held on so long.” Don’t give up, there’s no shame in falling down! True shame is to not stand up again! No matter how hard or impossible it is, never lose sight of your goal.” Life is not a game of luck. If you wanna win, work hard. The world isn’t perfect. But it’s there for us, doing the best it can….that’s what makes it so damn beautiful. Fear is not evil. It tells you what your weakness is. And once you know your weakness, you can become stronger as well as kinder. To know sorrow is not terrifying. What is terrifying is to know you can’t go back to happiness you could have. Knowing you’re different is only the beginning. If you accept these differences you’ll be able to get past them and grow even closer. Don’t be so quick to throw away your life. No matter how disgraceful or embarrassing it may be, you need to keep struggling to find your way out until the very end. The world’s not perfect, but it’s there for us trying the best it can. That’s what makes it so damn beautiful. We are all like fireworks: we climb, we shine and always go our separate ways and become further apart. But even when that time comes, let’s not disappear like a firework and continue to shine.. forever. If nobody cares to accept you and wants you in this world, accept yourself and you will see that you don’t need them and their selfish ideas. When you hit the point of no return, that’s the moment it truly becomes a journey. If you can still turn back, it’s not really a journey. Those who stand at the top determine what’s wrong and what’s right! This very place is neutral ground! Justice will prevail, you say? But of course it will! Whoever wins this war becomes justice! A person grows up when he’s able to overcome hardships. Protection is important, but there are some things that a person must learn on his own. Who decides limits? And based on what? You said you worked hard? Well, maybe you need to work a little harder. Is that really the limit of your strength? Could you of tomorrow beat you today? Instead of giving in, move forward. Mistakes are not shackles that halt one from stepping forward. Rather, they are that which sustain and grow one’s heart. Fear is freedom! Subjugation is liberation! Contradiction is the truth! Those are the facts of this world! And you will all surrender to them, you pigs in human clothing! Hatred and Sorrow are power. They are yours to control. All you have to do is to turn them into strength and use that strength to move forward. It’s not always possible to do what we want to do, but it’s important to believe in something before you actually do it. Life and death are like light and shadow. They’re both always there. But people don’t like thinking about death, so subconsciously, they always look away from it. It’s more important to master the cards you’re holding than to complain about the ones your opponent was dealt.” I am the hope of the universe. I am the answer to all living things that cry out for peace. I am the protector of the innocent. I am the light in the darkness. I am the truth. Ally to good! Nightmare to you! If you’re gonna insist on gambling and then complain when you lose, you had better work on your game.” Moving on doesn’t mean you forget about things. It just means you have to accept what’s happened and continue living. If nobody cares to accept you and wants you in this world, accept yourself and you will see that you don’t need them and their selfish ideas. If you keep on hiding your true feelings, who is going to be happy? If you are sad, you should say it out loud! Religion, ideology, resources, land, spite, love or just because… No matter how pathetic the reason, it’s enough to start a war. War will never cease to exist… reasons can be thought up after the fact… Human nature pursues strife. Don’t be upset because of what you can’t do. Do what you do best, live as carefree and optimistically as you can, because some people aren’t able to do that. If you begin to regret, you’ll dull your future decisions and let others make your choices for you. All that’s left for you then is to die. Nobody can foretell the outcome. Each decision you make holds meaning only by affecting your next decision. Everything has a beginning and an end. Life is just a cycle of starts and stops. There are ends we don’t desire, but they’re inevitable, we have to face them. It’s what being human is all about. Anything can happen. No one ever thinks it will until it does. What will happen, happens. That’s how the world is. The most important thing is to not let the tragedy defeat you. To believe that you can get through it. You’ll only realize that you truly love someone if they already caused you enormous pain. Your enemies can never hurt you the way your loved ones can. It’s the people close to your heart that can give you the most piercing wound. Love is a double-edged sword, it can heal the wound faster or it can sink the blade even deeper. I want you to be happy. I want you to laugh a lot. I don’t know what exactly I’ll be able to do for you, but I’ll always be by your side. “A lesson without pain is meaningless. That’s because no one can gain without sacrificing something. But by enduring that pain and overcoming it, he shall obtain a powerful, unmatched heart.” You need to accept the fact that you’re not the best and have all the will to strive to be better than anyone you face. I too will obtain everything that I desire. Not because someone asked me to do it, but because I know in my heart that I have something worth fighting for. You can’t win a game by doing nothing. And if someone else wins it for you then you haven’t accomplished anything. Life is the same way. Do not think about other things, there is only one thing you can do. So master that one thing. Do not forget. What you must imagine is always that you, yourself, are the strongest. You do not need outside enemies. For you, the one you have to fight is none other than your own image. Life is like a tube of toothpaste. When you’ve used all the toothpaste down to the last squeeze, that’s when you’ve really lived. Live with all your might, and struggle as long as you have life.” Just like games, no matter how well you have things lined up in your life, there’s always something to keep you on your toes. Do exactly as you like. That is the true meaning of pleasure. Pleasure leads to joy and joy leads to happiness. It Doesn t Matter How Strong The Opposition Is It Doesn t Matter How Fearsome The World Is It Doesn t Matter How Cruel The World Is Fight If There Are Humans Who Can Bring About Change They re Those Who Are Capable Of Abandoning Everything People Who When Required To Surpass Even Monsters Are Capable Of Tossing Aside Their Very Humanity I Don t Like The Terms Good Person or Bad Person It Is Impossible To Be Entirely Good To Everyone To Some You Are A Good Person While To Others You Are A Bad Person As Long As We Continue To Fight We Are Not Defeated If You Win You Live If You Lose You Die If You Don t Fight You Can t Win You Understand Don t You One Day Or Another Everyone You Care About Eventually Dies It s Something We Simply Can t Accept It s A Realization That Could Drive You Insane You re Gonna Care What Other People Think And Be Someone You re Not Your Whole Life You re Fine As You Are So Talk In Your Own Words Everyone Had To Be Drunk On Somethin To Keep Pushing On Everyone Was A Slave To Somethin This World Is Cruel And It s Also Very Beautiful No One Knows What The Outcome Will Be So Choose Whatever You ll Regret The Least Do you need a reason to not want to lose Being the best decoy ever is as cool as being the ace You can fly even higher If they adjust to me I have to adjust in turn Whoever stops adjusting won t be able to continue forward The last ones standing are the victors Only the strongest If you want to be the last one standing become strong Life s a bore if you don t challenge yourself There are some flowers you only see when you take detours Being weak means that there is room to grow Today might be the chance to grasp the chance to let your talent bloom If you re gonna hit it hit it until it breaks\n","Unique_chars: {'P', '“', 'I', 'W', 'U', 'F', 'M', 'Y', 'e', 'b', '’', 's', 'B', '\\xa0', 'R', '”', 'N', 'i', 'y', 'm', '?', '.', 'z', 'E', 'V', 'D', 'u', 'f', '…', '-', 'n', 't', 'T', 'o', 'k', 'r', 'A', 'l', '!', 'j', 'H', 'g', 'G', 'L', 'p', 'c', 'x', 'q', ' ', 'O', 'v', ':', 'J', 'h', ',', 'K', 'a', 'S', 'd', 'C', 'w'}\n","Total number of charachthers in all_anime_quotes: 12501\n","Vocabulary size: 61\n"]}],"source":["# combine the contents of the list into a single string\n","all_anime_quotes = \" \".join(anime_quotes)\n","\n","\n","num_char = len(all_anime_quotes)\n","unique_chars = set(all_anime_quotes)\n","vocab_size = len(unique_chars)\n","\n","print(all_anime_quotes)\n","print(f\"Unique_chars: {unique_chars}\")\n","print(f\"Total number of charachthers in all_anime_quotes: {num_char}\")\n","print(f\"Vocabulary size: {vocab_size}\")\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":276,"status":"ok","timestamp":1660511898583,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"},"user_tz":-60},"id":"Sqn17d-myaUP","outputId":"934bd0ab-ffd4-4234-ca80-e1e90854d4da"},"outputs":[{"output_type":"stream","name":"stdout","text":["[' ', '!', ',', '-', '.', ':', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\xa0', '’', '“', '”', '…']\n"]}],"source":["print(sorted(unique_chars))\n"]},{"cell_type":"markdown","metadata":{"id":"jllGdi09yySc"},"source":["To recap the steps we are going to take for the text generation model.\n","\n","**Preparing the text**\n","- We are going to perform tokenization on each individual chars to convert them into tokens\n","- From the tokens we would then create sequences. We would create sequences of length 100 which would be our feature. Our label would be our sequence shifted one way to the right.\n","\n","**Model training**\n","- We would then train an RNN model on the features and labels.\n","\n","**Text generation**\n","- We would then generate a text from a seed word using the trained model"]},{"cell_type":"markdown","metadata":{"id":"RMgPRcuR0giW"},"source":["define a function to map the char into tokens."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":439,"status":"ok","timestamp":1660511902661,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"},"user_tz":-60},"id":"xugQEAIMyk_R","outputId":"bbf9013d-1763-4347-a31b-bc82576e3431"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'P': 0, '“': 1, 'I': 2, 'W': 3, 'U': 4, 'F': 5, 'M': 6, 'Y': 7, 'e': 8, 'b': 9, '’': 10, 's': 11, 'B': 12, '\\xa0': 13, 'R': 14, '”': 15, 'N': 16, 'i': 17, 'y': 18, 'm': 19, '?': 20, '.': 21, 'z': 22, 'E': 23, 'V': 24, 'D': 25, 'u': 26, 'f': 27, '…': 28, '-': 29, 'n': 30, 't': 31, 'T': 32, 'o': 33, 'k': 34, 'r': 35, 'A': 36, 'l': 37, '!': 38, 'j': 39, 'H': 40, 'g': 41, 'G': 42, 'L': 43, 'p': 44, 'c': 45, 'x': 46, 'q': 47, ' ': 48, 'O': 49, 'v': 50, ':': 51, 'J': 52, 'h': 53, ',': 54, 'K': 55, 'a': 56, 'S': 57, 'd': 58, 'C': 59, 'w': 60}\n"]}],"source":["# define a dictionary to map the char into token\n","char_to_token = dict([(char, token) for token, char in enumerate(unique_chars)])\n","print(char_to_token)\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1660511903133,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"},"user_tz":-60},"id":"nz6bPXXj2EO7","outputId":"a46c2079-6986-4ae8-e596-74ee8a306c7a"},"outputs":[{"output_type":"stream","name":"stdout","text":["{0: 'P', 1: '“', 2: 'I', 3: 'W', 4: 'U', 5: 'F', 6: 'M', 7: 'Y', 8: 'e', 9: 'b', 10: '’', 11: 's', 12: 'B', 13: '\\xa0', 14: 'R', 15: '”', 16: 'N', 17: 'i', 18: 'y', 19: 'm', 20: '?', 21: '.', 22: 'z', 23: 'E', 24: 'V', 25: 'D', 26: 'u', 27: 'f', 28: '…', 29: '-', 30: 'n', 31: 't', 32: 'T', 33: 'o', 34: 'k', 35: 'r', 36: 'A', 37: 'l', 38: '!', 39: 'j', 40: 'H', 41: 'g', 42: 'G', 43: 'L', 44: 'p', 45: 'c', 46: 'x', 47: 'q', 48: ' ', 49: 'O', 50: 'v', 51: ':', 52: 'J', 53: 'h', 54: ',', 55: 'K', 56: 'a', 57: 'S', 58: 'd', 59: 'C', 60: 'w'}\n"]}],"source":["# create a dictionary with inverted mapping\n","token_to_char = dict([(token, char) for char, token in char_to_token.items()])\n","print(token_to_char)\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":429,"status":"ok","timestamp":1660511905964,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"},"user_tz":-60},"id":"qREa44q33EN1","outputId":"313ed0d9-3338-4805-ee06-ac465e83f66f"},"outputs":[{"output_type":"stream","name":"stdout","text":["A has token 36\n","36 represents A\n"]}],"source":["# Sanity check\n","print(f\"A has token {char_to_token['A']}\")\n","print(f\"{char_to_token['A']} represents {token_to_char[char_to_token['A']]}\")\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":799,"status":"ok","timestamp":1660511908539,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"},"user_tz":-60},"id":"aWNWsFqL2vM8","outputId":"f9637638-80cd-4b5b-a5ce-3f72a2535245"},"outputs":[{"output_type":"stream","name":"stdout","text":["[0, 8, 33, 44, 37, 8, 10, 11, 48, 37, 17, 50, 8, 11, 48, 58, 33, 30, 10, 31, 48, 8, 30, 58, 48, 60, 53, 8, 30, 48, 31, 53, 8, 18, 48, 58, 17, 8, 54, 48, 17, 31, 48, 8, 30, 58, 11, 48, 60, 53, 8, 30, 48, 31, 53, 8, 18, 48, 37, 33, 11, 8, 48, 27, 56, 17, 31, 53, 21, 48, 2, 27, 48, 18, 33, 26, 48, 58, 33, 30, 10, 31, 48, 31, 56, 34, 8, 48, 35, 17, 11, 34, 11, 54, 48, 18, 33, 26, 48, 45, 56, 30, 10, 31, 48, 45, 35, 8, 56, 31, 8, 48, 56, 48, 27, 26, 31, 26, 35, 8, 38, 48, 2, 27, 48, 18, 33, 26, 48, 58, 33, 30, 10, 31, 48, 37, 17, 34, 8, 48, 18, 33, 26, 35, 48, 58, 8, 11, 31, 17, 30, 18, 54, 48, 58, 33, 30, 10, 31, 48, 56, 45, 45, 8, 44, 31, 48, 17, 31, 21, 48, 3, 53, 8, 30, 48, 18, 33, 26, 48, 41, 17, 50, 8, 48, 26, 44, 54, 48, 31, 53, 56, 31, 10, 11, 48, 60, 53, 8, 30, 48, 31, 53, 8, 48, 41, 56, 19, 8, 48, 8, 30, 58, 11, 21, 48, 36, 37, 37, 48, 60, 8, 48, 45, 56, 30, 48, 58, 33, 48, 17, 11, 48, 37, 17, 50, 8, 48, 26, 30, 31, 17, 37, 48, 31, 53, 8, 48, 58, 56, 18, 48, 60, 8, 48, 58, 17, 8, 21, 48, 59, 33, 30, 31, 35, 33, 37, 48, 60, 53, 56, 31, 48, 60, 8, 48, 45, 56, 30, 28, 56, 30, 58, 48, 27, 37, 18, 48, 27, 35, 8, 8, 21, 48, 5, 33, 35, 41, 8, 31, 31, 17, 30, 41, 48, 17, 11, 48, 37, 17, 34, 8, 48, 56, 48, 60, 33, 26, 30, 58, 21, 48, 32, 53, 8, 48, 60, 33, 26, 30, 58, 48, 19, 56, 18, 48, 53, 8, 56, 37, 54, 48, 9, 26, 31, 48, 17, 31, 48, 53, 56, 11, 48, 56, 37, 35, 8, 56, 58, 18, 48, 37, 8, 27, 31, 48, 56, 48, 11, 45, 56, 35, 21, 48, 2, 31, 10, 11, 48, 39, 26, 11, 31, 48, 44, 56, 31, 53, 8, 31, 17, 45, 48, 31, 33, 48, 41, 17, 50, 8, 48, 26, 44, 48, 33, 30, 48, 11, 33, 19, 8, 31, 53, 17, 30, 41, 48, 9, 8, 27, 33, 35, 8, 48, 18, 33, 26, 48, 8, 50, 8, 30, 48, 41, 17, 50, 8, 48, 17, 31, 48, 56, 48, 11, 53, 33, 31, 21, 15, 48, 2, 27, 48, 18, 33, 26, 48, 58, 33, 30, 10, 31, 48, 11, 53, 56, 35, 8, 48, 11, 33, 19, 8, 33, 30, 8, 10, 11, 48, 44, 56, 17, 30, 54, 48, 18, 33, 26, 48, 45, 56, 30, 48, 30, 8, 50, 8, 35, 48, 26, 30, 58, 8, 35, 11, 31, 56, 30, 58, 48, 31, 53, 8, 19, 21, 48, 3, 53, 56, 31, 8, 50, 8, 35, 48, 18, 33, 26, 48, 37, 33, 11, 8, 54, 48, 18, 33, 26, 10, 37, 37, 48, 27, 17, 30, 58, 48, 17, 31, 48, 56, 41, 56, 17, 30, 21, 48, 12, 26, 31, 48, 60, 53, 56, 31, 48, 18, 33, 26, 48, 31, 53, 35, 33, 60, 48, 56, 60, 56, 18, 48, 18, 33, 26, 10, 37, 37, 48, 30, 8, 50, 8, 35, 48, 41, 8, 31, 48, 9, 56, 45, 34, 21, 48, 3, 8, 48, 58, 33, 30, 10, 31, 48, 53, 56, 50, 8, 48, 31, 33, 48, 34, 30, 33, 60, 48, 60, 53, 56, 31, 48, 31, 33, 19, 33, 35, 35, 33, 60, 48, 53, 33, 37, 58, 11, 38, 48, 32, 53, 56, 31, 10, 11, 48, 60, 53, 18, 48, 60, 8, 48, 45, 56, 30, 48, 37, 17, 50, 8, 48, 27, 33, 35, 48, 8, 50, 8, 35, 18, 31, 53, 17, 30, 41, 48, 60, 8, 10, 35, 8, 48, 60, 33, 35, 31, 53, 48, 31, 33, 58, 56, 18, 38, 15, 48, 3, 53, 18, 48, 11, 53, 33, 26, 37, 58, 48, 2, 48, 56, 44, 33, 37, 33, 41, 17, 22, 8, 48, 27, 33, 35, 48, 9, 8, 17, 30, 41, 48, 56, 48, 19, 33, 30, 11, 31, 8, 35, 20, 48, 40, 56, 11, 48, 56, 30, 18, 33, 30, 8, 48, 8, 50, 8, 35, 48, 56, 44, 33, 37, 33, 41, 17, 22, 8, 58, 48, 27, 33, 35, 48, 31, 26, 35, 30, 17, 30, 41, 48, 19, 8, 48, 17, 30, 31, 33, 48, 33, 30, 8, 20, 48, 0, 8, 33, 44, 37, 8, 48, 9, 8, 45, 33, 19, 8, 48, 11, 31, 35, 33, 30, 41, 8, 35, 48, 9, 8, 45, 56, 26, 11, 8, 48, 31, 53, 8, 18, 48, 53, 56, 50, 8, 48, 19, 8, 19, 33, 35, 17, 8, 11, 48, 31, 53, 8, 18, 48, 45, 56, 30, 10, 31, 48, 27, 33, 35, 41, 8, 31, 21, 48, 2, 10, 37, 37, 48, 37, 8, 56, 50, 8, 48, 31, 33, 19, 33, 35, 35, 33, 60, 10, 11, 48, 44, 35, 33, 9, 37, 8, 19, 11, 48, 31, 33, 48, 31, 33, 19, 33, 35, 35, 33, 60, 10, 11, 48, 19, 8, 21, 48, 2, 27, 48, 18, 33, 26, 48, 60, 56, 30, 30, 56, 48, 19, 56, 34, 8, 48, 44, 8, 33, 44, 37, 8, 48, 58, 35, 8, 56, 19, 54, 48, 18, 33, 26, 10, 50, 8, 48, 41, 33, 31, 31, 56, 48, 11, 31, 56, 35, 31, 48, 9, 18, 48, 9, 8, 37, 17, 8, 50, 17, 30, 41, 48, 17, 30, 48, 31, 53, 56, 31, 48, 58, 35, 8, 56, 19, 48, 18, 33, 26, 35, 11, 8, 37, 27, 38, 48, 12, 8, 17, 30, 41, 48, 37, 33, 30, 8, 37, 18, 48, 17, 11, 48, 19, 33, 35, 8, 48, 44, 56, 17, 30, 27, 26, 37, 48, 31, 53, 8, 30, 48, 41, 8, 31, 31, 17, 30, 41, 48, 53, 26, 35, 31, 21, 48, 32, 53, 8, 35, 8, 10, 11, 48, 30, 33, 48, 11, 53, 56, 19, 8, 48, 17, 30, 48, 27, 56, 37, 37, 17, 30, 41, 48, 58, 33, 60, 30, 38, 48, 32, 35, 26, 8, 48, 11, 53, 56, 19, 8, 48, 17, 11, 48, 31, 33, 48, 30, 33, 31, 48, 11, 31, 56, 30, 58, 48, 26, 44, 48, 56, 41, 56, 17, 30, 38, 48, 57, 17, 19, 44, 37, 17, 45, 17, 31, 18, 48, 17, 11, 48, 31, 53, 8, 48, 8, 56, 11, 17, 8, 11, 31, 48, 44, 56, 31, 53, 48, 31, 33, 48, 31, 35, 26, 8, 48, 9, 8, 56, 26, 31, 18, 21, 48, 2, 27, 48, 18, 33, 26, 48, 45, 56, 30, 10, 31, 48, 58, 33, 48, 11, 33, 19, 8, 31, 53, 17, 30, 41, 54, 48, 31, 53, 8, 30, 48, 58, 33, 30, 10, 31, 21, 48, 5, 33, 45, 26, 11, 48, 33, 30, 48, 60, 53, 56, 31, 48, 18, 33, 26, 48, 45, 56, 30, 21, 48, 42, 17, 50, 17, 30, 41, 48, 26, 44, 48, 34, 17, 37, 37, 11, 48, 44, 8, 33, 44, 37, 8, 21, 48, 3, 53, 8, 30, 48, 44, 8, 33, 44, 37, 8, 48, 35, 8, 39, 8, 45, 31, 48, 41, 17, 50, 17, 30, 41, 48, 26, 44, 28, 48, 31, 53, 8, 18, 48, 27, 17, 30, 56, 37, 37, 18, 48, 60, 17, 30, 48, 31, 53, 8, 48, 35, 17, 41, 53, 31, 48, 31, 33, 48, 31, 35, 56, 30, 11, 45, 8, 30, 58, 48, 53, 26, 19, 56, 30, 17, 31, 18, 21, 48, 7, 33, 26, 48, 45, 56, 30, 48, 58, 17, 8, 48, 56, 30, 18, 31, 17, 19, 8, 54, 48, 9, 26, 31, 48, 37, 17, 50, 17, 30, 41, 48, 31, 56, 34, 8, 11, 48, 31, 35, 26, 8, 48, 45, 33, 26, 35, 56, 41, 8, 21, 15, 48, 23, 50, 8, 35, 18, 48, 39, 33, 26, 35, 30, 8, 18, 48, 9, 8, 41, 17, 30, 11, 48, 60, 17, 31, 53, 48, 56, 48, 11, 17, 30, 41, 37, 8, 48, 11, 31, 8, 44, 21, 48, 3, 8, 48, 39, 26, 11, 31, 48, 53, 56, 50, 8, 48, 31, 33, 48, 53, 56, 50, 8, 48, 44, 56, 31, 17, 8, 30, 45, 8, 21, 48, 2, 31, 48, 58, 33, 8, 11, 30, 10, 31, 48, 58, 33, 48, 56, 30, 18, 48, 41, 33, 33, 58, 48, 31, 33, 48, 44, 35, 8, 31, 8, 30, 58, 48, 18, 33, 26, 48, 45, 56, 30, 10, 31, 48, 11, 8, 8, 48, 60, 53, 56, 31, 10, 11, 48, 41, 33, 17, 30, 41, 48, 33, 30, 21, 48, 12, 8, 17, 30, 41, 48, 60, 8, 56, 34, 48, 17, 11, 48, 30, 33, 31, 53, 17, 30, 41, 48, 31, 33, 48, 9, 8, 48, 56, 11, 53, 56, 19, 8, 58, 48, 33, 27, 28, 48, 57, 31, 56, 18, 17, 30, 41, 48, 60, 8, 56, 34, 48, 17, 11, 48, 38, 38, 48, 32, 33, 48, 56, 45, 31, 48, 17, 11, 48, 30, 33, 31, 48, 30, 8, 45, 8, 11, 11, 56, 35, 17, 37, 18, 48, 45, 33, 19, 44, 56, 11, 11, 17, 33, 30, 21, 48, 32, 35, 26, 8, 48, 45, 33, 19, 44, 56, 11, 11, 17, 33, 30, 48, 11, 33, 19, 8, 31, 17, 19, 8, 11, 48, 45, 33, 19, 8, 11, 48, 27, 35, 33, 19, 48, 17, 30, 56, 45, 31, 17, 33, 30, 21, 48, 36, 48, 58, 35, 33, 44, 33, 26, 31, 48, 60, 17, 37, 37, 48, 9, 8, 56, 31, 48, 56, 48, 41, 8, 30, 17, 26, 11, 48, 31, 53, 35, 33, 26, 41, 53, 48, 53, 56, 35, 58, 48, 60, 33, 35, 34, 21, 48, 14, 8, 39, 8, 45, 31, 48, 45, 33, 19, 19, 33, 30, 48, 11, 8, 30, 11, 8, 48, 31, 33, 48, 19, 56, 34, 8, 48, 31, 53, 8, 48, 17, 19, 44, 33, 11, 11, 17, 9, 37, 8, 48, 44, 33, 11, 11, 17, 9, 37, 8, 21, 48, 3, 53, 56, 31, 8, 50, 8, 35, 48, 18, 33, 26, 48, 37, 33, 11, 8, 54, 48, 18, 33, 26, 10, 37, 37, 48, 27, 17, 30, 58, 48, 17, 31, 48, 56, 41, 56, 17, 30, 21, 48, 12, 26, 31, 48, 60, 53, 56, 31, 48, 18, 33, 26, 48, 31, 53, 35, 33, 60, 48, 56, 60, 56, 18, 48, 18, 33, 26, 10, 37, 37, 48, 30, 8, 50, 8, 35, 48, 41, 8, 31, 48, 9, 56, 45, 34, 21, 48, 2, 27, 48, 18, 33, 26, 48, 35, 8, 56, 37, 37, 18, 48, 60, 56, 30, 31, 48, 31, 33, 48, 9, 8, 48, 11, 31, 35, 33, 30, 41, 28, 48, 57, 31, 33, 44, 48, 45, 56, 35, 17, 30, 41, 48, 56, 9, 33, 26, 31, 48, 60, 53, 56, 31, 48, 18, 33, 26, 35, 48, 11, 26, 35, 35, 33, 26, 30, 58, 17, 30, 41, 48, 31, 53, 17, 30, 34, 11, 48, 33, 27, 48, 18, 33, 26, 38, 48, 24, 17, 11, 17, 33, 30, 48, 17, 11, 48, 30, 33, 31, 48, 60, 53, 56, 31, 48, 18, 33, 26, 35, 48, 8, 18, 8, 11, 48, 11, 8, 8, 54, 48, 9, 26, 31, 48, 56, 30, 48, 17, 19, 56, 41, 8, 48, 31, 53, 56, 31, 48, 18, 33, 26, 35, 48, 9, 35, 56, 17, 30, 48, 45, 33, 19, 44, 35, 8, 53, 8, 30, 58, 11, 21, 48, 57, 33, 19, 8, 31, 17, 19, 8, 11, 54, 48, 44, 8, 33, 44, 37, 8, 48, 56, 35, 8, 48, 39, 26, 11, 31, 48, 19, 8, 56, 30, 21, 48, 25, 33, 30, 10, 31, 48, 27, 17, 41, 53, 31, 48, 19, 8, 56, 30, 48, 60, 17, 31, 53, 48, 19, 8, 56, 30, 21, 48, 40, 33, 37, 58, 48, 18, 33, 26, 35, 48, 53, 8, 56, 58, 48, 53, 17, 41, 53, 21, 48, 32, 53, 8, 48, 31, 17, 45, 34, 8, 31, 48, 31, 33, 48, 31, 53, 8, 48, 27, 26, 31, 26, 35, 8, 48, 17, 11, 48, 56, 37, 60, 56, 18, 11, 48, 33, 44, 8, 30, 21, 48, 40, 56, 35, 58, 48, 60, 33, 35, 34, 48, 17, 11, 48, 60, 33, 35, 31, 53, 37, 8, 11, 11, 48, 27, 33, 35, 48, 31, 53, 33, 11, 8, 48, 31, 53, 56, 31, 48, 58, 33, 30, 10, 31, 48, 9, 8, 37, 17, 8, 50, 8, 48, 17, 30, 48, 31, 53, 8, 19, 11, 8, 37, 50, 8, 11, 21, 48, 36, 48, 44, 37, 56, 45, 8, 48, 60, 53, 8, 35, 8, 48, 11, 33, 19, 8, 33, 30, 8, 48, 11, 31, 17, 37, 37, 48, 31, 53, 17, 30, 34, 11, 48, 56, 9, 33, 26, 31, 48, 18, 33, 26, 48, 17, 11, 48, 56, 48, 44, 37, 56, 45, 8, 48, 18, 33, 26, 48, 45, 56, 30, 48, 45, 56, 37, 37, 48, 53, 33, 19, 8, 21, 48, 43, 17, 27, 8, 48, 45, 33, 19, 8, 11, 48, 56, 31, 48, 56, 48, 45, 33, 11, 31, 21, 48, 3, 33, 26, 37, 58, 30, 10, 31, 48, 17, 31, 48, 9, 8, 48, 56, 35, 35, 33, 41, 56, 30, 31, 13, 31, 33, 48, 58, 17, 8, 48, 9, 8, 27, 33, 35, 8, 48, 18, 33, 26, 10, 50, 8, 48, 35, 8, 44, 56, 17, 58, 48, 31, 53, 56, 31, 48, 58, 8, 9, 31, 20, 48, 7, 33, 26, 48, 45, 56, 30, 48, 58, 17, 8, 48, 56, 30, 18, 31, 17, 19, 8, 54, 48, 9, 26, 31, 48, 37, 17, 50, 17, 30, 41, 48, 31, 56, 34, 8, 11, 48, 31, 35, 26, 8, 48, 45, 33, 26, 35, 56, 41, 8, 21, 48, 23, 50, 8, 35, 18, 48, 39, 33, 26, 35, 30, 8, 18, 48, 9, 8, 41, 17, 30, 11, 48, 60, 17, 31, 53, 48, 56, 48, 11, 17, 30, 41, 37, 8, 48, 11, 31, 8, 44, 21, 48, 3, 8, 48, 39, 26, 11, 31, 48, 53, 56, 50, 8, 48, 31, 33, 48, 53, 56, 50, 8, 48, 44, 56, 31, 17, 8, 30, 45, 8, 21, 48, 2, 27, 48, 18, 33, 26, 48, 39, 26, 11, 31, 48, 11, 26, 9, 19, 17, 31, 48, 18, 33, 26, 35, 11, 8, 37, 27, 48, 31, 33, 48, 27, 56, 31, 8, 54, 48, 31, 53, 8, 30, 48, 31, 53, 56, 31, 10, 11, 48, 31, 53, 8, 48, 8, 30, 58, 48, 33, 27, 48, 17, 31, 21, 15, 48, 2, 31, 48, 17, 11, 48, 56, 31, 48, 31, 53, 8, 48, 19, 33, 19, 8, 30, 31, 48, 33, 27, 48, 58, 8, 56, 31, 53, 48, 31, 53, 56, 31, 48, 53, 26, 19, 56, 30, 17, 31, 18, 48, 53, 56, 11, 48, 50, 56, 37, 26, 8, 21, 48, 0, 8, 33, 44, 37, 8, 54, 48, 60, 53, 33, 48, 45, 56, 30, 10, 31, 48, 31, 53, 35, 33, 60, 48, 11, 33, 19, 8, 31, 53, 17, 30, 41, 48, 17, 19, 44, 33, 35, 31, 56, 30, 31, 48, 56, 60, 56, 18, 54, 48, 45, 56, 30, 48, 30, 8, 50, 8, 35, 48, 53, 33, 44, 8, 48, 31, 33, 48, 45, 53, 56, 30, 41, 8, 48, 56, 30, 18, 31, 53, 17, 30, 41, 21, 48, 3, 53, 56, 31, 8, 50, 8, 35, 48, 18, 33, 26, 48, 58, 33, 54, 48, 8, 30, 39, 33, 18, 48, 17, 31, 48, 31, 33, 48, 31, 53, 8, 48, 27, 26, 37, 37, 8, 11, 31, 21, 48, 32, 53, 56, 31, 48, 17, 11, 48, 31, 53, 8, 48, 11, 8, 45, 35, 8, 31, 48, 33, 27, 48, 37, 17, 27, 8, 21, 15, 48, 0, 33, 60, 8, 35, 48, 45, 33, 19, 8, 11, 48, 17, 30, 48, 35, 8, 11, 44, 33, 30, 11, 8, 48, 31, 33, 48, 56, 48, 30, 8, 8, 58, 54, 48, 30, 33, 31, 48, 56, 48, 58, 8, 11, 17, 35, 8, 21, 48, 7, 33, 26, 48, 53, 56, 50, 8, 48, 31, 33, 48, 45, 35, 8, 56, 31, 8, 48, 31, 53, 56, 31, 48, 30, 8, 8, 58, 21, 48, 32, 53, 8, 35, 8, 48, 56, 35, 8, 48, 30, 33, 48, 35, 8, 41, 35, 8, 31, 11, 21, 48, 2, 27, 48, 33, 30, 8, 48, 45, 56, 30, 48, 9, 8, 48, 44, 35, 33, 26, 58, 48, 33, 27, 48, 33, 30, 8, 10, 11, 48, 37, 17, 27, 8, 54, 48, 33, 30, 8, 48, 11, 53, 33, 26, 37, 58, 48, 30, 33, 31, 48, 60, 17, 11, 53, 48, 27, 33, 35, 48, 56, 30, 33, 31, 53, 8, 35, 48, 45, 53, 56, 30, 45, 8, 21, 15, 48, 7, 33, 26, 48, 45, 56, 30, 10, 31, 48, 56, 37, 60, 56, 18, 11, 48, 53, 33, 37, 58, 48, 33, 30, 48, 31, 33, 48, 31, 53, 8, 48, 31, 53, 17, 30, 41, 11, 48, 31, 53, 56, 31, 48, 56, 35, 8, 48, 17, 19, 44, 33, 35, 31, 56, 30, 31, 21, 48, 12, 18, 48, 37, 8, 31, 31, 17, 30, 41, 48, 31, 53, 8, 19, 48, 41, 33, 48, 60, 8, 48, 41, 56, 17, 30, 48, 11, 33, 19, 8, 31, 53, 17, 30, 41, 48, 8, 37, 11, 8, 21, 15, 48, 2, 27, 48, 18, 33, 26, 48, 58, 33, 30, 10, 31, 48, 37, 17, 34, 8, 48, 18, 33, 26, 35, 48, 58, 8, 11, 31, 17, 30, 18, 54, 48, 58, 33, 30, 10, 31, 48, 56, 45, 45, 8, 44, 31, 48, 17, 31, 21, 48, 2, 30, 11, 31, 8, 56, 58, 54, 48, 53, 56, 50, 8, 48, 31, 53, 8, 48, 45, 33, 26, 35, 56, 41, 8, 48, 31, 33, 48, 45, 53, 56, 30, 41, 8, 48, 17, 31, 48, 31, 53, 8, 48, 60, 56, 18, 48, 18, 33, 26, 48, 60, 56, 30, 31, 48, 17, 31, 48, 31, 33, 48, 9, 8, 21, 48, 25, 33, 30, 10, 31, 48, 9, 8, 41, 13, 27, 33, 35, 13, 31, 53, 17, 30, 41, 11, 21, 48, 25, 33, 13, 17, 31, 48, 18, 33, 26, 35, 11, 8, 37, 27, 54, 48, 33, 35, 48, 8, 37, 11, 8, 48, 18, 33, 26, 48, 60, 33, 30, 10, 31, 13, 41, 8, 31, 48, 56, 30, 18, 31, 53, 17, 30, 41, 21, 48, 2, 48, 35, 8, 27, 26, 11, 8, 48, 31, 33, 48, 37, 8, 31, 48, 19, 18, 48, 27, 8, 56, 35, 48, 45, 33, 30, 31, 35, 33, 37, 48, 19, 8, 48, 56, 30, 18, 19, 33, 35, 8, 21, 15, 48, 2, 27, 48, 18, 33, 26, 48, 45, 56, 30, 10, 31, 48, 27, 17, 30, 58, 48, 56, 48, 35, 8, 56, 11, 33, 30, 48, 31, 33, 48, 27, 17, 41, 53, 31, 54, 48, 31, 53, 8, 30, 48, 18, 33, 26, 48, 11, 53, 33, 26, 37, 58, 30, 10, 31, 48, 9, 8, 48, 27, 17, 41, 53, 31, 17, 30, 41, 21, 15, 48, 7, 33, 26, 48, 11, 53, 33, 26, 37, 58, 48, 30, 8, 50, 8, 35, 48, 41, 17, 50, 8, 48, 26, 44, 48, 33, 30, 48, 37, 17, 27, 8, 54, 48, 30, 33, 48, 19, 56, 31, 31, 8, 35, 48, 53, 33, 60, 48, 18, 33, 26, 48, 27, 8, 8, 37, 21, 48, 16, 33, 48, 19, 56, 31, 31, 8, 35, 48, 53, 33, 60, 48, 9, 56, 58, 37, 18, 48, 18, 33, 26, 48, 60, 56, 30, 31, 48, 31, 33, 48, 41, 17, 50, 8, 48, 26, 44, 21, 15, 48, 0, 8, 33, 44, 37, 8, 48, 60, 53, 33, 48, 45, 56, 30, 10, 31, 48, 31, 53, 35, 33, 60, 48, 11, 33, 19, 8, 31, 53, 17, 30, 41, 48, 17, 19, 44, 33, 35, 31, 56, 30, 31, 48, 56, 60, 56, 18, 54, 48, 45, 56, 30, 48, 30, 8, 50, 8, 35, 48, 53, 33, 44, 8, 48, 31, 33, 48, 45, 53, 56, 30, 41, 8, 48, 56, 30, 18, 31, 53, 17, 30, 41, 21, 48, 3, 8, 48, 45, 56, 30, 10, 31, 48, 60, 56, 11, 31, 8, 48, 31, 17, 19, 8, 48, 60, 33, 35, 35, 18, 17, 30, 41, 48, 56, 9, 33, 26, 31, 48, 31, 53, 8, 48, 60, 53, 56, 31, 48, 17, 27, 10, 11, 21, 15, 48, 5, 33, 33, 37, 11, 48, 60, 53, 33, 48, 58, 33, 30, 10, 31, 48, 35, 8, 11, 44, 8, 45, 31, 48, 31, 53, 8, 48, 44, 56, 11, 31, 48, 56, 35, 8, 48, 37, 17, 34, 8, 37, 18, 48, 31, 33, 48, 35, 8, 44, 8, 56, 31, 48, 17, 31, 21, 48, 32, 53, 56, 31, 10, 11, 48, 60, 53, 18, 48, 2, 48, 45, 56, 30, 10, 31, 48, 19, 56, 34, 8, 48, 56, 48, 45, 53, 56, 30, 41, 8, 21, 48, 23, 50, 8, 35, 18, 31, 53, 17, 30, 41, 48, 2, 48, 58, 33, 48, 17, 11, 48, 11, 33, 28, 48, 40, 56, 37, 27, 29, 56, 11, 11, 8, 58, 21, 15, 48, 57, 33, 19, 8, 31, 17, 19, 8, 11, 48, 17, 31, 10, 11, 48, 30, 8, 45, 8, 11, 11, 56, 35, 18, 48, 31, 33, 48, 58, 33, 48, 26, 30, 30, 8, 45, 8, 11, 11, 56, 35, 18, 48, 31, 53, 17, 30, 41, 11, 21, 48, 36, 30, 48, 8, 46, 45, 8, 37, 37, 8, 30, 31, 48, 37, 8, 56, 58, 8, 35, 48, 19, 26, 11, 31, 48, 9, 8, 48, 44, 56, 11, 11, 17, 33, 30, 56, 31, 8, 48, 9, 8, 45, 56, 26, 11, 8, 48, 17, 31, 10, 11, 48, 31, 53, 8, 17, 35, 48, 58, 26, 31, 18, 48, 31, 33, 48, 34, 8, 8, 44, 48, 8, 50, 8, 35, 18, 33, 30, 8, 48, 19, 33, 50, 17, 30, 41, 48, 27, 33, 35, 60, 56, 35, 58, 21, 48, 0, 35, 33, 31, 8, 45, 31, 17, 30, 41, 48, 11, 33, 19, 8, 33, 30, 8, 48, 19, 8, 56, 30, 11, 48, 41, 17, 50, 17, 30, 41, 48, 31, 53, 8, 19, 48, 56, 48, 44, 37, 56, 45, 8, 48, 31, 33, 48, 9, 8, 37, 33, 30, 41, 21, 48, 42, 17, 50, 17, 30, 41, 48, 31, 53, 8, 19, 48, 56, 48, 44, 37, 56, 45, 8, 48, 60, 53, 8, 35, 8, 48, 31, 53, 8, 18, 48, 45, 56, 30, 48, 9, 8, 48, 53, 56, 44, 44, 18, 21, 48, 32, 53, 17, 30, 34, 17, 30, 41, 48, 18, 33, 26, 10, 35, 8, 48, 30, 33, 29, 41, 33, 33, 58, 48, 56, 30, 58, 48, 60, 33, 35, 31, 53, 37, 8, 11, 11, 48, 17, 11, 48, 31, 53, 8, 48, 60, 33, 35, 11, 31, 48, 31, 53, 17, 30, 41, 48, 18, 33, 26, 48, 45, 56, 30, 48, 58, 33, 48, 57, 33, 19, 8, 31, 17, 19, 8, 11, 48, 2, 48, 58, 33, 48, 27, 8, 8, 37, 48, 37, 17, 34, 8, 48, 2, 10, 19, 48, 56, 48, 27, 56, 17, 37, 26, 35, 8, 21, 48, 43, 17, 34, 8, 48, 31, 53, 8, 35, 8, 10, 11, 48, 30, 33, 48, 53, 33, 44, 8, 48, 27, 33, 35, 48, 19, 8, 21, 48, 12, 26, 31, 48, 8, 50, 8, 30, 48, 11, 33, 54, 48, 2, 10, 19, 48, 30, 33, 31, 48, 41, 33, 30, 30, 56, 48, 41, 17, 50, 8, 48, 26, 44, 21, 48, 23, 50, 8, 35, 38, 15, 48, 2, 27, 48, 18, 33, 26, 48, 45, 56, 30, 10, 31, 48, 58, 33, 48, 11, 33, 19, 8, 31, 53, 17, 30, 41, 54, 48, 31, 53, 8, 30, 48, 58, 33, 30, 10, 31, 21, 48, 5, 33, 45, 26, 11, 48, 33, 30, 48, 60, 53, 56, 31, 48, 18, 33, 26, 48, 45, 56, 30, 48, 58, 33, 21, 15, 48, 3, 53, 8, 30, 48, 18, 33, 26, 48, 37, 33, 11, 8, 48, 11, 17, 41, 53, 31, 48, 33, 27, 48, 18, 33, 26, 35, 48, 44, 56, 31, 53, 54, 48, 37, 17, 11, 31, 8, 30, 48, 27, 33, 35, 48, 31, 53, 8, 48, 58, 8, 11, 31, 17, 30, 56, 31, 17, 33, 30, 48, 17, 30, 48, 18, 33, 26, 35, 48, 53, 8, 56, 35, 31, 21, 48, 32, 53, 8, 48, 19, 33, 19, 8, 30, 31, 48, 18, 33, 26, 48, 31, 53, 17, 30, 34, 48, 33, 27, 48, 41, 17, 50, 17, 30, 41, 48, 26, 44, 54, 48, 31, 53, 17, 30, 34, 48, 33, 27, 48, 31, 53, 8, 48, 35, 8, 56, 11, 33, 30, 48, 60, 53, 18, 48, 18, 33, 26, 48, 53, 8, 37, 58, 48, 33, 30, 48, 11, 33, 48, 37, 33, 30, 41, 21, 15, 48, 25, 33, 30, 10, 31, 48, 41, 17, 50, 8, 48, 26, 44, 54, 48, 31, 53, 8, 35, 8, 10, 11, 48, 30, 33, 48, 11, 53, 56, 19, 8, 48, 17, 30, 48, 27, 56, 37, 37, 17, 30, 41, 48, 58, 33, 60, 30, 38, 48, 32, 35, 26, 8, 48, 11, 53, 56, 19, 8, 48, 17, 11, 48, 31, 33, 48, 30, 33, 31, 48, 11, 31, 56, 30, 58, 48, 26, 44, 48, 56, 41, 56, 17, 30, 38, 48, 16, 33, 48, 19, 56, 31, 31, 8, 35, 48, 53, 33, 60, 48, 53, 56, 35, 58, 48, 33, 35, 48, 17, 19, 44, 33, 11, 11, 17, 9, 37, 8, 48, 17, 31, 48, 17, 11, 54, 48, 30, 8, 50, 8, 35, 48, 37, 33, 11, 8, 48, 11, 17, 41, 53, 31, 48, 33, 27, 48, 18, 33, 26, 35, 48, 41, 33, 56, 37, 21, 15, 48, 43, 17, 27, 8, 48, 17, 11, 48, 30, 33, 31, 48, 56, 48, 41, 56, 19, 8, 48, 33, 27, 48, 37, 26, 45, 34, 21, 48, 2, 27, 48, 18, 33, 26, 48, 60, 56, 30, 30, 56, 48, 60, 17, 30, 54, 48, 60, 33, 35, 34, 48, 53, 56, 35, 58, 21, 48, 32, 53, 8, 48, 60, 33, 35, 37, 58, 48, 17, 11, 30, 10, 31, 48, 44, 8, 35, 27, 8, 45, 31, 21, 48, 12, 26, 31, 48, 17, 31, 10, 11, 48, 31, 53, 8, 35, 8, 48, 27, 33, 35, 48, 26, 11, 54, 48, 58, 33, 17, 30, 41, 48, 31, 53, 8, 48, 9, 8, 11, 31, 48, 17, 31, 48, 45, 56, 30, 28, 21, 31, 53, 56, 31, 10, 11, 48, 60, 53, 56, 31, 48, 19, 56, 34, 8, 11, 48, 17, 31, 48, 11, 33, 48, 58, 56, 19, 30, 48, 9, 8, 56, 26, 31, 17, 27, 26, 37, 21, 48, 5, 8, 56, 35, 48, 17, 11, 48, 30, 33, 31, 48, 8, 50, 17, 37, 21, 48, 2, 31, 48, 31, 8, 37, 37, 11, 48, 18, 33, 26, 48, 60, 53, 56, 31, 48, 18, 33, 26, 35, 48, 60, 8, 56, 34, 30, 8, 11, 11, 48, 17, 11, 21, 48, 36, 30, 58, 48, 33, 30, 45, 8, 48, 18, 33, 26, 48, 34, 30, 33, 60, 48, 18, 33, 26, 35, 48, 60, 8, 56, 34, 30, 8, 11, 11, 54, 48, 18, 33, 26, 48, 45, 56, 30, 48, 9, 8, 45, 33, 19, 8, 48, 11, 31, 35, 33, 30, 41, 8, 35, 48, 56, 11, 48, 60, 8, 37, 37, 48, 56, 11, 48, 34, 17, 30, 58, 8, 35, 21, 48, 32, 33, 48, 34, 30, 33, 60, 48, 11, 33, 35, 35, 33, 60, 48, 17, 11, 48, 30, 33, 31, 48, 31, 8, 35, 35, 17, 27, 18, 17, 30, 41, 21, 48, 3, 53, 56, 31, 48, 17, 11, 48, 31, 8, 35, 35, 17, 27, 18, 17, 30, 41, 48, 17, 11, 48, 31, 33, 48, 34, 30, 33, 60, 48, 18, 33, 26, 48, 45, 56, 30, 10, 31, 48, 41, 33, 48, 9, 56, 45, 34, 48, 31, 33, 48, 53, 56, 44, 44, 17, 30, 8, 11, 11, 48, 18, 33, 26, 48, 45, 33, 26, 37, 58, 48, 53, 56, 50, 8, 21, 48, 55, 30, 33, 60, 17, 30, 41, 48, 18, 33, 26, 10, 35, 8, 48, 58, 17, 27, 27, 8, 35, 8, 30, 31, 48, 17, 11, 48, 33, 30, 37, 18, 48, 31, 53, 8, 48, 9, 8, 41, 17, 30, 30, 17, 30, 41, 21, 48, 2, 27, 48, 18, 33, 26, 48, 56, 45, 45, 8, 44, 31, 48, 31, 53, 8, 11, 8, 48, 58, 17, 27, 27, 8, 35, 8, 30, 45, 8, 11, 48, 18, 33, 26, 10, 37, 37, 48, 9, 8, 48, 56, 9, 37, 8, 48, 31, 33, 48, 41, 8, 31, 48, 44, 56, 11, 31, 48, 31, 53, 8, 19, 48, 56, 30, 58, 48, 41, 35, 33, 60, 48, 8, 50, 8, 30, 48, 45, 37, 33, 11, 8, 35, 21, 48, 25, 33, 30, 10, 31, 48, 9, 8, 48, 11, 33, 48, 47, 26, 17, 45, 34, 48, 31, 33, 48, 31, 53, 35, 33, 60, 48, 56, 60, 56, 18, 48, 18, 33, 26, 35, 48, 37, 17, 27, 8, 21, 48, 16, 33, 48, 19, 56, 31, 31, 8, 35, 48, 53, 33, 60, 48, 58, 17, 11, 41, 35, 56, 45, 8, 27, 26, 37, 48, 33, 35, 48, 8, 19, 9, 56, 35, 35, 56, 11, 11, 17, 30, 41, 48, 17, 31, 48, 19, 56, 18, 48, 9, 8, 54, 48, 18, 33, 26, 48, 30, 8, 8, 58, 48, 31, 33, 48, 34, 8, 8, 44, 48, 11, 31, 35, 26, 41, 41, 37, 17, 30, 41, 48, 31, 33, 48, 27, 17, 30, 58, 48, 18, 33, 26, 35, 48, 60, 56, 18, 48, 33, 26, 31, 48, 26, 30, 31, 17, 37, 48, 31, 53, 8, 48, 50, 8, 35, 18, 48, 8, 30, 58, 21, 48, 32, 53, 8, 48, 60, 33, 35, 37, 58, 10, 11, 48, 30, 33, 31, 48, 44, 8, 35, 27, 8, 45, 31, 54, 48, 9, 26, 31, 48, 17, 31, 10, 11, 48, 31, 53, 8, 35, 8, 48, 27, 33, 35, 48, 26, 11, 48, 31, 35, 18, 17, 30, 41, 48, 31, 53, 8, 48, 9, 8, 11, 31, 48, 17, 31, 48, 45, 56, 30, 21, 48, 32, 53, 56, 31, 10, 11, 48, 60, 53, 56, 31, 48, 19, 56, 34, 8, 11, 48, 17, 31, 48, 11, 33, 48, 58, 56, 19, 30, 48, 9, 8, 56, 26, 31, 17, 27, 26, 37, 21, 48, 3, 8, 48, 56, 35, 8, 48, 56, 37, 37, 48, 37, 17, 34, 8, 48, 27, 17, 35, 8, 60, 33, 35, 34, 11, 51, 48, 60, 8, 48, 45, 37, 17, 19, 9, 54, 48, 60, 8, 48, 11, 53, 17, 30, 8, 48, 56, 30, 58, 48, 56, 37, 60, 56, 18, 11, 48, 41, 33, 48, 33, 26, 35, 48, 11, 8, 44, 56, 35, 56, 31, 8, 48, 60, 56, 18, 11, 48, 56, 30, 58, 48, 9, 8, 45, 33, 19, 8, 48, 27, 26, 35, 31, 53, 8, 35, 48, 56, 44, 56, 35, 31, 21, 48, 12, 26, 31, 48, 8, 50, 8, 30, 48, 60, 53, 8, 30, 48, 31, 53, 56, 31, 48, 31, 17, 19, 8, 48, 45, 33, 19, 8, 11, 54, 48, 37, 8, 31, 10, 11, 48, 30, 33, 31, 48, 58, 17, 11, 56, 44, 44, 8, 56, 35, 48, 37, 17, 34, 8, 48, 56, 48, 27, 17, 35, 8, 60, 33, 35, 34, 48, 56, 30, 58, 48, 45, 33, 30, 31, 17, 30, 26, 8, 48, 31, 33, 48, 11, 53, 17, 30, 8, 21, 21, 48, 27, 33, 35, 8, 50, 8, 35, 21, 48, 2, 27, 48, 30, 33, 9, 33, 58, 18, 48, 45, 56, 35, 8, 11, 48, 31, 33, 48, 56, 45, 45, 8, 44, 31, 48, 18, 33, 26, 48, 56, 30, 58, 48, 60, 56, 30, 31, 11, 48, 18, 33, 26, 48, 17, 30, 48, 31, 53, 17, 11, 48, 60, 33, 35, 37, 58, 54, 48, 56, 45, 45, 8, 44, 31, 48, 18, 33, 26, 35, 11, 8, 37, 27, 48, 56, 30, 58, 48, 18, 33, 26, 48, 60, 17, 37, 37, 48, 11, 8, 8, 48, 31, 53, 56, 31, 48, 18, 33, 26, 48, 58, 33, 30, 10, 31, 48, 30, 8, 8, 58, 48, 31, 53, 8, 19, 48, 56, 30, 58, 48, 31, 53, 8, 17, 35, 48, 11, 8, 37, 27, 17, 11, 53, 48, 17, 58, 8, 56, 11, 21, 48, 3, 53, 8, 30, 48, 18, 33, 26, 48, 53, 17, 31, 48, 31, 53, 8, 48, 44, 33, 17, 30, 31, 48, 33, 27, 48, 30, 33, 48, 35, 8, 31, 26, 35, 30, 54, 48, 31, 53, 56, 31, 10, 11, 48, 31, 53, 8, 48, 19, 33, 19, 8, 30, 31, 48, 17, 31, 48, 31, 35, 26, 37, 18, 48, 9, 8, 45, 33, 19, 8, 11, 48, 56, 48, 39, 33, 26, 35, 30, 8, 18, 21, 48, 2, 27, 48, 18, 33, 26, 48, 45, 56, 30, 48, 11, 31, 17, 37, 37, 48, 31, 26, 35, 30, 48, 9, 56, 45, 34, 54, 48, 17, 31, 10, 11, 48, 30, 33, 31, 48, 35, 8, 56, 37, 37, 18, 48, 56, 48, 39, 33, 26, 35, 30, 8, 18, 21, 48, 32, 53, 33, 11, 8, 48, 60, 53, 33, 48, 11, 31, 56, 30, 58, 48, 56, 31, 48, 31, 53, 8, 48, 31, 33, 44, 48, 58, 8, 31, 8, 35, 19, 17, 30, 8, 48, 60, 53, 56, 31, 10, 11, 48, 60, 35, 33, 30, 41, 48, 56, 30, 58, 48, 60, 53, 56, 31, 10, 11, 48, 35, 17, 41, 53, 31, 38, 48, 32, 53, 17, 11, 48, 50, 8, 35, 18, 48, 44, 37, 56, 45, 8, 48, 17, 11, 48, 30, 8, 26, 31, 35, 56, 37, 48, 41, 35, 33, 26, 30, 58, 38, 48, 52, 26, 11, 31, 17, 45, 8, 48, 60, 17, 37, 37, 48, 44, 35, 8, 50, 56, 17, 37, 54, 48, 18, 33, 26, 48, 11, 56, 18, 20, 48, 12, 26, 31, 48, 33, 27, 48, 45, 33, 26, 35, 11, 8, 48, 17, 31, 48, 60, 17, 37, 37, 38, 48, 3, 53, 33, 8, 50, 8, 35, 48, 60, 17, 30, 11, 48, 31, 53, 17, 11, 48, 60, 56, 35, 48, 9, 8, 45, 33, 19, 8, 11, 48, 39, 26, 11, 31, 17, 45, 8, 38, 48, 36, 48, 44, 8, 35, 11, 33, 30, 48, 41, 35, 33, 60, 11, 48, 26, 44, 48, 60, 53, 8, 30, 48, 53, 8, 10, 11, 48, 56, 9, 37, 8, 48, 31, 33, 48, 33, 50, 8, 35, 45, 33, 19, 8, 48, 53, 56, 35, 58, 11, 53, 17, 44, 11, 21, 48, 0, 35, 33, 31, 8, 45, 31, 17, 33, 30, 48, 17, 11, 48, 17, 19, 44, 33, 35, 31, 56, 30, 31, 54, 48, 9, 26, 31, 48, 31, 53, 8, 35, 8, 48, 56, 35, 8, 48, 11, 33, 19, 8, 48, 31, 53, 17, 30, 41, 11, 48, 31, 53, 56, 31, 48, 56, 48, 44, 8, 35, 11, 33, 30, 48, 19, 26, 11, 31, 48, 37, 8, 56, 35, 30, 48, 33, 30, 48, 53, 17, 11, 48, 33, 60, 30, 21, 48, 3, 53, 33, 48, 58, 8, 45, 17, 58, 8, 11, 48, 37, 17, 19, 17, 31, 11, 20, 48, 36, 30, 58, 48, 9, 56, 11, 8, 58, 48, 33, 30, 48, 60, 53, 56, 31, 20, 48, 7, 33, 26, 48, 11, 56, 17, 58, 48, 18, 33, 26, 48, 60, 33, 35, 34, 8, 58, 48, 53, 56, 35, 58, 20, 48, 3, 8, 37, 37, 54, 48, 19, 56, 18, 9, 8, 48, 18, 33, 26, 48, 30, 8, 8, 58, 48, 31, 33, 48, 60, 33, 35, 34, 48, 56, 48, 37, 17, 31, 31, 37, 8, 48, 53, 56, 35, 58, 8, 35, 21, 48, 2, 11, 48, 31, 53, 56, 31, 48, 35, 8, 56, 37, 37, 18, 48, 31, 53, 8, 48, 37, 17, 19, 17, 31, 48, 33, 27, 48, 18, 33, 26, 35, 48, 11, 31, 35, 8, 30, 41, 31, 53, 20, 48, 59, 33, 26, 37, 58, 48, 18, 33, 26, 48, 33, 27, 48, 31, 33, 19, 33, 35, 35, 33, 60, 48, 9, 8, 56, 31, 48, 18, 33, 26, 48, 31, 33, 58, 56, 18, 20, 48, 2, 30, 11, 31, 8, 56, 58, 48, 33, 27, 48, 41, 17, 50, 17, 30, 41, 48, 17, 30, 54, 48, 19, 33, 50, 8, 48, 27, 33, 35, 60, 56, 35, 58, 21, 48, 6, 17, 11, 31, 56, 34, 8, 11, 48, 56, 35, 8, 48, 30, 33, 31, 48, 11, 53, 56, 45, 34, 37, 8, 11, 48, 31, 53, 56, 31, 48, 53, 56, 37, 31, 48, 33, 30, 8, 48, 27, 35, 33, 19, 48, 11, 31, 8, 44, 44, 17, 30, 41, 48, 27, 33, 35, 60, 56, 35, 58, 21, 48, 14, 56, 31, 53, 8, 35, 54, 48, 31, 53, 8, 18, 48, 56, 35, 8, 48, 31, 53, 56, 31, 48, 60, 53, 17, 45, 53, 48, 11, 26, 11, 31, 56, 17, 30, 48, 56, 30, 58, 48, 41, 35, 33, 60, 48, 33, 30, 8, 10, 11, 48, 53, 8, 56, 35, 31, 21, 48, 5, 8, 56, 35, 48, 17, 11, 48, 27, 35, 8, 8, 58, 33, 19, 38, 48, 57, 26, 9, 39, 26, 41, 56, 31, 17, 33, 30, 48, 17, 11, 48, 37, 17, 9, 8, 35, 56, 31, 17, 33, 30, 38, 48, 59, 33, 30, 31, 35, 56, 58, 17, 45, 31, 17, 33, 30, 48, 17, 11, 48, 31, 53, 8, 48, 31, 35, 26, 31, 53, 38, 48, 32, 53, 33, 11, 8, 48, 56, 35, 8, 48, 31, 53, 8, 48, 27, 56, 45, 31, 11, 48, 33, 27, 48, 31, 53, 17, 11, 48, 60, 33, 35, 37, 58, 38, 48, 36, 30, 58, 48, 18, 33, 26, 48, 60, 17, 37, 37, 48, 56, 37, 37, 48, 11, 26, 35, 35, 8, 30, 58, 8, 35, 48, 31, 33, 48, 31, 53, 8, 19, 54, 48, 18, 33, 26, 48, 44, 17, 41, 11, 48, 17, 30, 48, 53, 26, 19, 56, 30, 48, 45, 37, 33, 31, 53, 17, 30, 41, 38, 48, 40, 56, 31, 35, 8, 58, 48, 56, 30, 58, 48, 57, 33, 35, 35, 33, 60, 48, 56, 35, 8, 48, 44, 33, 60, 8, 35, 21, 48, 32, 53, 8, 18, 48, 56, 35, 8, 48, 18, 33, 26, 35, 11, 48, 31, 33, 48, 45, 33, 30, 31, 35, 33, 37, 21, 48, 36, 37, 37, 48, 18, 33, 26, 48, 53, 56, 50, 8, 48, 31, 33, 48, 58, 33, 48, 17, 11, 48, 31, 33, 48, 31, 26, 35, 30, 48, 31, 53, 8, 19, 48, 17, 30, 31, 33, 48, 11, 31, 35, 8, 30, 41, 31, 53, 48, 56, 30, 58, 48, 26, 11, 8, 48, 31, 53, 56, 31, 48, 11, 31, 35, 8, 30, 41, 31, 53, 48, 31, 33, 48, 19, 33, 50, 8, 48, 27, 33, 35, 60, 56, 35, 58, 21, 48, 2, 31, 10, 11, 48, 30, 33, 31, 48, 56, 37, 60, 56, 18, 11, 48, 44, 33, 11, 11, 17, 9, 37, 8, 48, 31, 33, 48, 58, 33, 48, 60, 53, 56, 31, 48, 60, 8, 48, 60, 56, 30, 31, 48, 31, 33, 48, 58, 33, 54, 48, 9, 26, 31, 48, 17, 31, 10, 11, 48, 17, 19, 44, 33, 35, 31, 56, 30, 31, 48, 31, 33, 48, 9, 8, 37, 17, 8, 50, 8, 48, 17, 30, 48, 11, 33, 19, 8, 31, 53, 17, 30, 41, 48, 9, 8, 27, 33, 35, 8, 48, 18, 33, 26, 48, 56, 45, 31, 26, 56, 37, 37, 18, 48, 58, 33, 48, 17, 31, 21, 48, 43, 17, 27, 8, 48, 56, 30, 58, 48, 58, 8, 56, 31, 53, 48, 56, 35, 8, 48, 37, 17, 34, 8, 48, 37, 17, 41, 53, 31, 48, 56, 30, 58, 48, 11, 53, 56, 58, 33, 60, 21, 48, 32, 53, 8, 18, 10, 35, 8, 48, 9, 33, 31, 53, 48, 56, 37, 60, 56, 18, 11, 48, 31, 53, 8, 35, 8, 21, 48, 12, 26, 31, 48, 44, 8, 33, 44, 37, 8, 48, 58, 33, 30, 10, 31, 48, 37, 17, 34, 8, 48, 31, 53, 17, 30, 34, 17, 30, 41, 48, 56, 9, 33, 26, 31, 48, 58, 8, 56, 31, 53, 54, 48, 11, 33, 48, 11, 26, 9, 45, 33, 30, 11, 45, 17, 33, 26, 11, 37, 18, 54, 48, 31, 53, 8, 18, 48, 56, 37, 60, 56, 18, 11, 48, 37, 33, 33, 34, 48, 56, 60, 56, 18, 48, 27, 35, 33, 19, 48, 17, 31, 21, 48, 2, 31, 10, 11, 48, 19, 33, 35, 8, 48, 17, 19, 44, 33, 35, 31, 56, 30, 31, 48, 31, 33, 48, 19, 56, 11, 31, 8, 35, 48, 31, 53, 8, 48, 45, 56, 35, 58, 11, 48, 18, 33, 26, 10, 35, 8, 48, 53, 33, 37, 58, 17, 30, 41, 48, 31, 53, 56, 30, 48, 31, 33, 48, 45, 33, 19, 44, 37, 56, 17, 30, 48, 56, 9, 33, 26, 31, 48, 31, 53, 8, 48, 33, 30, 8, 11, 48, 18, 33, 26, 35, 48, 33, 44, 44, 33, 30, 8, 30, 31, 48, 60, 56, 11, 48, 58, 8, 56, 37, 31, 21, 15, 48, 2, 48, 56, 19, 48, 31, 53, 8, 48, 53, 33, 44, 8, 48, 33, 27, 48, 31, 53, 8, 48, 26, 30, 17, 50, 8, 35, 11, 8, 21, 48, 2, 48, 56, 19, 48, 31, 53, 8, 48, 56, 30, 11, 60, 8, 35, 48, 31, 33, 48, 56, 37, 37, 48, 37, 17, 50, 17, 30, 41, 48, 31, 53, 17, 30, 41, 11, 48, 31, 53, 56, 31, 48, 45, 35, 18, 48, 33, 26, 31, 48, 27, 33, 35, 48, 44, 8, 56, 45, 8, 21, 48, 2, 48, 56, 19, 48, 31, 53, 8, 48, 44, 35, 33, 31, 8, 45, 31, 33, 35, 48, 33, 27, 48, 31, 53, 8, 48, 17, 30, 30, 33, 45, 8, 30, 31, 21, 48, 2, 48, 56, 19, 48, 31, 53, 8, 48, 37, 17, 41, 53, 31, 48, 17, 30, 48, 31, 53, 8, 48, 58, 56, 35, 34, 30, 8, 11, 11, 21, 48, 2, 48, 56, 19, 48, 31, 53, 8, 48, 31, 35, 26, 31, 53, 21, 48, 36, 37, 37, 18, 48, 31, 33, 48, 41, 33, 33, 58, 38, 48, 16, 17, 41, 53, 31, 19, 56, 35, 8, 48, 31, 33, 48, 18, 33, 26, 38, 48, 2, 27, 48, 18, 33, 26, 10, 35, 8, 48, 41, 33, 30, 30, 56, 48, 17, 30, 11, 17, 11, 31, 48, 33, 30, 48, 41, 56, 19, 9, 37, 17, 30, 41, 48, 56, 30, 58, 48, 31, 53, 8, 30, 48, 45, 33, 19, 44, 37, 56, 17, 30, 48, 60, 53, 8, 30, 48, 18, 33, 26, 48, 37, 33, 11, 8, 54, 48, 18, 33, 26, 48, 53, 56, 58, 48, 9, 8, 31, 31, 8, 35, 48, 60, 33, 35, 34, 48, 33, 30, 48, 18, 33, 26, 35, 48, 41, 56, 19, 8, 21, 15, 48, 6, 33, 50, 17, 30, 41, 48, 33, 30, 48, 58, 33, 8, 11, 30, 10, 31, 48, 19, 8, 56, 30, 48, 18, 33, 26, 48, 27, 33, 35, 41, 8, 31, 48, 56, 9, 33, 26, 31, 48, 31, 53, 17, 30, 41, 11, 21, 48, 2, 31, 48, 39, 26, 11, 31, 48, 19, 8, 56, 30, 11, 48, 18, 33, 26, 48, 53, 56, 50, 8, 48, 31, 33, 48, 56, 45, 45, 8, 44, 31, 48, 60, 53, 56, 31, 10, 11, 48, 53, 56, 44, 44, 8, 30, 8, 58, 48, 56, 30, 58, 48, 45, 33, 30, 31, 17, 30, 26, 8, 48, 37, 17, 50, 17, 30, 41, 21, 48, 2, 27, 48, 30, 33, 9, 33, 58, 18, 48, 45, 56, 35, 8, 11, 48, 31, 33, 48, 56, 45, 45, 8, 44, 31, 48, 18, 33, 26, 48, 56, 30, 58, 48, 60, 56, 30, 31, 11, 48, 18, 33, 26, 48, 17, 30, 48, 31, 53, 17, 11, 48, 60, 33, 35, 37, 58, 54, 48, 56, 45, 45, 8, 44, 31, 48, 18, 33, 26, 35, 11, 8, 37, 27, 48, 56, 30, 58, 48, 18, 33, 26, 48, 60, 17, 37, 37, 48, 11, 8, 8, 48, 31, 53, 56, 31, 48, 18, 33, 26, 48, 58, 33, 30, 10, 31, 48, 30, 8, 8, 58, 48, 31, 53, 8, 19, 48, 56, 30, 58, 48, 31, 53, 8, 17, 35, 48, 11, 8, 37, 27, 17, 11, 53, 48, 17, 58, 8, 56, 11, 21, 48, 2, 27, 48, 18, 33, 26, 48, 34, 8, 8, 44, 48, 33, 30, 48, 53, 17, 58, 17, 30, 41, 48, 18, 33, 26, 35, 48, 31, 35, 26, 8, 48, 27, 8, 8, 37, 17, 30, 41, 11, 54, 48, 60, 53, 33, 48, 17, 11, 48, 41, 33, 17, 30, 41, 48, 31, 33, 48, 9, 8, 48, 53, 56, 44, 44, 18, 20, 48, 2, 27, 48, 18, 33, 26, 48, 56, 35, 8, 48, 11, 56, 58, 54, 48, 18, 33, 26, 48, 11, 53, 33, 26, 37, 58, 48, 11, 56, 18, 48, 17, 31, 48, 33, 26, 31, 48, 37, 33, 26, 58, 38, 48, 14, 8, 37, 17, 41, 17, 33, 30, 54, 48, 17, 58, 8, 33, 37, 33, 41, 18, 54, 48, 35, 8, 11, 33, 26, 35, 45, 8, 11, 54, 48, 37, 56, 30, 58, 54, 48, 11, 44, 17, 31, 8, 54, 48, 37, 33, 50, 8, 48, 33, 35, 48, 39, 26, 11, 31, 48, 9, 8, 45, 56, 26, 11, 8, 28, 48, 16, 33, 48, 19, 56, 31, 31, 8, 35, 48, 53, 33, 60, 48, 44, 56, 31, 53, 8, 31, 17, 45, 48, 31, 53, 8, 48, 35, 8, 56, 11, 33, 30, 54, 48, 17, 31, 10, 11, 48, 8, 30, 33, 26, 41, 53, 48, 31, 33, 48, 11, 31, 56, 35, 31, 48, 56, 48, 60, 56, 35, 21, 48, 3, 56, 35, 48, 60, 17, 37, 37, 48, 30, 8, 50, 8, 35, 48, 45, 8, 56, 11, 8, 48, 31, 33, 48, 8, 46, 17, 11, 31, 28, 48, 35, 8, 56, 11, 33, 30, 11, 48, 45, 56, 30, 48, 9, 8, 48, 31, 53, 33, 26, 41, 53, 31, 48, 26, 44, 48, 56, 27, 31, 8, 35, 48, 31, 53, 8, 48, 27, 56, 45, 31, 28, 48, 40, 26, 19, 56, 30, 48, 30, 56, 31, 26, 35, 8, 48, 44, 26, 35, 11, 26, 8, 11, 48, 11, 31, 35, 17, 27, 8, 21, 48, 25, 33, 30, 10, 31, 48, 9, 8, 48, 26, 44, 11, 8, 31, 48, 9, 8, 45, 56, 26, 11, 8, 48, 33, 27, 48, 60, 53, 56, 31, 48, 18, 33, 26, 48, 45, 56, 30, 10, 31, 48, 58, 33, 21, 48, 25, 33, 48, 60, 53, 56, 31, 48, 18, 33, 26, 48, 58, 33, 48, 9, 8, 11, 31, 54, 48, 37, 17, 50, 8, 48, 56, 11, 48, 45, 56, 35, 8, 27, 35, 8, 8, 48, 56, 30, 58, 48, 33, 44, 31, 17, 19, 17, 11, 31, 17, 45, 56, 37, 37, 18, 48, 56, 11, 48, 18, 33, 26, 48, 45, 56, 30, 54, 48, 9, 8, 45, 56, 26, 11, 8, 48, 11, 33, 19, 8, 48, 44, 8, 33, 44, 37, 8, 48, 56, 35, 8, 30, 10, 31, 48, 56, 9, 37, 8, 48, 31, 33, 48, 58, 33, 48, 31, 53, 56, 31, 21, 48, 2, 27, 48, 18, 33, 26, 48, 9, 8, 41, 17, 30, 48, 31, 33, 48, 35, 8, 41, 35, 8, 31, 54, 48, 18, 33, 26, 10, 37, 37, 48, 58, 26, 37, 37, 48, 18, 33, 26, 35, 48, 27, 26, 31, 26, 35, 8, 48, 58, 8, 45, 17, 11, 17, 33, 30, 11, 48, 56, 30, 58, 48, 37, 8, 31, 48, 33, 31, 53, 8, 35, 11, 48, 19, 56, 34, 8, 48, 18, 33, 26, 35, 48, 45, 53, 33, 17, 45, 8, 11, 48, 27, 33, 35, 48, 18, 33, 26, 21, 48, 36, 37, 37, 48, 31, 53, 56, 31, 10, 11, 48, 37, 8, 27, 31, 48, 27, 33, 35, 48, 18, 33, 26, 48, 31, 53, 8, 30, 48, 17, 11, 48, 31, 33, 48, 58, 17, 8, 21, 48, 16, 33, 9, 33, 58, 18, 48, 45, 56, 30, 48, 27, 33, 35, 8, 31, 8, 37, 37, 48, 31, 53, 8, 48, 33, 26, 31, 45, 33, 19, 8, 21, 48, 23, 56, 45, 53, 48, 58, 8, 45, 17, 11, 17, 33, 30, 48, 18, 33, 26, 48, 19, 56, 34, 8, 48, 53, 33, 37, 58, 11, 48, 19, 8, 56, 30, 17, 30, 41, 48, 33, 30, 37, 18, 48, 9, 18, 48, 56, 27, 27, 8, 45, 31, 17, 30, 41, 48, 18, 33, 26, 35, 48, 30, 8, 46, 31, 48, 58, 8, 45, 17, 11, 17, 33, 30, 21, 48, 23, 50, 8, 35, 18, 31, 53, 17, 30, 41, 48, 53, 56, 11, 48, 56, 48, 9, 8, 41, 17, 30, 30, 17, 30, 41, 48, 56, 30, 58, 48, 56, 30, 48, 8, 30, 58, 21, 48, 43, 17, 27, 8, 48, 17, 11, 48, 39, 26, 11, 31, 48, 56, 48, 45, 18, 45, 37, 8, 48, 33, 27, 48, 11, 31, 56, 35, 31, 11, 48, 56, 30, 58, 48, 11, 31, 33, 44, 11, 21, 48, 32, 53, 8, 35, 8, 48, 56, 35, 8, 48, 8, 30, 58, 11, 48, 60, 8, 48, 58, 33, 30, 10, 31, 48, 58, 8, 11, 17, 35, 8, 54, 48, 9, 26, 31, 48, 31, 53, 8, 18, 10, 35, 8, 48, 17, 30, 8, 50, 17, 31, 56, 9, 37, 8, 54, 48, 60, 8, 48, 53, 56, 50, 8, 48, 31, 33, 48, 27, 56, 45, 8, 48, 31, 53, 8, 19, 21, 48, 2, 31, 10, 11, 48, 60, 53, 56, 31, 48, 9, 8, 17, 30, 41, 48, 53, 26, 19, 56, 30, 48, 17, 11, 48, 56, 37, 37, 48, 56, 9, 33, 26, 31, 21, 48, 36, 30, 18, 31, 53, 17, 30, 41, 48, 45, 56, 30, 48, 53, 56, 44, 44, 8, 30, 21, 48, 16, 33, 48, 33, 30, 8, 48, 8, 50, 8, 35, 48, 31, 53, 17, 30, 34, 11, 48, 17, 31, 48, 60, 17, 37, 37, 48, 26, 30, 31, 17, 37, 48, 17, 31, 48, 58, 33, 8, 11, 21, 48, 3, 53, 56, 31, 48, 60, 17, 37, 37, 48, 53, 56, 44, 44, 8, 30, 54, 48, 53, 56, 44, 44, 8, 30, 11, 21, 48, 32, 53, 56, 31, 10, 11, 48, 53, 33, 60, 48, 31, 53, 8, 48, 60, 33, 35, 37, 58, 48, 17, 11, 21, 48, 32, 53, 8, 48, 19, 33, 11, 31, 48, 17, 19, 44, 33, 35, 31, 56, 30, 31, 48, 31, 53, 17, 30, 41, 48, 17, 11, 48, 31, 33, 48, 30, 33, 31, 48, 37, 8, 31, 48, 31, 53, 8, 48, 31, 35, 56, 41, 8, 58, 18, 48, 58, 8, 27, 8, 56, 31, 48, 18, 33, 26, 21, 48, 32, 33, 48, 9, 8, 37, 17, 8, 50, 8, 48, 31, 53, 56, 31, 48, 18, 33, 26, 48, 45, 56, 30, 48, 41, 8, 31, 48, 31, 53, 35, 33, 26, 41, 53, 48, 17, 31, 21, 48, 7, 33, 26, 10, 37, 37, 48, 33, 30, 37, 18, 48, 35, 8, 56, 37, 17, 22, 8, 48, 31, 53, 56, 31, 48, 18, 33, 26, 48, 31, 35, 26, 37, 18, 48, 37, 33, 50, 8, 48, 11, 33, 19, 8, 33, 30, 8, 48, 17, 27, 48, 31, 53, 8, 18, 48, 56, 37, 35, 8, 56, 58, 18, 48, 45, 56, 26, 11, 8, 58, 48, 18, 33, 26, 48, 8, 30, 33, 35, 19, 33, 26, 11, 48, 44, 56, 17, 30, 21, 48, 7, 33, 26, 35, 48, 8, 30, 8, 19, 17, 8, 11, 48, 45, 56, 30, 48, 30, 8, 50, 8, 35, 48, 53, 26, 35, 31, 48, 18, 33, 26, 48, 31, 53, 8, 48, 60, 56, 18, 48, 18, 33, 26, 35, 48, 37, 33, 50, 8, 58, 48, 33, 30, 8, 11, 48, 45, 56, 30, 21, 48, 2, 31, 10, 11, 48, 31, 53, 8, 48, 44, 8, 33, 44, 37, 8, 48, 45, 37, 33, 11, 8, 48, 31, 33, 48, 18, 33, 26, 35, 48, 53, 8, 56, 35, 31, 48, 31, 53, 56, 31, 48, 45, 56, 30, 48, 41, 17, 50, 8, 48, 18, 33, 26, 48, 31, 53, 8, 48, 19, 33, 11, 31, 48, 44, 17, 8, 35, 45, 17, 30, 41, 48, 60, 33, 26, 30, 58, 21, 48, 43, 33, 50, 8, 48, 17, 11, 48, 56, 48, 58, 33, 26, 9, 37, 8, 29, 8, 58, 41, 8, 58, 48, 11, 60, 33, 35, 58, 54, 48, 17, 31, 48, 45, 56, 30, 48, 53, 8, 56, 37, 48, 31, 53, 8, 48, 60, 33, 26, 30, 58, 48, 27, 56, 11, 31, 8, 35, 48, 33, 35, 48, 17, 31, 48, 45, 56, 30, 48, 11, 17, 30, 34, 48, 31, 53, 8, 48, 9, 37, 56, 58, 8, 48, 8, 50, 8, 30, 48, 58, 8, 8, 44, 8, 35, 21, 48, 2, 48, 60, 56, 30, 31, 48, 18, 33, 26, 48, 31, 33, 48, 9, 8, 48, 53, 56, 44, 44, 18, 21, 48, 2, 48, 60, 56, 30, 31, 48, 18, 33, 26, 48, 31, 33, 48, 37, 56, 26, 41, 53, 48, 56, 48, 37, 33, 31, 21, 48, 2, 48, 58, 33, 30, 10, 31, 48, 34, 30, 33, 60, 48, 60, 53, 56, 31, 48, 8, 46, 56, 45, 31, 37, 18, 48, 2, 10, 37, 37, 48, 9, 8, 48, 56, 9, 37, 8, 48, 31, 33, 48, 58, 33, 48, 27, 33, 35, 48, 18, 33, 26, 54, 48, 9, 26, 31, 48, 2, 10, 37, 37, 48, 56, 37, 60, 56, 18, 11, 48, 9, 8, 48, 9, 18, 48, 18, 33, 26, 35, 48, 11, 17, 58, 8, 21, 48, 1, 36, 48, 37, 8, 11, 11, 33, 30, 48, 60, 17, 31, 53, 33, 26, 31, 48, 44, 56, 17, 30, 48, 17, 11, 48, 19, 8, 56, 30, 17, 30, 41, 37, 8, 11, 11, 21, 48, 32, 53, 56, 31, 10, 11, 48, 9, 8, 45, 56, 26, 11, 8, 48, 30, 33, 48, 33, 30, 8, 48, 45, 56, 30, 48, 41, 56, 17, 30, 48, 60, 17, 31, 53, 33, 26, 31, 48, 11, 56, 45, 35, 17, 27, 17, 45, 17, 30, 41, 48, 11, 33, 19, 8, 31, 53, 17, 30, 41, 21, 48, 12, 26, 31, 48, 9, 18, 48, 8, 30, 58, 26, 35, 17, 30, 41, 48, 31, 53, 56, 31, 48, 44, 56, 17, 30, 48, 56, 30, 58, 48, 33, 50, 8, 35, 45, 33, 19, 17, 30, 41, 48, 17, 31, 54, 48, 53, 8, 48, 11, 53, 56, 37, 37, 48, 33, 9, 31, 56, 17, 30, 48, 56, 48, 44, 33, 60, 8, 35, 27, 26, 37, 54, 48, 26, 30, 19, 56, 31, 45, 53, 8, 58, 48, 53, 8, 56, 35, 31, 21, 15, 48, 7, 33, 26, 48, 30, 8, 8, 58, 48, 31, 33, 48, 56, 45, 45, 8, 44, 31, 48, 31, 53, 8, 48, 27, 56, 45, 31, 48, 31, 53, 56, 31, 48, 18, 33, 26, 10, 35, 8, 48, 30, 33, 31, 48, 31, 53, 8, 48, 9, 8, 11, 31, 48, 56, 30, 58, 48, 53, 56, 50, 8, 48, 56, 37, 37, 48, 31, 53, 8, 48, 60, 17, 37, 37, 48, 31, 33, 48, 11, 31, 35, 17, 50, 8, 48, 31, 33, 48, 9, 8, 48, 9, 8, 31, 31, 8, 35, 48, 31, 53, 56, 30, 48, 56, 30, 18, 33, 30, 8, 48, 18, 33, 26, 48, 27, 56, 45, 8, 21, 48, 2, 48, 31, 33, 33, 48, 60, 17, 37, 37, 48, 33, 9, 31, 56, 17, 30, 48, 8, 50, 8, 35, 18, 31, 53, 17, 30, 41, 48, 31, 53, 56, 31, 48, 2, 48, 58, 8, 11, 17, 35, 8, 21, 48, 16, 33, 31, 48, 9, 8, 45, 56, 26, 11, 8, 48, 11, 33, 19, 8, 33, 30, 8, 48, 56, 11, 34, 8, 58, 48, 19, 8, 48, 31, 33, 48, 58, 33, 48, 17, 31, 54, 48, 9, 26, 31, 48, 9, 8, 45, 56, 26, 11, 8, 48, 2, 48, 34, 30, 33, 60, 48, 17, 30, 48, 19, 18, 48, 53, 8, 56, 35, 31, 48, 31, 53, 56, 31, 48, 2, 48, 53, 56, 50, 8, 48, 11, 33, 19, 8, 31, 53, 17, 30, 41, 48, 60, 33, 35, 31, 53, 48, 27, 17, 41, 53, 31, 17, 30, 41, 48, 27, 33, 35, 21, 48, 7, 33, 26, 48, 45, 56, 30, 10, 31, 48, 60, 17, 30, 48, 56, 48, 41, 56, 19, 8, 48, 9, 18, 48, 58, 33, 17, 30, 41, 48, 30, 33, 31, 53, 17, 30, 41, 21, 48, 36, 30, 58, 48, 17, 27, 48, 11, 33, 19, 8, 33, 30, 8, 48, 8, 37, 11, 8, 48, 60, 17, 30, 11, 48, 17, 31, 48, 27, 33, 35, 48, 18, 33, 26, 48, 31, 53, 8, 30, 48, 18, 33, 26, 48, 53, 56, 50, 8, 30, 10, 31, 48, 56, 45, 45, 33, 19, 44, 37, 17, 11, 53, 8, 58, 48, 56, 30, 18, 31, 53, 17, 30, 41, 21, 48, 43, 17, 27, 8, 48, 17, 11, 48, 31, 53, 8, 48, 11, 56, 19, 8, 48, 60, 56, 18, 21, 48, 25, 33, 48, 30, 33, 31, 48, 31, 53, 17, 30, 34, 48, 56, 9, 33, 26, 31, 48, 33, 31, 53, 8, 35, 48, 31, 53, 17, 30, 41, 11, 54, 48, 31, 53, 8, 35, 8, 48, 17, 11, 48, 33, 30, 37, 18, 48, 33, 30, 8, 48, 31, 53, 17, 30, 41, 48, 18, 33, 26, 48, 45, 56, 30, 48, 58, 33, 21, 48, 57, 33, 48, 19, 56, 11, 31, 8, 35, 48, 31, 53, 56, 31, 48, 33, 30, 8, 48, 31, 53, 17, 30, 41, 21, 48, 25, 33, 48, 30, 33, 31, 48, 27, 33, 35, 41, 8, 31, 21, 48, 3, 53, 56, 31, 48, 18, 33, 26, 48, 19, 26, 11, 31, 48, 17, 19, 56, 41, 17, 30, 8, 48, 17, 11, 48, 56, 37, 60, 56, 18, 11, 48, 31, 53, 56, 31, 48, 18, 33, 26, 54, 48, 18, 33, 26, 35, 11, 8, 37, 27, 54, 48, 56, 35, 8, 48, 31, 53, 8, 48, 11, 31, 35, 33, 30, 41, 8, 11, 31, 21, 48, 7, 33, 26, 48, 58, 33, 48, 30, 33, 31, 48, 30, 8, 8, 58, 48, 33, 26, 31, 11, 17, 58, 8, 48, 8, 30, 8, 19, 17, 8, 11, 21, 48, 5, 33, 35, 48, 18, 33, 26, 54, 48, 31, 53, 8, 48, 33, 30, 8, 48, 18, 33, 26, 48, 53, 56, 50, 8, 48, 31, 33, 48, 27, 17, 41, 53, 31, 48, 17, 11, 48, 30, 33, 30, 8, 48, 33, 31, 53, 8, 35, 48, 31, 53, 56, 30, 48, 18, 33, 26, 35, 48, 33, 60, 30, 48, 17, 19, 56, 41, 8, 21, 48, 43, 17, 27, 8, 48, 17, 11, 48, 37, 17, 34, 8, 48, 56, 48, 31, 26, 9, 8, 48, 33, 27, 48, 31, 33, 33, 31, 53, 44, 56, 11, 31, 8, 21, 48, 3, 53, 8, 30, 48, 18, 33, 26, 10, 50, 8, 48, 26, 11, 8, 58, 48, 56, 37, 37, 48, 31, 53, 8, 48, 31, 33, 33, 31, 53, 44, 56, 11, 31, 8, 48, 58, 33, 60, 30, 48, 31, 33, 48, 31, 53, 8, 48, 37, 56, 11, 31, 48, 11, 47, 26, 8, 8, 22, 8, 54, 48, 31, 53, 56, 31, 10, 11, 48, 60, 53, 8, 30, 48, 18, 33, 26, 10, 50, 8, 48, 35, 8, 56, 37, 37, 18, 48, 37, 17, 50, 8, 58, 21, 48, 43, 17, 50, 8, 48, 60, 17, 31, 53, 48, 56, 37, 37, 48, 18, 33, 26, 35, 48, 19, 17, 41, 53, 31, 54, 48, 56, 30, 58, 48, 11, 31, 35, 26, 41, 41, 37, 8, 48, 56, 11, 48, 37, 33, 30, 41, 48, 56, 11, 48, 18, 33, 26, 48, 53, 56, 50, 8, 48, 37, 17, 27, 8, 21, 15, 48, 52, 26, 11, 31, 48, 37, 17, 34, 8, 13, 41, 56, 19, 8, 11, 54, 48, 30, 33, 48, 19, 56, 31, 31, 8, 35, 48, 53, 33, 60, 48, 60, 8, 37, 37, 48, 18, 33, 26, 48, 53, 56, 50, 8, 48, 31, 53, 17, 30, 41, 11, 48, 37, 17, 30, 8, 58, 48, 26, 44, 48, 17, 30, 48, 18, 33, 26, 35, 48, 37, 17, 27, 8, 54, 48, 31, 53, 8, 35, 8, 10, 11, 48, 56, 37, 60, 56, 18, 11, 48, 11, 33, 19, 8, 31, 53, 17, 30, 41, 48, 31, 33, 48, 34, 8, 8, 44, 48, 18, 33, 26, 48, 33, 30, 48, 18, 33, 26, 35, 48, 31, 33, 8, 11, 21, 48, 25, 33, 48, 8, 46, 56, 45, 31, 37, 18, 48, 56, 11, 48, 18, 33, 26, 48, 37, 17, 34, 8, 21, 48, 32, 53, 56, 31, 48, 17, 11, 48, 31, 53, 8, 48, 31, 35, 26, 8, 48, 19, 8, 56, 30, 17, 30, 41, 48, 33, 27, 48, 44, 37, 8, 56, 11, 26, 35, 8, 21, 48, 0, 37, 8, 56, 11, 26, 35, 8, 48, 37, 8, 56, 58, 11, 48, 31, 33, 48, 39, 33, 18, 48, 56, 30, 58, 48, 39, 33, 18, 48, 37, 8, 56, 58, 11, 48, 31, 33, 48, 53, 56, 44, 44, 17, 30, 8, 11, 11, 21, 48, 2, 31, 48, 25, 33, 8, 11, 30, 48, 31, 48, 6, 56, 31, 31, 8, 35, 48, 40, 33, 60, 48, 57, 31, 35, 33, 30, 41, 48, 32, 53, 8, 48, 49, 44, 44, 33, 11, 17, 31, 17, 33, 30, 48, 2, 11, 48, 2, 31, 48, 25, 33, 8, 11, 30, 48, 31, 48, 6, 56, 31, 31, 8, 35, 48, 40, 33, 60, 48, 5, 8, 56, 35, 11, 33, 19, 8, 48, 32, 53, 8, 48, 3, 33, 35, 37, 58, 48, 2, 11, 48, 2, 31, 48, 25, 33, 8, 11, 30, 48, 31, 48, 6, 56, 31, 31, 8, 35, 48, 40, 33, 60, 48, 59, 35, 26, 8, 37, 48, 32, 53, 8, 48, 3, 33, 35, 37, 58, 48, 2, 11, 48, 5, 17, 41, 53, 31, 48, 2, 27, 48, 32, 53, 8, 35, 8, 48, 36, 35, 8, 48, 40, 26, 19, 56, 30, 11, 48, 3, 53, 33, 48, 59, 56, 30, 48, 12, 35, 17, 30, 41, 48, 36, 9, 33, 26, 31, 48, 59, 53, 56, 30, 41, 8, 48, 32, 53, 8, 18, 48, 35, 8, 48, 32, 53, 33, 11, 8, 48, 3, 53, 33, 48, 36, 35, 8, 48, 59, 56, 44, 56, 9, 37, 8, 48, 49, 27, 48, 36, 9, 56, 30, 58, 33, 30, 17, 30, 41, 48, 23, 50, 8, 35, 18, 31, 53, 17, 30, 41, 48, 0, 8, 33, 44, 37, 8, 48, 3, 53, 33, 48, 3, 53, 8, 30, 48, 14, 8, 47, 26, 17, 35, 8, 58, 48, 32, 33, 48, 57, 26, 35, 44, 56, 11, 11, 48, 23, 50, 8, 30, 48, 6, 33, 30, 11, 31, 8, 35, 11, 48, 36, 35, 8, 48, 59, 56, 44, 56, 9, 37, 8, 48, 49, 27, 48, 32, 33, 11, 11, 17, 30, 41, 48, 36, 11, 17, 58, 8, 48, 32, 53, 8, 17, 35, 48, 24, 8, 35, 18, 48, 40, 26, 19, 56, 30, 17, 31, 18, 48, 2, 48, 25, 33, 30, 48, 31, 48, 43, 17, 34, 8, 48, 32, 53, 8, 48, 32, 8, 35, 19, 11, 48, 42, 33, 33, 58, 48, 0, 8, 35, 11, 33, 30, 48, 33, 35, 48, 12, 56, 58, 48, 0, 8, 35, 11, 33, 30, 48, 2, 31, 48, 2, 11, 48, 2, 19, 44, 33, 11, 11, 17, 9, 37, 8, 48, 32, 33, 48, 12, 8, 48, 23, 30, 31, 17, 35, 8, 37, 18, 48, 42, 33, 33, 58, 48, 32, 33, 48, 23, 50, 8, 35, 18, 33, 30, 8, 48, 32, 33, 48, 57, 33, 19, 8, 48, 7, 33, 26, 48, 36, 35, 8, 48, 36, 48, 42, 33, 33, 58, 48, 0, 8, 35, 11, 33, 30, 48, 3, 53, 17, 37, 8, 48, 32, 33, 48, 49, 31, 53, 8, 35, 11, 48, 7, 33, 26, 48, 36, 35, 8, 48, 36, 48, 12, 56, 58, 48, 0, 8, 35, 11, 33, 30, 48, 36, 11, 48, 43, 33, 30, 41, 48, 36, 11, 48, 3, 8, 48, 59, 33, 30, 31, 17, 30, 26, 8, 48, 32, 33, 48, 5, 17, 41, 53, 31, 48, 3, 8, 48, 36, 35, 8, 48, 16, 33, 31, 48, 25, 8, 27, 8, 56, 31, 8, 58, 48, 2, 27, 48, 7, 33, 26, 48, 3, 17, 30, 48, 7, 33, 26, 48, 43, 17, 50, 8, 48, 2, 27, 48, 7, 33, 26, 48, 43, 33, 11, 8, 48, 7, 33, 26, 48, 25, 17, 8, 48, 2, 27, 48, 7, 33, 26, 48, 25, 33, 30, 48, 31, 48, 5, 17, 41, 53, 31, 48, 7, 33, 26, 48, 59, 56, 30, 48, 31, 48, 3, 17, 30, 48, 7, 33, 26, 48, 4, 30, 58, 8, 35, 11, 31, 56, 30, 58, 48, 25, 33, 30, 48, 31, 48, 7, 33, 26, 48, 49, 30, 8, 48, 25, 56, 18, 48, 49, 35, 48, 36, 30, 33, 31, 53, 8, 35, 48, 23, 50, 8, 35, 18, 33, 30, 8, 48, 7, 33, 26, 48, 59, 56, 35, 8, 48, 36, 9, 33, 26, 31, 48, 23, 50, 8, 30, 31, 26, 56, 37, 37, 18, 48, 25, 17, 8, 11, 48, 2, 31, 48, 11, 48, 57, 33, 19, 8, 31, 53, 17, 30, 41, 48, 3, 8, 48, 57, 17, 19, 44, 37, 18, 48, 59, 56, 30, 48, 31, 48, 36, 45, 45, 8, 44, 31, 48, 2, 31, 48, 11, 48, 36, 48, 14, 8, 56, 37, 17, 22, 56, 31, 17, 33, 30, 48, 32, 53, 56, 31, 48, 59, 33, 26, 37, 58, 48, 25, 35, 17, 50, 8, 48, 7, 33, 26, 48, 2, 30, 11, 56, 30, 8, 48, 7, 33, 26, 48, 35, 8, 48, 42, 33, 30, 30, 56, 48, 59, 56, 35, 8, 48, 3, 53, 56, 31, 48, 49, 31, 53, 8, 35, 48, 0, 8, 33, 44, 37, 8, 48, 32, 53, 17, 30, 34, 48, 36, 30, 58, 48, 12, 8, 48, 57, 33, 19, 8, 33, 30, 8, 48, 7, 33, 26, 48, 35, 8, 48, 16, 33, 31, 48, 7, 33, 26, 35, 48, 3, 53, 33, 37, 8, 48, 43, 17, 27, 8, 48, 7, 33, 26, 48, 35, 8, 48, 5, 17, 30, 8, 48, 36, 11, 48, 7, 33, 26, 48, 36, 35, 8, 48, 57, 33, 48, 32, 56, 37, 34, 48, 2, 30, 48, 7, 33, 26, 35, 48, 49, 60, 30, 48, 3, 33, 35, 58, 11, 48, 23, 50, 8, 35, 18, 33, 30, 8, 48, 40, 56, 58, 48, 32, 33, 48, 12, 8, 48, 25, 35, 26, 30, 34, 48, 49, 30, 48, 57, 33, 19, 8, 31, 53, 17, 30, 48, 32, 33, 48, 55, 8, 8, 44, 48, 0, 26, 11, 53, 17, 30, 41, 48, 49, 30, 48, 23, 50, 8, 35, 18, 33, 30, 8, 48, 3, 56, 11, 48, 36, 48, 57, 37, 56, 50, 8, 48, 32, 33, 48, 57, 33, 19, 8, 31, 53, 17, 30, 48, 32, 53, 17, 11, 48, 3, 33, 35, 37, 58, 48, 2, 11, 48, 59, 35, 26, 8, 37, 48, 36, 30, 58, 48, 2, 31, 48, 11, 48, 36, 37, 11, 33, 48, 24, 8, 35, 18, 48, 12, 8, 56, 26, 31, 17, 27, 26, 37, 48, 16, 33, 48, 49, 30, 8, 48, 55, 30, 33, 60, 11, 48, 3, 53, 56, 31, 48, 32, 53, 8, 48, 49, 26, 31, 45, 33, 19, 8, 48, 3, 17, 37, 37, 48, 12, 8, 48, 57, 33, 48, 59, 53, 33, 33, 11, 8, 48, 3, 53, 56, 31, 8, 50, 8, 35, 48, 7, 33, 26, 48, 37, 37, 48, 14, 8, 41, 35, 8, 31, 48, 32, 53, 8, 48, 43, 8, 56, 11, 31, 48, 25, 33, 48, 18, 33, 26, 48, 30, 8, 8, 58, 48, 56, 48, 35, 8, 56, 11, 33, 30, 48, 31, 33, 48, 30, 33, 31, 48, 60, 56, 30, 31, 48, 31, 33, 48, 37, 33, 11, 8, 48, 12, 8, 17, 30, 41, 48, 31, 53, 8, 48, 9, 8, 11, 31, 48, 58, 8, 45, 33, 18, 48, 8, 50, 8, 35, 48, 17, 11, 48, 56, 11, 48, 45, 33, 33, 37, 48, 56, 11, 48, 9, 8, 17, 30, 41, 48, 31, 53, 8, 48, 56, 45, 8, 48, 7, 33, 26, 48, 45, 56, 30, 48, 27, 37, 18, 48, 8, 50, 8, 30, 48, 53, 17, 41, 53, 8, 35, 48, 2, 27, 48, 31, 53, 8, 18, 48, 56, 58, 39, 26, 11, 31, 48, 31, 33, 48, 19, 8, 48, 2, 48, 53, 56, 50, 8, 48, 31, 33, 48, 56, 58, 39, 26, 11, 31, 48, 17, 30, 48, 31, 26, 35, 30, 48, 3, 53, 33, 8, 50, 8, 35, 48, 11, 31, 33, 44, 11, 48, 56, 58, 39, 26, 11, 31, 17, 30, 41, 48, 60, 33, 30, 48, 31, 48, 9, 8, 48, 56, 9, 37, 8, 48, 31, 33, 48, 45, 33, 30, 31, 17, 30, 26, 8, 48, 27, 33, 35, 60, 56, 35, 58, 48, 32, 53, 8, 48, 37, 56, 11, 31, 48, 33, 30, 8, 11, 48, 11, 31, 56, 30, 58, 17, 30, 41, 48, 56, 35, 8, 48, 31, 53, 8, 48, 50, 17, 45, 31, 33, 35, 11, 48, 49, 30, 37, 18, 48, 31, 53, 8, 48, 11, 31, 35, 33, 30, 41, 8, 11, 31, 48, 2, 27, 48, 18, 33, 26, 48, 60, 56, 30, 31, 48, 31, 33, 48, 9, 8, 48, 31, 53, 8, 48, 37, 56, 11, 31, 48, 33, 30, 8, 48, 11, 31, 56, 30, 58, 17, 30, 41, 48, 9, 8, 45, 33, 19, 8, 48, 11, 31, 35, 33, 30, 41, 48, 43, 17, 27, 8, 48, 11, 48, 56, 48, 9, 33, 35, 8, 48, 17, 27, 48, 18, 33, 26, 48, 58, 33, 30, 48, 31, 48, 45, 53, 56, 37, 37, 8, 30, 41, 8, 48, 18, 33, 26, 35, 11, 8, 37, 27, 48, 32, 53, 8, 35, 8, 48, 56, 35, 8, 48, 11, 33, 19, 8, 48, 27, 37, 33, 60, 8, 35, 11, 48, 18, 33, 26, 48, 33, 30, 37, 18, 48, 11, 8, 8, 48, 60, 53, 8, 30, 48, 18, 33, 26, 48, 31, 56, 34, 8, 48, 58, 8, 31, 33, 26, 35, 11, 48, 12, 8, 17, 30, 41, 48, 60, 8, 56, 34, 48, 19, 8, 56, 30, 11, 48, 31, 53, 56, 31, 48, 31, 53, 8, 35, 8, 48, 17, 11, 48, 35, 33, 33, 19, 48, 31, 33, 48, 41, 35, 33, 60, 48, 32, 33, 58, 56, 18, 48, 19, 17, 41, 53, 31, 48, 9, 8, 48, 31, 53, 8, 48, 45, 53, 56, 30, 45, 8, 48, 31, 33, 48, 41, 35, 56, 11, 44, 48, 31, 53, 8, 48, 45, 53, 56, 30, 45, 8, 48, 31, 33, 48, 37, 8, 31, 48, 18, 33, 26, 35, 48, 31, 56, 37, 8, 30, 31, 48, 9, 37, 33, 33, 19, 48, 2, 27, 48, 18, 33, 26, 48, 35, 8, 48, 41, 33, 30, 30, 56, 48, 53, 17, 31, 48, 17, 31, 48, 53, 17, 31, 48, 17, 31, 48, 26, 30, 31, 17, 37, 48, 17, 31, 48, 9, 35, 8, 56, 34, 11]\n","Length of sequence: 12501\n"]}],"source":["# Convert the text data into sequences\n","sequences = []\n","for char in all_anime_quotes:\n","  token = char_to_token[char]\n","  sequences.append(token)\n","\n","print(sequences)\n","print(f\"Length of sequence: {len(sequences)}\")\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"x0nhxpTS300t","executionInfo":{"status":"ok","timestamp":1660511909222,"user_tz":-60,"elapsed":282,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}}},"outputs":[],"source":["# From the sequence_data create a list containing\n","sequence_length = 100\n","sequences_as_tf_data = tf.data.Dataset.from_tensor_slices(sequences).batch(sequence_length+1, drop_remainder=True)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1660511910562,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"},"user_tz":-60},"id":"52eLBp2r-NKB","outputId":"f57a79af-e208-4257-e930-081ffbb213ad"},"outputs":[{"output_type":"stream","name":"stdout","text":["People’s lives don’t end when they die, it ends when they lose faith. If you don’t take risks, you ca\n","n’t create a future! If you don’t like your destiny, don’t accept it. When you give up, that’s when t\n"]}],"source":["# display the 2 samples from the dataset\n","for sample in sequences_as_tf_data.take(2):\n","  print(\"\".join([token_to_char[token] for token in sample.numpy()]))"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"ow8IY9-d_jnL","executionInfo":{"status":"ok","timestamp":1660511911527,"user_tz":-60,"elapsed":3,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}}},"outputs":[],"source":["# Split sequences into features and labels\n","def split_sequence(sequence):\n","  feature = sequence[:-1]\n","  label = sequence[1:]\n","  return feature, label\n"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":269,"status":"ok","timestamp":1660511913844,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"},"user_tz":-60},"id":"QVdTfXhn_9h3","outputId":"80c9f4b4-b923-4b4a-c5a1-83a45a09d63e"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Feature, Label pair\n","People’s lives don’t end when they die, it ends when they lose faith. If you don’t take risks, you c\n","eople’s lives don’t end when they die, it ends when they lose faith. If you don’t take risks, you ca\n","\n","Feature, Label pair\n","n’t create a future! If you don’t like your destiny, don’t accept it. When you give up, that’s when \n","’t create a future! If you don’t like your destiny, don’t accept it. When you give up, that’s when t\n"]}],"source":["# try it out on the 2 samples\n","for sample in sequences_as_tf_data.take(2):\n","  (feature, label) = split_sequence(sample.numpy())\n","  print(\"\\nFeature, Label pair\")\n","  print(\"\".join([token_to_char[token] for token in feature]))\n","  print(\"\".join([token_to_char[token] for token in label]))\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":423,"status":"ok","timestamp":1660511916187,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"},"user_tz":-60},"id":"gtMyzHZPBrdl","outputId":"762ea3a6-201a-4118-9a34-e87e5bea783b"},"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[ 0  8 33 44 37  8 10 11 48 37 17 50  8 11 48 58 33 30 10 31 48  8 30 58\n"," 48 60 53  8 30 48 31 53  8 18 48 58 17  8 54 48 17 31 48  8 30 58 11 48\n"," 60 53  8 30 48 31 53  8 18 48 37 33 11  8 48 27 56 17 31 53 21 48  2 27\n"," 48 18 33 26 48 58 33 30 10 31 48 31 56 34  8 48 35 17 11 34 11 54 48 18\n"," 33 26 48 45], shape=(100,), dtype=int32)\n","tf.Tensor(\n","[ 8 33 44 37  8 10 11 48 37 17 50  8 11 48 58 33 30 10 31 48  8 30 58 48\n"," 60 53  8 30 48 31 53  8 18 48 58 17  8 54 48 17 31 48  8 30 58 11 48 60\n"," 53  8 30 48 31 53  8 18 48 37 33 11  8 48 27 56 17 31 53 21 48  2 27 48\n"," 18 33 26 48 58 33 30 10 31 48 31 56 34  8 48 35 17 11 34 11 54 48 18 33\n"," 26 48 45 56], shape=(100,), dtype=int32)\n"]}],"source":["# Apply the split_sequence function to the dataset\n","feature_label_data = sequences_as_tf_data.map(split_sequence)\n","\n","for feature, label in feature_label_data.take(1):\n","  print(feature)\n","  print(label)\n"]},{"cell_type":"markdown","metadata":{"id":"wg-agsE_CipS"},"source":["We have our text data prepared. Inputs to the model is a sequence of tokens and the label is also the same sequence shifted by 1 to the right."]},{"cell_type":"code","execution_count":15,"metadata":{"id":"F3jloXi2CWUt","executionInfo":{"status":"ok","timestamp":1660511918769,"user_tz":-60,"elapsed":353,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}}},"outputs":[],"source":["# might be easier to convert sequences to strings if we define a function to convert it\n","\n","def convert_sequence_to_string(sequence):\n","  string = \"\".join([token_to_char[token] for token in sequence])\n","  return string\n"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":441,"status":"ok","timestamp":1660511920982,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"},"user_tz":-60},"id":"HTAShoOJEUs2","outputId":"d3c82bfe-6410-4d77-9db8-8e02e0274b76"},"outputs":[{"output_type":"stream","name":"stdout","text":["People’s lives don’t end when they die, it ends when they lose faith. If you don’t take risks, you c\n","eople’s lives don’t end when they die, it ends when they lose faith. If you don’t take risks, you ca\n"]}],"source":["for feature, label in feature_label_data.take(1):\n","  print(convert_sequence_to_string(feature.numpy()))\n","  print(convert_sequence_to_string(label.numpy()))"]},{"cell_type":"code","source":["# create a batched dataset\n","batched_dataset = (feature_label_data.batch(1))"],"metadata":{"id":"_yuzZP2BNgub","executionInfo":{"status":"ok","timestamp":1660511921371,"user_tz":-60,"elapsed":3,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6UmqtMZAEmK7"},"source":["# **Define the RNN model**"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"0fTe2asMKOUg","executionInfo":{"status":"ok","timestamp":1660512409056,"user_tz":-60,"elapsed":610,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}}},"outputs":[],"source":["vocab_szie = 61\n","Embedding_dim = 128\n","GRU_units = 256\n"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":430,"status":"ok","timestamp":1660512411361,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"},"user_tz":-60},"id":"SeimhMxgEtmI"},"outputs":[],"source":["# define a text generation model\n","Anime_qoutes_model = tf.keras.Sequential([tf.keras.layers.Embedding(vocab_size, Embedding_dim),\n","                                         tf.keras.layers.GRU(units=GRU_units, dropout=0.5, \n","                                                             recurrent_dropout=0.25,\n","                                                             return_sequences=True),\n","                                         tf.keras.layers.Dense(units=vocab_size, activation=\"softmax\")])\n"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"ZK6n-foDU4kQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660512414121,"user_tz":-60,"elapsed":28,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"0a688ec9-06fc-40a8-80a9-a03ff9101d09"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_2 (Embedding)     (None, None, 128)         7808      \n","                                                                 \n"," gru_2 (GRU)                 (None, None, 256)         296448    \n","                                                                 \n"," dense_2 (Dense)             (None, None, 61)          15677     \n","                                                                 \n","=================================================================\n","Total params: 319,933\n","Trainable params: 319,933\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["# Compile the model\n","Anime_qoutes_model.compile(optimizer='adam',\n","                           loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","                           )\n","\n","Anime_qoutes_model.summary()"]},{"cell_type":"markdown","source":["Some notes missed out from an unsaved version\n","- Batch dimension in the data is needed for RNN \n","- SparseCategoricalCrossentropy used for multiclass classification when expected labels are integers and not one-hot encoded labels.\n","- Use categoricalCrossentropy loss for multiclass classifications with one-hot encoded labels"],"metadata":{"id":"AO_-TfITPX5A"}},{"cell_type":"markdown","source":["# **Train the model**"],"metadata":{"id":"ssFrk2CkN6YY"}},{"cell_type":"code","source":["# define the model call backs\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=\"./model_checkpoints/model_epoch_{epoch}_loss_{loss}\",\n","                                                               monitor='loss',\n","                                                               save_best_only=True)\n","early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta=0.1, patience=4)"],"metadata":{"id":"2Gq2u284OEeD","executionInfo":{"status":"ok","timestamp":1660512417447,"user_tz":-60,"elapsed":408,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["history = Anime_qoutes_model.fit(batched_dataset, epochs=22,\n","                                 callbacks=[model_checkpoint_callback, early_stopping_callback])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":834},"id":"x6qd0RXwO5zS","executionInfo":{"status":"error","timestamp":1660513061897,"user_tz":-60,"elapsed":643081,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"718691da-818a-4576-c249-4a0914f22442"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/22\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n","  return dispatch_target(*args, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["123/123 [==============================] - ETA: 0s - loss: 2.9948"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f4fa793d150> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 63s 488ms/step - loss: 2.9948\n","Epoch 2/22\n","123/123 [==============================] - ETA: 0s - loss: 2.4452"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f4fa793d150> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 61s 498ms/step - loss: 2.4452\n","Epoch 3/22\n","123/123 [==============================] - ETA: 0s - loss: 2.3100"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f4fa793d150> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 61s 499ms/step - loss: 2.3100\n","Epoch 4/22\n","123/123 [==============================] - ETA: 0s - loss: 2.2194"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f4fa793d150> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 61s 498ms/step - loss: 2.2194\n","Epoch 5/22\n","123/123 [==============================] - ETA: 0s - loss: 2.1428"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f4fa793d150> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 63s 509ms/step - loss: 2.1428\n","Epoch 6/22\n","123/123 [==============================] - ETA: 0s - loss: 2.0680"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f4fa793d150> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 62s 507ms/step - loss: 2.0680\n","Epoch 7/22\n","123/123 [==============================] - ETA: 0s - loss: 1.9964"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f4fa793d150> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 61s 499ms/step - loss: 1.9964\n","Epoch 8/22\n","123/123 [==============================] - ETA: 0s - loss: 1.9325"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f4fa793d150> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 65s 524ms/step - loss: 1.9325\n","Epoch 9/22\n","123/123 [==============================] - ETA: 0s - loss: 1.8625"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-a52d553580c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m history = Anime_qoutes_model.fit(batched_dataset, epochs=22,\n\u001b[0;32m----> 2\u001b[0;31m                                  callbacks=[model_checkpoint_callback, early_stopping_callback])\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1433\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1435\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1436\u001b[0m         \u001b[0mtraining_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m       \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_should_save_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_save_model\u001b[0;34m(self, epoch, batch, logs)\u001b[0m\n\u001b[1;32m   1441\u001b[0m                     filepath, overwrite=True, options=self._options)\n\u001b[1;32m   1442\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1444\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m   2383\u001b[0m     \u001b[0;31m# pylint: enable=line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2384\u001b[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0;32m-> 2385\u001b[0;31m                     signatures, options, save_traces)\n\u001b[0m\u001b[1;32m   2386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2387\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtraceback_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSharedObjectSavingScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m       saved_model_save.save(model, filepath, overwrite, include_optimizer,\n\u001b[0;32m--> 152\u001b[0;31m                             signatures, options, save_traces)\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(model, filepath, overwrite, include_optimizer, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_option_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_traces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m       saved_nodes, node_paths = save_lib.save_and_return_nodes(\n\u001b[0;32m---> 94\u001b[0;31m           model, filepath, signatures, options)\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# Save all metadata to a separate file in the SavedModel directory.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36msave_and_return_nodes\u001b[0;34m(obj, export_dir, signatures, options, experimental_skip_checkpoint)\u001b[0m\n\u001b[1;32m   1367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m   _, exported_graph, object_saver, asset_info, saved_nodes, node_paths = (\n\u001b[0;32m-> 1369\u001b[0;31m       _build_meta_graph(obj, signatures, options, meta_graph_def))\n\u001b[0m\u001b[1;32m   1370\u001b[0m   saved_model.saved_model_schema_version = (\n\u001b[1;32m   1371\u001b[0m       constants.SAVED_MODEL_SCHEMA_VERSION)\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_build_meta_graph\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0msave_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1536\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_build_meta_graph_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_build_meta_graph_impl\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1486\u001b[0m   \u001b[0;31m# Use _SaveableView to provide a frozen listing of properties and functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m   saveable_view = _SaveableView(checkpoint_graph_view, options,\n\u001b[0;32m-> 1488\u001b[0;31m                                 wrapped_functions)\n\u001b[0m\u001b[1;32m   1489\u001b[0m   \u001b[0mobject_saver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrackableSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_graph_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1490\u001b[0m   asset_info, exported_graph = _fill_meta_graph_def(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, checkpoint_view, options, wrapped_functions)\u001b[0m\n\u001b[1;32m    197\u001b[0m     (self._trackable_objects, self.node_paths, self.node_ids,\n\u001b[1;32m    198\u001b[0m      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slot_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m          self.checkpoint_view.objects_ids_and_slot_variables_and_paths())\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_save_and_restore_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/graph_view.py\u001b[0m in \u001b[0;36mobjects_ids_and_slot_variables_and_paths\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    604\u001b[0m                   object -> node id, slot variables, object_names)\n\u001b[1;32m    605\u001b[0m     \"\"\"\n\u001b[0;32m--> 606\u001b[0;31m     \u001b[0mtrackable_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_breadth_first_traversal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m     \u001b[0mobject_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectIdentityDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode_paths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/graph_view.py\u001b[0m in \u001b[0;36m_breadth_first_traversal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    306\u001b[0m       \u001b[0mcurrent_trackable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_visit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m       \u001b[0mbfs_sorted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_trackable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdependency\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_trackable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdependency\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode_paths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m           node_paths[dependency] = (\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36mlist_children\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    134\u001b[0m               \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m               \u001b[0msave_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaveType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVEDMODEL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m               cache=self._serialization_cache))\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_children_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m       \u001b[0;32myield\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrackableReference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/graph_view.py\u001b[0m in \u001b[0;36mlist_children\u001b[0;34m(self, obj, save_type, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_initialize_trackable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     children = [base.TrackableReference(name, ref) for name, ref\n\u001b[0;32m--> 256\u001b[0;31m                 in obj._trackable_children(save_type, **kwargs).items()]\n\u001b[0m\u001b[1;32m    257\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_trackable_children\u001b[0;34m(self, save_type, **kwargs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0msave_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSaveType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVEDMODEL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m       \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cache\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_legacy_saved_model_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1480\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m       raise ValueError(\"Unexpected format passed to `_trackable_children`. \"\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_get_legacy_saved_model_children\u001b[0;34m(self, serialization_cache)\u001b[0m\n\u001b[1;32m   1497\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcore_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenericFunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1499\u001b[0;31m         \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_list_all_concrete_functions_for_serialization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m     \u001b[0;31m# Retrieve children that are only included when exporting SavedModel.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_list_all_concrete_functions_for_serialization\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1218\u001b[0m     \u001b[0mconcrete_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseen_signatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1220\u001b[0;31m       \u001b[0mconcrete_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1221\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcrete_functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1262\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m     \u001b[0;31m# Implements GenericFunction.get_concrete_function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m     \u001b[0mconcrete\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concrete_function_garbage_collected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1265\u001b[0m     \u001b[0mconcrete\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcrete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1254\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m       concrete = self._stateful_fn._get_concrete_function_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m-> 1256\u001b[0;31m           *args, **kwargs)\n\u001b[0m\u001b[1;32m   1257\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3034\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3035\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3036\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3037\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3038\u001b[0m       captured = object_identity.ObjectIdentitySet(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_call_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3292\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3293\u001b[0m           self._function_cache.add(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   3294\u001b[0m                                    graph_function)\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3138\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3139\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3140\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3141\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/save_impl.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m       with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m    571\u001b[0m           layer._compute_dtype_object):  # pylint: disable=protected-access\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m     \u001b[0m_restore_layer_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/utils.py\u001b[0m in \u001b[0;36mwrap_with_training_arg\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     return control_flow_util.smart_cond(\n\u001b[1;32m    169\u001b[0m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreplace_training_and_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         lambda: replace_training_and_call(False))\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m   \u001b[0;31m# Create arg spec for decorated function. If 'training' is not defined in the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/control_flow_util.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m    104\u001b[0m         pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[1;32m    105\u001b[0m   return tf.__internal__.smart_cond.smart_cond(\n\u001b[0;32m--> 106\u001b[0;31m       pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/smart_cond.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpred_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpred_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     return control_flow_util.smart_cond(\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreplace_training_and_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         lambda: replace_training_and_call(False))\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/utils.py\u001b[0m in \u001b[0;36mreplace_training_and_call\u001b[0;34m(training)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreplace_training_and_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m       \u001b[0mset_training_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_arg_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     return control_flow_util.smart_cond(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/save_impl.py\u001b[0m in \u001b[0;36mcall_and_return_conditional_losses\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    632\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_return_conditional_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m     \u001b[0;34m\"\"\"Returns layer (call_output, conditional losses) tuple.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m     \u001b[0mcall_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mversion_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_v1_layer_or_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m       conditional_losses = layer.get_losses_for(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m    439\u001b[0m           \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrow_lengths\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrow_lengths\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m           \u001b[0mtime_major\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_major\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m           zero_output_for_mask=self.zero_output_for_mask)\n\u001b[0m\u001b[1;32m    442\u001b[0m       \u001b[0;31m# This is a dummy tensor for testing purpose.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m       \u001b[0mruntime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_runtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_RUNTIME_UNKNOWN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36mrnn\u001b[0;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask)\u001b[0m\n\u001b[1;32m   4744\u001b[0m           \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4745\u001b[0m           \u001b[0mloop_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_ta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4746\u001b[0;31m           **while_loop_kwargs)\n\u001b[0m\u001b[1;32m   4747\u001b[0m       \u001b[0mnew_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2753\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2754\u001b[0m         \u001b[0mreturn_same_structure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_same_structure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2755\u001b[0;31m         back_prop=back_prop)\n\u001b[0m\u001b[1;32m   2756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2757\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"while\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, maximum_iterations, name, return_same_structure, back_prop)\u001b[0m\n\u001b[1;32m    218\u001b[0m             body_name, collections=ops.get_default_graph()._collections),  # pylint: disable=protected-access\n\u001b[1;32m    219\u001b[0m         \u001b[0madd_control_dependencies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_control_dependencies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         acd_record_initial_resource_uses=stateful_parallelism)\n\u001b[0m\u001b[1;32m    221\u001b[0m     \u001b[0;31m# Add external captures of body to the list of loop vars.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;31m# Note that external tensors will be treated as loop invariants, i.e.,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36mwrapped_body\u001b[0;34m(loop_counter, maximum_iterations_arg, *args)\u001b[0m\n\u001b[1;32m    195\u001b[0m       \u001b[0;31m# `orig_loop_vars` and `args`, converts flows in `args` to TensorArrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m       \u001b[0;31m# and packs it into the structure of `orig_loop_vars`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_pack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_loop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_nested_or_composite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(time, output_ta_t, *states)\u001b[0m\n\u001b[1;32m   4728\u001b[0m         \u001b[0mcurrent_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4729\u001b[0m         output, new_states = step_function(current_input,\n\u001b[0;32m-> 4730\u001b[0;31m                                            tuple(states) + tuple(constants))\n\u001b[0m\u001b[1;32m   4731\u001b[0m         \u001b[0mflat_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4732\u001b[0m         \u001b[0mflat_new_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(cell_inputs, cell_states)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m       last_output, outputs, states = backend.rnn(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1095\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1096\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_call_info_injected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, states, training)\u001b[0m\n\u001b[1;32m   1884\u001b[0m       \u001b[0mx_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m       \u001b[0mx_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1886\u001b[0;31m       \u001b[0mx_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1888\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_SliceHelperVar\u001b[0;34m(var, slice_spec)\u001b[0m\n\u001b[1;32m   1304\u001b[0m   \"\"\"\n\u001b[1;32m   1305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_slice_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m   1036\u001b[0m       skip_on_eager=False) as name:\n\u001b[1;32m   1037\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m       packed_begin, packed_end, packed_strides = (stack(begin), stack(end),\n\u001b[0m\u001b[1;32m   1039\u001b[0m                                                   stack(strides))\n\u001b[1;32m   1040\u001b[0m       if (packed_begin.dtype == dtypes.int64 or\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1422\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1423\u001b[0m       \u001b[0;31m# If the input is a constant list, it can be converted to a constant op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1424\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1425\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1426\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Input list contains non-constant tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    341\u001b[0m                                          as_ref=False):\n\u001b[1;32m    342\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    266\u001b[0m   \"\"\"\n\u001b[1;32m    267\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 268\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    288\u001b[0m   \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtensor_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdtype_value\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m   const_tensor = g._create_op_internal(  # pylint: disable=protected-access\n\u001b[0;32m--> 290\u001b[0;31m       \"Const\", [], [dtype_value.type], attrs=attrs, name=name).outputs[0]\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mop_callbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_invoke_op_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    693\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    694\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3782\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3783\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3784\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3785\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3786\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2170\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2171\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0;32m-> 2172\u001b[0;31m                                 control_input_ops, op_def)\n\u001b[0m\u001b[1;32m   2173\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0merror_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_traceback_filtering_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNameError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36mis_traceback_filtering_enabled\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m     was called).\n\u001b[1;32m     46\u001b[0m   \"\"\"\n\u001b[0;32m---> 47\u001b[0;31m   \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ENABLE_TRACEBACK_FILTERING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'value'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["i have a feeling the final model is going to overfit onto the dataset, might be best to stop at the 10th epoch"],"metadata":{"id":"5k5gXIEUSZ8R"}},{"cell_type":"code","source":[""],"metadata":{"id":"eMWdKRAEO5vY"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Text Generation 3rd Attempt.ipynb","provenance":[],"mount_file_id":"1mWNZkI4Vstz1JogsTVGbWa8f4KG3WqGT","authorship_tag":"ABX9TyPqkC74pnpcX094ePu1v9IA"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}