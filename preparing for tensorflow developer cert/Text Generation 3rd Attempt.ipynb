{"cells":[{"cell_type":"markdown","metadata":{"id":"z68tEydbgOja"},"source":["# **Third Attempt at generating text using RNN**\n","\n","So far i've tried to generate shakespeare like text using Tensorflow. ith my first few attempts i went of the Udacity course and tried to train my own model to perfom text generation. I didn't get very far as the models i tried to train were far to complex and i saw very little results. Following the guide on tensorflow, the trained model was far simplier and was successfully trained.\n","\n","I thought i'd give it another go at training my own text generation model/Something a bit intresting...\n","\n","Text Generation Model trained on [Anime Quotes](https://www.kaggle.com/datasets/tarundalal/anime-quotes)\n","\n","\n","P.s\n","I'm most likely going to steal some stuff from both the Udacity and Tensorflow guide"]},{"cell_type":"markdown","metadata":{"id":"WdSvTrv9oo-3"},"source":["# **Import Dependencies**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3116,"status":"ok","timestamp":1661590339870,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"},"user_tz":-60},"id":"GVYvO1grgFsK","outputId":"caad403a-90c9-4dc1-b2a3-02392f447051"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.8.2\n"]}],"source":["import tensorflow as tf\n","import numpy as np\n","import urllib.request\n","import csv\n","\n","print(tf.__version__)\n"]},{"cell_type":"markdown","metadata":{"id":"0momWAi_pjQj"},"source":["# **Download the dataset**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WpDxBph2pBb4"},"outputs":[],"source":["# i downloaded the dataset from this link\n","url = \"https://www.kaggle.com/datasets/tarundalal/anime-quotes/download?datasetVersionNumber=1\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33,"status":"ok","timestamp":1661590356284,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"},"user_tz":-60},"id":"MVth_xV8ye0U","outputId":"682c5ba8-f8f4-4d1d-e44a-516f1777441e"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}],"source":["!pwd"]},{"cell_type":"markdown","metadata":{"id":"so1lJZj6zneg"},"source":["Extracted the csv file and loaded it into the contents folder"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":428,"status":"ok","timestamp":1661590360608,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"},"user_tz":-60},"id":"7zlvR_RTztBa","outputId":"3866578f-0319-4263-c1cb-b717bca79457"},"outputs":[{"output_type":"stream","name":"stdout","text":["['Quote', 'People’s lives don’t end when they die, it ends when they lose faith.', 'If you don’t take risks, you can’t create a future!', 'If you don’t like your destiny, don’t accept it.', 'When you give up, that’s when the game ends.', 'All we can do is live until the day we die. Control what we can…and fly free.', 'Forgetting is like a wound. The wound may heal, but it has already left a scar.', 'It’s just pathetic to give up on something before you even give it a shot.”', 'If you don’t share someone’s pain, you can never understand them.', 'Whatever you lose, you’ll find it again. But what you throw away you’ll never get back.']\n"]}],"source":["# read the csvfile\n","anime_quotes = []\n","\n","# the csv file contains Quote, character, Anime. For this task we are only\n","# interested in the quote so we would only get the first column from each row.\n","with open('AnimeQuotes.csv') as csv_file:\n","  csv_reader = csv.reader(csv_file, delimiter=',')\n","  for row in csv_reader:\n","    anime_quotes.append(row[0])\n","\n","print(anime_quotes[:10])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":555,"status":"ok","timestamp":1661590365088,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"},"user_tz":-60},"id":"yo3DdZdf0zqK","outputId":"cb7e60f3-bf47-471c-d042-664f81e56a28"},"outputs":[{"output_type":"stream","name":"stdout","text":["['People’s lives don’t end when they die, it ends when they lose faith.', 'If you don’t take risks, you can’t create a future!', 'If you don’t like your destiny, don’t accept it.', 'When you give up, that’s when the game ends.', 'All we can do is live until the day we die. Control what we can…and fly free.', 'Forgetting is like a wound. The wound may heal, but it has already left a scar.', 'It’s just pathetic to give up on something before you even give it a shot.”', 'If you don’t share someone’s pain, you can never understand them.', 'Whatever you lose, you’ll find it again. But what you throw away you’ll never get back.', 'We don’t have to know what tomorrow holds! That’s why we can live for everything we’re worth today!”']\n","121\n"]}],"source":["# remove the header\n","anime_quotes = anime_quotes[1:]\n","\n","print(anime_quotes[:10])\n","print(len(anime_quotes))\n"]},{"cell_type":"markdown","metadata":{"id":"sKSlbYTX1C1B"},"source":["# **Prepare the text**\n","\n","The main task is here is to be able to generate anime quotes from our own seed text. Towards this we need, a set of feature and labels to train the model on.\n","\n","<br>\n","\n","**Set features and labels**   \n","The feature and labels need to reflect the task, so the feature should be a set of initial text and the label should be the next set of text.\n","\n","From what i've seen there are 2 ways we can approach this, we can create a model which Predicts the next char or predicts the next word. I'll try out the different methods to prepare the text\n","- Predicting next char \n","- Predicting the next probable word\n","\n","\n","In this collab i'll generate a model to predict the next probable char.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":943,"status":"ok","timestamp":1661590388981,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"},"user_tz":-60},"id":"gfuzrYg50_hP","outputId":"24f2c1fe-36b6-453a-8c10-9333b09766f8"},"outputs":[{"output_type":"stream","name":"stdout","text":["People’s lives don’t end when they die, it ends when they lose faith. If you don’t take risks, you can’t create a future! If you don’t like your destiny, don’t accept it. When you give up, that’s when the game ends. All we can do is live until the day we die. Control what we can…and fly free. Forgetting is like a wound. The wound may heal, but it has already left a scar. It’s just pathetic to give up on something before you even give it a shot.” If you don’t share someone’s pain, you can never understand them. Whatever you lose, you’ll find it again. But what you throw away you’ll never get back. We don’t have to know what tomorrow holds! That’s why we can live for everything we’re worth today!” Why should I apologize for being a monster? Has anyone ever apologized for turning me into one? People become stronger because they have memories they can’t forget. I’ll leave tomorrow’s problems to tomorrow’s me. If you wanna make people dream, you’ve gotta start by believing in that dream yourself! Being lonely is more painful then getting hurt. There’s no shame in falling down! True shame is to not stand up again! Simplicity is the easiest path to true beauty. If you can’t do something, then don’t. Focus on what you can. Giving up kills people. When people reject giving up… they finally win the right to transcend humanity. You can die anytime, but living takes true courage.” Every journey begins with a single step. We just have to have patience. It doesn’t do any good to pretend you can’t see what’s going on. Being weak is nothing to be ashamed of… Staying weak is !! To act is not necessarily compassion. True compassion sometimes comes from inaction. A dropout will beat a genius through hard work. Reject common sense to make the impossible possible. Whatever you lose, you’ll find it again. But what you throw away you’ll never get back. If you really want to be strong… Stop caring about what your surrounding thinks of you! Vision is not what your eyes see, but an image that your brain comprehends. Sometimes, people are just mean. Don’t fight mean with mean. Hold your head high. The ticket to the future is always open. Hard work is worthless for those that don’t believe in themselves. A place where someone still thinks about you is a place you can call home. Life comes at a cost. Wouldn’t it be arrogant to die before you’ve repaid that debt? You can die anytime, but living takes true courage. Every journey begins with a single step. We just have to have patience. If you just submit yourself to fate, then that’s the end of it.” It is at the moment of death that humanity has value. People, who can’t throw something important away, can never hope to change anything. Whatever you do, enjoy it to the fullest. That is the secret of life.” Power comes in response to a need, not a desire. You have to create that need. There are no regrets. If one can be proud of one’s life, one should not wish for another chance.” You can’t always hold on to the things that are important. By letting them go we gain something else.” If you don’t like your destiny, don’t accept it. Instead, have the courage to change it the way you want it to be. Don’t beg for things. Do it yourself, or else you won’t get anything. I refuse to let my fear control me anymore.” If you can’t find a reason to fight, then you shouldn’t be fighting.” You should never give up on life, no matter how you feel. No matter how badly you want to give up.” People who can’t throw something important away, can never hope to change anything. We can’t waste time worrying about the what if’s.” Fools who don’t respect the past are likely to repeat it. That’s why I can’t make a change. Everything I do is so… Half-assed.” Sometimes it’s necessary to do unnecessary things. An excellent leader must be passionate because it’s their duty to keep everyone moving forward. Protecting someone means giving them a place to belong. Giving them a place where they can be happy. Thinking you’re no-good and worthless is the worst thing you can do Sometimes I do feel like I’m a failure. Like there’s no hope for me. But even so, I’m not gonna give up. Ever!” If you can’t do something, then don’t. Focus on what you can do.” When you lose sight of your path, listen for the destination in your heart. The moment you think of giving up, think of the reason why you held on so long.” Don’t give up, there’s no shame in falling down! True shame is to not stand up again! No matter how hard or impossible it is, never lose sight of your goal.” Life is not a game of luck. If you wanna win, work hard. The world isn’t perfect. But it’s there for us, doing the best it can….that’s what makes it so damn beautiful. Fear is not evil. It tells you what your weakness is. And once you know your weakness, you can become stronger as well as kinder. To know sorrow is not terrifying. What is terrifying is to know you can’t go back to happiness you could have. Knowing you’re different is only the beginning. If you accept these differences you’ll be able to get past them and grow even closer. Don’t be so quick to throw away your life. No matter how disgraceful or embarrassing it may be, you need to keep struggling to find your way out until the very end. The world’s not perfect, but it’s there for us trying the best it can. That’s what makes it so damn beautiful. We are all like fireworks: we climb, we shine and always go our separate ways and become further apart. But even when that time comes, let’s not disappear like a firework and continue to shine.. forever. If nobody cares to accept you and wants you in this world, accept yourself and you will see that you don’t need them and their selfish ideas. When you hit the point of no return, that’s the moment it truly becomes a journey. If you can still turn back, it’s not really a journey. Those who stand at the top determine what’s wrong and what’s right! This very place is neutral ground! Justice will prevail, you say? But of course it will! Whoever wins this war becomes justice! A person grows up when he’s able to overcome hardships. Protection is important, but there are some things that a person must learn on his own. Who decides limits? And based on what? You said you worked hard? Well, maybe you need to work a little harder. Is that really the limit of your strength? Could you of tomorrow beat you today? Instead of giving in, move forward. Mistakes are not shackles that halt one from stepping forward. Rather, they are that which sustain and grow one’s heart. Fear is freedom! Subjugation is liberation! Contradiction is the truth! Those are the facts of this world! And you will all surrender to them, you pigs in human clothing! Hatred and Sorrow are power. They are yours to control. All you have to do is to turn them into strength and use that strength to move forward. It’s not always possible to do what we want to do, but it’s important to believe in something before you actually do it. Life and death are like light and shadow. They’re both always there. But people don’t like thinking about death, so subconsciously, they always look away from it. It’s more important to master the cards you’re holding than to complain about the ones your opponent was dealt.” I am the hope of the universe. I am the answer to all living things that cry out for peace. I am the protector of the innocent. I am the light in the darkness. I am the truth. Ally to good! Nightmare to you! If you’re gonna insist on gambling and then complain when you lose, you had better work on your game.” Moving on doesn’t mean you forget about things. It just means you have to accept what’s happened and continue living. If nobody cares to accept you and wants you in this world, accept yourself and you will see that you don’t need them and their selfish ideas. If you keep on hiding your true feelings, who is going to be happy? If you are sad, you should say it out loud! Religion, ideology, resources, land, spite, love or just because… No matter how pathetic the reason, it’s enough to start a war. War will never cease to exist… reasons can be thought up after the fact… Human nature pursues strife. Don’t be upset because of what you can’t do. Do what you do best, live as carefree and optimistically as you can, because some people aren’t able to do that. If you begin to regret, you’ll dull your future decisions and let others make your choices for you. All that’s left for you then is to die. Nobody can foretell the outcome. Each decision you make holds meaning only by affecting your next decision. Everything has a beginning and an end. Life is just a cycle of starts and stops. There are ends we don’t desire, but they’re inevitable, we have to face them. It’s what being human is all about. Anything can happen. No one ever thinks it will until it does. What will happen, happens. That’s how the world is. The most important thing is to not let the tragedy defeat you. To believe that you can get through it. You’ll only realize that you truly love someone if they already caused you enormous pain. Your enemies can never hurt you the way your loved ones can. It’s the people close to your heart that can give you the most piercing wound. Love is a double-edged sword, it can heal the wound faster or it can sink the blade even deeper. I want you to be happy. I want you to laugh a lot. I don’t know what exactly I’ll be able to do for you, but I’ll always be by your side. “A lesson without pain is meaningless. That’s because no one can gain without sacrificing something. But by enduring that pain and overcoming it, he shall obtain a powerful, unmatched heart.” You need to accept the fact that you’re not the best and have all the will to strive to be better than anyone you face. I too will obtain everything that I desire. Not because someone asked me to do it, but because I know in my heart that I have something worth fighting for. You can’t win a game by doing nothing. And if someone else wins it for you then you haven’t accomplished anything. Life is the same way. Do not think about other things, there is only one thing you can do. So master that one thing. Do not forget. What you must imagine is always that you, yourself, are the strongest. You do not need outside enemies. For you, the one you have to fight is none other than your own image. Life is like a tube of toothpaste. When you’ve used all the toothpaste down to the last squeeze, that’s when you’ve really lived. Live with all your might, and struggle as long as you have life.” Just like games, no matter how well you have things lined up in your life, there’s always something to keep you on your toes. Do exactly as you like. That is the true meaning of pleasure. Pleasure leads to joy and joy leads to happiness. It Doesn t Matter How Strong The Opposition Is It Doesn t Matter How Fearsome The World Is It Doesn t Matter How Cruel The World Is Fight If There Are Humans Who Can Bring About Change They re Those Who Are Capable Of Abandoning Everything People Who When Required To Surpass Even Monsters Are Capable Of Tossing Aside Their Very Humanity I Don t Like The Terms Good Person or Bad Person It Is Impossible To Be Entirely Good To Everyone To Some You Are A Good Person While To Others You Are A Bad Person As Long As We Continue To Fight We Are Not Defeated If You Win You Live If You Lose You Die If You Don t Fight You Can t Win You Understand Don t You One Day Or Another Everyone You Care About Eventually Dies It s Something We Simply Can t Accept It s A Realization That Could Drive You Insane You re Gonna Care What Other People Think And Be Someone You re Not Your Whole Life You re Fine As You Are So Talk In Your Own Words Everyone Had To Be Drunk On Somethin To Keep Pushing On Everyone Was A Slave To Somethin This World Is Cruel And It s Also Very Beautiful No One Knows What The Outcome Will Be So Choose Whatever You ll Regret The Least Do you need a reason to not want to lose Being the best decoy ever is as cool as being the ace You can fly even higher If they adjust to me I have to adjust in turn Whoever stops adjusting won t be able to continue forward The last ones standing are the victors Only the strongest If you want to be the last one standing become strong Life s a bore if you don t challenge yourself There are some flowers you only see when you take detours Being weak means that there is room to grow Today might be the chance to grasp the chance to let your talent bloom If you re gonna hit it hit it until it breaks\n","Unique_chars: {'p', 'r', 'u', 'm', ':', 'J', 'H', 'L', 'i', 'M', 'F', 'B', 'G', '’', 'A', 'f', 'c', 'g', 'I', 'v', 't', '.', 'T', '?', 'E', 'j', 'D', 'K', ' ', 'R', 'e', 'h', 's', 'o', 'Y', 'x', '…', 'C', 'a', 'w', 'y', 'W', 'l', 'q', 'V', 'U', 'b', '“', 'd', 'S', '!', '”', ',', 'O', 'k', 'P', 'N', '-', 'n', 'z', '\\xa0'}\n","Total number of charachthers in all_anime_quotes: 12501\n","Vocabulary size: 61\n"]}],"source":["# combine the contents of the list into a single string\n","all_anime_quotes = \" \".join(anime_quotes)\n","\n","\n","num_char = len(all_anime_quotes)\n","unique_chars = set(all_anime_quotes)\n","vocab_size = len(unique_chars)\n","\n","print(all_anime_quotes)\n","print(f\"Unique_chars: {unique_chars}\")\n","print(f\"Total number of charachthers in all_anime_quotes: {num_char}\")\n","print(f\"Vocabulary size: {vocab_size}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":336,"status":"ok","timestamp":1661590397726,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"},"user_tz":-60},"id":"Sqn17d-myaUP","outputId":"e1792bc8-f742-4d99-d01d-c4bb08e59bf2"},"outputs":[{"output_type":"stream","name":"stdout","text":["[' ', '!', ',', '-', '.', ':', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\xa0', '’', '“', '”', '…']\n"]}],"source":["print(sorted(unique_chars))\n"]},{"cell_type":"markdown","metadata":{"id":"jllGdi09yySc"},"source":["To recap the steps we are going to take for the text generation model.\n","\n","**Preparing the text**\n","- We are going to perform tokenization on each individual chars to convert them into tokens\n","- From the tokens we would then create sequences. We would create sequences of length 100 which would be our feature. Our label would be our sequence shifted one way to the right.\n","\n","**Model training**\n","- We would then train an RNN model on the features and labels.\n","\n","**Text generation**\n","- We would then generate a text from a seed word using the trained model"]},{"cell_type":"markdown","metadata":{"id":"RMgPRcuR0giW"},"source":["define a function to map the char into tokens."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1661590421528,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"},"user_tz":-60},"id":"xugQEAIMyk_R","outputId":"315a541e-fde5-495b-9f03-10c70c05be4b"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'p': 0, 'r': 1, 'u': 2, 'm': 3, ':': 4, 'J': 5, 'H': 6, 'L': 7, 'i': 8, 'M': 9, 'F': 10, 'B': 11, 'G': 12, '’': 13, 'A': 14, 'f': 15, 'c': 16, 'g': 17, 'I': 18, 'v': 19, 't': 20, '.': 21, 'T': 22, '?': 23, 'E': 24, 'j': 25, 'D': 26, 'K': 27, ' ': 28, 'R': 29, 'e': 30, 'h': 31, 's': 32, 'o': 33, 'Y': 34, 'x': 35, '…': 36, 'C': 37, 'a': 38, 'w': 39, 'y': 40, 'W': 41, 'l': 42, 'q': 43, 'V': 44, 'U': 45, 'b': 46, '“': 47, 'd': 48, 'S': 49, '!': 50, '”': 51, ',': 52, 'O': 53, 'k': 54, 'P': 55, 'N': 56, '-': 57, 'n': 58, 'z': 59, '\\xa0': 60}\n"]}],"source":["# define a dictionary to map the char into token\n","char_to_token = dict([(char, token) for token, char in enumerate(unique_chars)])\n","print(char_to_token)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1112,"status":"ok","timestamp":1661590431042,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"},"user_tz":-60},"id":"nz6bPXXj2EO7","outputId":"a44b3191-46ff-4574-cb03-04d85b9ba994"},"outputs":[{"output_type":"stream","name":"stdout","text":["{0: 'p', 1: 'r', 2: 'u', 3: 'm', 4: ':', 5: 'J', 6: 'H', 7: 'L', 8: 'i', 9: 'M', 10: 'F', 11: 'B', 12: 'G', 13: '’', 14: 'A', 15: 'f', 16: 'c', 17: 'g', 18: 'I', 19: 'v', 20: 't', 21: '.', 22: 'T', 23: '?', 24: 'E', 25: 'j', 26: 'D', 27: 'K', 28: ' ', 29: 'R', 30: 'e', 31: 'h', 32: 's', 33: 'o', 34: 'Y', 35: 'x', 36: '…', 37: 'C', 38: 'a', 39: 'w', 40: 'y', 41: 'W', 42: 'l', 43: 'q', 44: 'V', 45: 'U', 46: 'b', 47: '“', 48: 'd', 49: 'S', 50: '!', 51: '”', 52: ',', 53: 'O', 54: 'k', 55: 'P', 56: 'N', 57: '-', 58: 'n', 59: 'z', 60: '\\xa0'}\n"]}],"source":["# create a dictionary with inverted mapping\n","token_to_char = dict([(token, char) for char, token in char_to_token.items()])\n","print(token_to_char)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":954,"status":"ok","timestamp":1661590439751,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"},"user_tz":-60},"id":"qREa44q33EN1","outputId":"21810b82-a5c0-4407-f23e-6745593d2b9b"},"outputs":[{"output_type":"stream","name":"stdout","text":["A has token 14\n","14 represents A\n"]}],"source":["# Sanity check\n","print(f\"A has token {char_to_token['A']}\")\n","print(f\"{char_to_token['A']} represents {token_to_char[char_to_token['A']]}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1114,"status":"ok","timestamp":1661590447330,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"},"user_tz":-60},"id":"aWNWsFqL2vM8","outputId":"f3dda906-4670-4f6d-fb92-30cf02dac187"},"outputs":[{"output_type":"stream","name":"stdout","text":["[55, 30, 33, 0, 42, 30, 13, 32, 28, 42, 8, 19, 30, 32, 28, 48, 33, 58, 13, 20, 28, 30, 58, 48, 28, 39, 31, 30, 58, 28, 20, 31, 30, 40, 28, 48, 8, 30, 52, 28, 8, 20, 28, 30, 58, 48, 32, 28, 39, 31, 30, 58, 28, 20, 31, 30, 40, 28, 42, 33, 32, 30, 28, 15, 38, 8, 20, 31, 21, 28, 18, 15, 28, 40, 33, 2, 28, 48, 33, 58, 13, 20, 28, 20, 38, 54, 30, 28, 1, 8, 32, 54, 32, 52, 28, 40, 33, 2, 28, 16, 38, 58, 13, 20, 28, 16, 1, 30, 38, 20, 30, 28, 38, 28, 15, 2, 20, 2, 1, 30, 50, 28, 18, 15, 28, 40, 33, 2, 28, 48, 33, 58, 13, 20, 28, 42, 8, 54, 30, 28, 40, 33, 2, 1, 28, 48, 30, 32, 20, 8, 58, 40, 52, 28, 48, 33, 58, 13, 20, 28, 38, 16, 16, 30, 0, 20, 28, 8, 20, 21, 28, 41, 31, 30, 58, 28, 40, 33, 2, 28, 17, 8, 19, 30, 28, 2, 0, 52, 28, 20, 31, 38, 20, 13, 32, 28, 39, 31, 30, 58, 28, 20, 31, 30, 28, 17, 38, 3, 30, 28, 30, 58, 48, 32, 21, 28, 14, 42, 42, 28, 39, 30, 28, 16, 38, 58, 28, 48, 33, 28, 8, 32, 28, 42, 8, 19, 30, 28, 2, 58, 20, 8, 42, 28, 20, 31, 30, 28, 48, 38, 40, 28, 39, 30, 28, 48, 8, 30, 21, 28, 37, 33, 58, 20, 1, 33, 42, 28, 39, 31, 38, 20, 28, 39, 30, 28, 16, 38, 58, 36, 38, 58, 48, 28, 15, 42, 40, 28, 15, 1, 30, 30, 21, 28, 10, 33, 1, 17, 30, 20, 20, 8, 58, 17, 28, 8, 32, 28, 42, 8, 54, 30, 28, 38, 28, 39, 33, 2, 58, 48, 21, 28, 22, 31, 30, 28, 39, 33, 2, 58, 48, 28, 3, 38, 40, 28, 31, 30, 38, 42, 52, 28, 46, 2, 20, 28, 8, 20, 28, 31, 38, 32, 28, 38, 42, 1, 30, 38, 48, 40, 28, 42, 30, 15, 20, 28, 38, 28, 32, 16, 38, 1, 21, 28, 18, 20, 13, 32, 28, 25, 2, 32, 20, 28, 0, 38, 20, 31, 30, 20, 8, 16, 28, 20, 33, 28, 17, 8, 19, 30, 28, 2, 0, 28, 33, 58, 28, 32, 33, 3, 30, 20, 31, 8, 58, 17, 28, 46, 30, 15, 33, 1, 30, 28, 40, 33, 2, 28, 30, 19, 30, 58, 28, 17, 8, 19, 30, 28, 8, 20, 28, 38, 28, 32, 31, 33, 20, 21, 51, 28, 18, 15, 28, 40, 33, 2, 28, 48, 33, 58, 13, 20, 28, 32, 31, 38, 1, 30, 28, 32, 33, 3, 30, 33, 58, 30, 13, 32, 28, 0, 38, 8, 58, 52, 28, 40, 33, 2, 28, 16, 38, 58, 28, 58, 30, 19, 30, 1, 28, 2, 58, 48, 30, 1, 32, 20, 38, 58, 48, 28, 20, 31, 30, 3, 21, 28, 41, 31, 38, 20, 30, 19, 30, 1, 28, 40, 33, 2, 28, 42, 33, 32, 30, 52, 28, 40, 33, 2, 13, 42, 42, 28, 15, 8, 58, 48, 28, 8, 20, 28, 38, 17, 38, 8, 58, 21, 28, 11, 2, 20, 28, 39, 31, 38, 20, 28, 40, 33, 2, 28, 20, 31, 1, 33, 39, 28, 38, 39, 38, 40, 28, 40, 33, 2, 13, 42, 42, 28, 58, 30, 19, 30, 1, 28, 17, 30, 20, 28, 46, 38, 16, 54, 21, 28, 41, 30, 28, 48, 33, 58, 13, 20, 28, 31, 38, 19, 30, 28, 20, 33, 28, 54, 58, 33, 39, 28, 39, 31, 38, 20, 28, 20, 33, 3, 33, 1, 1, 33, 39, 28, 31, 33, 42, 48, 32, 50, 28, 22, 31, 38, 20, 13, 32, 28, 39, 31, 40, 28, 39, 30, 28, 16, 38, 58, 28, 42, 8, 19, 30, 28, 15, 33, 1, 28, 30, 19, 30, 1, 40, 20, 31, 8, 58, 17, 28, 39, 30, 13, 1, 30, 28, 39, 33, 1, 20, 31, 28, 20, 33, 48, 38, 40, 50, 51, 28, 41, 31, 40, 28, 32, 31, 33, 2, 42, 48, 28, 18, 28, 38, 0, 33, 42, 33, 17, 8, 59, 30, 28, 15, 33, 1, 28, 46, 30, 8, 58, 17, 28, 38, 28, 3, 33, 58, 32, 20, 30, 1, 23, 28, 6, 38, 32, 28, 38, 58, 40, 33, 58, 30, 28, 30, 19, 30, 1, 28, 38, 0, 33, 42, 33, 17, 8, 59, 30, 48, 28, 15, 33, 1, 28, 20, 2, 1, 58, 8, 58, 17, 28, 3, 30, 28, 8, 58, 20, 33, 28, 33, 58, 30, 23, 28, 55, 30, 33, 0, 42, 30, 28, 46, 30, 16, 33, 3, 30, 28, 32, 20, 1, 33, 58, 17, 30, 1, 28, 46, 30, 16, 38, 2, 32, 30, 28, 20, 31, 30, 40, 28, 31, 38, 19, 30, 28, 3, 30, 3, 33, 1, 8, 30, 32, 28, 20, 31, 30, 40, 28, 16, 38, 58, 13, 20, 28, 15, 33, 1, 17, 30, 20, 21, 28, 18, 13, 42, 42, 28, 42, 30, 38, 19, 30, 28, 20, 33, 3, 33, 1, 1, 33, 39, 13, 32, 28, 0, 1, 33, 46, 42, 30, 3, 32, 28, 20, 33, 28, 20, 33, 3, 33, 1, 1, 33, 39, 13, 32, 28, 3, 30, 21, 28, 18, 15, 28, 40, 33, 2, 28, 39, 38, 58, 58, 38, 28, 3, 38, 54, 30, 28, 0, 30, 33, 0, 42, 30, 28, 48, 1, 30, 38, 3, 52, 28, 40, 33, 2, 13, 19, 30, 28, 17, 33, 20, 20, 38, 28, 32, 20, 38, 1, 20, 28, 46, 40, 28, 46, 30, 42, 8, 30, 19, 8, 58, 17, 28, 8, 58, 28, 20, 31, 38, 20, 28, 48, 1, 30, 38, 3, 28, 40, 33, 2, 1, 32, 30, 42, 15, 50, 28, 11, 30, 8, 58, 17, 28, 42, 33, 58, 30, 42, 40, 28, 8, 32, 28, 3, 33, 1, 30, 28, 0, 38, 8, 58, 15, 2, 42, 28, 20, 31, 30, 58, 28, 17, 30, 20, 20, 8, 58, 17, 28, 31, 2, 1, 20, 21, 28, 22, 31, 30, 1, 30, 13, 32, 28, 58, 33, 28, 32, 31, 38, 3, 30, 28, 8, 58, 28, 15, 38, 42, 42, 8, 58, 17, 28, 48, 33, 39, 58, 50, 28, 22, 1, 2, 30, 28, 32, 31, 38, 3, 30, 28, 8, 32, 28, 20, 33, 28, 58, 33, 20, 28, 32, 20, 38, 58, 48, 28, 2, 0, 28, 38, 17, 38, 8, 58, 50, 28, 49, 8, 3, 0, 42, 8, 16, 8, 20, 40, 28, 8, 32, 28, 20, 31, 30, 28, 30, 38, 32, 8, 30, 32, 20, 28, 0, 38, 20, 31, 28, 20, 33, 28, 20, 1, 2, 30, 28, 46, 30, 38, 2, 20, 40, 21, 28, 18, 15, 28, 40, 33, 2, 28, 16, 38, 58, 13, 20, 28, 48, 33, 28, 32, 33, 3, 30, 20, 31, 8, 58, 17, 52, 28, 20, 31, 30, 58, 28, 48, 33, 58, 13, 20, 21, 28, 10, 33, 16, 2, 32, 28, 33, 58, 28, 39, 31, 38, 20, 28, 40, 33, 2, 28, 16, 38, 58, 21, 28, 12, 8, 19, 8, 58, 17, 28, 2, 0, 28, 54, 8, 42, 42, 32, 28, 0, 30, 33, 0, 42, 30, 21, 28, 41, 31, 30, 58, 28, 0, 30, 33, 0, 42, 30, 28, 1, 30, 25, 30, 16, 20, 28, 17, 8, 19, 8, 58, 17, 28, 2, 0, 36, 28, 20, 31, 30, 40, 28, 15, 8, 58, 38, 42, 42, 40, 28, 39, 8, 58, 28, 20, 31, 30, 28, 1, 8, 17, 31, 20, 28, 20, 33, 28, 20, 1, 38, 58, 32, 16, 30, 58, 48, 28, 31, 2, 3, 38, 58, 8, 20, 40, 21, 28, 34, 33, 2, 28, 16, 38, 58, 28, 48, 8, 30, 28, 38, 58, 40, 20, 8, 3, 30, 52, 28, 46, 2, 20, 28, 42, 8, 19, 8, 58, 17, 28, 20, 38, 54, 30, 32, 28, 20, 1, 2, 30, 28, 16, 33, 2, 1, 38, 17, 30, 21, 51, 28, 24, 19, 30, 1, 40, 28, 25, 33, 2, 1, 58, 30, 40, 28, 46, 30, 17, 8, 58, 32, 28, 39, 8, 20, 31, 28, 38, 28, 32, 8, 58, 17, 42, 30, 28, 32, 20, 30, 0, 21, 28, 41, 30, 28, 25, 2, 32, 20, 28, 31, 38, 19, 30, 28, 20, 33, 28, 31, 38, 19, 30, 28, 0, 38, 20, 8, 30, 58, 16, 30, 21, 28, 18, 20, 28, 48, 33, 30, 32, 58, 13, 20, 28, 48, 33, 28, 38, 58, 40, 28, 17, 33, 33, 48, 28, 20, 33, 28, 0, 1, 30, 20, 30, 58, 48, 28, 40, 33, 2, 28, 16, 38, 58, 13, 20, 28, 32, 30, 30, 28, 39, 31, 38, 20, 13, 32, 28, 17, 33, 8, 58, 17, 28, 33, 58, 21, 28, 11, 30, 8, 58, 17, 28, 39, 30, 38, 54, 28, 8, 32, 28, 58, 33, 20, 31, 8, 58, 17, 28, 20, 33, 28, 46, 30, 28, 38, 32, 31, 38, 3, 30, 48, 28, 33, 15, 36, 28, 49, 20, 38, 40, 8, 58, 17, 28, 39, 30, 38, 54, 28, 8, 32, 28, 50, 50, 28, 22, 33, 28, 38, 16, 20, 28, 8, 32, 28, 58, 33, 20, 28, 58, 30, 16, 30, 32, 32, 38, 1, 8, 42, 40, 28, 16, 33, 3, 0, 38, 32, 32, 8, 33, 58, 21, 28, 22, 1, 2, 30, 28, 16, 33, 3, 0, 38, 32, 32, 8, 33, 58, 28, 32, 33, 3, 30, 20, 8, 3, 30, 32, 28, 16, 33, 3, 30, 32, 28, 15, 1, 33, 3, 28, 8, 58, 38, 16, 20, 8, 33, 58, 21, 28, 14, 28, 48, 1, 33, 0, 33, 2, 20, 28, 39, 8, 42, 42, 28, 46, 30, 38, 20, 28, 38, 28, 17, 30, 58, 8, 2, 32, 28, 20, 31, 1, 33, 2, 17, 31, 28, 31, 38, 1, 48, 28, 39, 33, 1, 54, 21, 28, 29, 30, 25, 30, 16, 20, 28, 16, 33, 3, 3, 33, 58, 28, 32, 30, 58, 32, 30, 28, 20, 33, 28, 3, 38, 54, 30, 28, 20, 31, 30, 28, 8, 3, 0, 33, 32, 32, 8, 46, 42, 30, 28, 0, 33, 32, 32, 8, 46, 42, 30, 21, 28, 41, 31, 38, 20, 30, 19, 30, 1, 28, 40, 33, 2, 28, 42, 33, 32, 30, 52, 28, 40, 33, 2, 13, 42, 42, 28, 15, 8, 58, 48, 28, 8, 20, 28, 38, 17, 38, 8, 58, 21, 28, 11, 2, 20, 28, 39, 31, 38, 20, 28, 40, 33, 2, 28, 20, 31, 1, 33, 39, 28, 38, 39, 38, 40, 28, 40, 33, 2, 13, 42, 42, 28, 58, 30, 19, 30, 1, 28, 17, 30, 20, 28, 46, 38, 16, 54, 21, 28, 18, 15, 28, 40, 33, 2, 28, 1, 30, 38, 42, 42, 40, 28, 39, 38, 58, 20, 28, 20, 33, 28, 46, 30, 28, 32, 20, 1, 33, 58, 17, 36, 28, 49, 20, 33, 0, 28, 16, 38, 1, 8, 58, 17, 28, 38, 46, 33, 2, 20, 28, 39, 31, 38, 20, 28, 40, 33, 2, 1, 28, 32, 2, 1, 1, 33, 2, 58, 48, 8, 58, 17, 28, 20, 31, 8, 58, 54, 32, 28, 33, 15, 28, 40, 33, 2, 50, 28, 44, 8, 32, 8, 33, 58, 28, 8, 32, 28, 58, 33, 20, 28, 39, 31, 38, 20, 28, 40, 33, 2, 1, 28, 30, 40, 30, 32, 28, 32, 30, 30, 52, 28, 46, 2, 20, 28, 38, 58, 28, 8, 3, 38, 17, 30, 28, 20, 31, 38, 20, 28, 40, 33, 2, 1, 28, 46, 1, 38, 8, 58, 28, 16, 33, 3, 0, 1, 30, 31, 30, 58, 48, 32, 21, 28, 49, 33, 3, 30, 20, 8, 3, 30, 32, 52, 28, 0, 30, 33, 0, 42, 30, 28, 38, 1, 30, 28, 25, 2, 32, 20, 28, 3, 30, 38, 58, 21, 28, 26, 33, 58, 13, 20, 28, 15, 8, 17, 31, 20, 28, 3, 30, 38, 58, 28, 39, 8, 20, 31, 28, 3, 30, 38, 58, 21, 28, 6, 33, 42, 48, 28, 40, 33, 2, 1, 28, 31, 30, 38, 48, 28, 31, 8, 17, 31, 21, 28, 22, 31, 30, 28, 20, 8, 16, 54, 30, 20, 28, 20, 33, 28, 20, 31, 30, 28, 15, 2, 20, 2, 1, 30, 28, 8, 32, 28, 38, 42, 39, 38, 40, 32, 28, 33, 0, 30, 58, 21, 28, 6, 38, 1, 48, 28, 39, 33, 1, 54, 28, 8, 32, 28, 39, 33, 1, 20, 31, 42, 30, 32, 32, 28, 15, 33, 1, 28, 20, 31, 33, 32, 30, 28, 20, 31, 38, 20, 28, 48, 33, 58, 13, 20, 28, 46, 30, 42, 8, 30, 19, 30, 28, 8, 58, 28, 20, 31, 30, 3, 32, 30, 42, 19, 30, 32, 21, 28, 14, 28, 0, 42, 38, 16, 30, 28, 39, 31, 30, 1, 30, 28, 32, 33, 3, 30, 33, 58, 30, 28, 32, 20, 8, 42, 42, 28, 20, 31, 8, 58, 54, 32, 28, 38, 46, 33, 2, 20, 28, 40, 33, 2, 28, 8, 32, 28, 38, 28, 0, 42, 38, 16, 30, 28, 40, 33, 2, 28, 16, 38, 58, 28, 16, 38, 42, 42, 28, 31, 33, 3, 30, 21, 28, 7, 8, 15, 30, 28, 16, 33, 3, 30, 32, 28, 38, 20, 28, 38, 28, 16, 33, 32, 20, 21, 28, 41, 33, 2, 42, 48, 58, 13, 20, 28, 8, 20, 28, 46, 30, 28, 38, 1, 1, 33, 17, 38, 58, 20, 60, 20, 33, 28, 48, 8, 30, 28, 46, 30, 15, 33, 1, 30, 28, 40, 33, 2, 13, 19, 30, 28, 1, 30, 0, 38, 8, 48, 28, 20, 31, 38, 20, 28, 48, 30, 46, 20, 23, 28, 34, 33, 2, 28, 16, 38, 58, 28, 48, 8, 30, 28, 38, 58, 40, 20, 8, 3, 30, 52, 28, 46, 2, 20, 28, 42, 8, 19, 8, 58, 17, 28, 20, 38, 54, 30, 32, 28, 20, 1, 2, 30, 28, 16, 33, 2, 1, 38, 17, 30, 21, 28, 24, 19, 30, 1, 40, 28, 25, 33, 2, 1, 58, 30, 40, 28, 46, 30, 17, 8, 58, 32, 28, 39, 8, 20, 31, 28, 38, 28, 32, 8, 58, 17, 42, 30, 28, 32, 20, 30, 0, 21, 28, 41, 30, 28, 25, 2, 32, 20, 28, 31, 38, 19, 30, 28, 20, 33, 28, 31, 38, 19, 30, 28, 0, 38, 20, 8, 30, 58, 16, 30, 21, 28, 18, 15, 28, 40, 33, 2, 28, 25, 2, 32, 20, 28, 32, 2, 46, 3, 8, 20, 28, 40, 33, 2, 1, 32, 30, 42, 15, 28, 20, 33, 28, 15, 38, 20, 30, 52, 28, 20, 31, 30, 58, 28, 20, 31, 38, 20, 13, 32, 28, 20, 31, 30, 28, 30, 58, 48, 28, 33, 15, 28, 8, 20, 21, 51, 28, 18, 20, 28, 8, 32, 28, 38, 20, 28, 20, 31, 30, 28, 3, 33, 3, 30, 58, 20, 28, 33, 15, 28, 48, 30, 38, 20, 31, 28, 20, 31, 38, 20, 28, 31, 2, 3, 38, 58, 8, 20, 40, 28, 31, 38, 32, 28, 19, 38, 42, 2, 30, 21, 28, 55, 30, 33, 0, 42, 30, 52, 28, 39, 31, 33, 28, 16, 38, 58, 13, 20, 28, 20, 31, 1, 33, 39, 28, 32, 33, 3, 30, 20, 31, 8, 58, 17, 28, 8, 3, 0, 33, 1, 20, 38, 58, 20, 28, 38, 39, 38, 40, 52, 28, 16, 38, 58, 28, 58, 30, 19, 30, 1, 28, 31, 33, 0, 30, 28, 20, 33, 28, 16, 31, 38, 58, 17, 30, 28, 38, 58, 40, 20, 31, 8, 58, 17, 21, 28, 41, 31, 38, 20, 30, 19, 30, 1, 28, 40, 33, 2, 28, 48, 33, 52, 28, 30, 58, 25, 33, 40, 28, 8, 20, 28, 20, 33, 28, 20, 31, 30, 28, 15, 2, 42, 42, 30, 32, 20, 21, 28, 22, 31, 38, 20, 28, 8, 32, 28, 20, 31, 30, 28, 32, 30, 16, 1, 30, 20, 28, 33, 15, 28, 42, 8, 15, 30, 21, 51, 28, 55, 33, 39, 30, 1, 28, 16, 33, 3, 30, 32, 28, 8, 58, 28, 1, 30, 32, 0, 33, 58, 32, 30, 28, 20, 33, 28, 38, 28, 58, 30, 30, 48, 52, 28, 58, 33, 20, 28, 38, 28, 48, 30, 32, 8, 1, 30, 21, 28, 34, 33, 2, 28, 31, 38, 19, 30, 28, 20, 33, 28, 16, 1, 30, 38, 20, 30, 28, 20, 31, 38, 20, 28, 58, 30, 30, 48, 21, 28, 22, 31, 30, 1, 30, 28, 38, 1, 30, 28, 58, 33, 28, 1, 30, 17, 1, 30, 20, 32, 21, 28, 18, 15, 28, 33, 58, 30, 28, 16, 38, 58, 28, 46, 30, 28, 0, 1, 33, 2, 48, 28, 33, 15, 28, 33, 58, 30, 13, 32, 28, 42, 8, 15, 30, 52, 28, 33, 58, 30, 28, 32, 31, 33, 2, 42, 48, 28, 58, 33, 20, 28, 39, 8, 32, 31, 28, 15, 33, 1, 28, 38, 58, 33, 20, 31, 30, 1, 28, 16, 31, 38, 58, 16, 30, 21, 51, 28, 34, 33, 2, 28, 16, 38, 58, 13, 20, 28, 38, 42, 39, 38, 40, 32, 28, 31, 33, 42, 48, 28, 33, 58, 28, 20, 33, 28, 20, 31, 30, 28, 20, 31, 8, 58, 17, 32, 28, 20, 31, 38, 20, 28, 38, 1, 30, 28, 8, 3, 0, 33, 1, 20, 38, 58, 20, 21, 28, 11, 40, 28, 42, 30, 20, 20, 8, 58, 17, 28, 20, 31, 30, 3, 28, 17, 33, 28, 39, 30, 28, 17, 38, 8, 58, 28, 32, 33, 3, 30, 20, 31, 8, 58, 17, 28, 30, 42, 32, 30, 21, 51, 28, 18, 15, 28, 40, 33, 2, 28, 48, 33, 58, 13, 20, 28, 42, 8, 54, 30, 28, 40, 33, 2, 1, 28, 48, 30, 32, 20, 8, 58, 40, 52, 28, 48, 33, 58, 13, 20, 28, 38, 16, 16, 30, 0, 20, 28, 8, 20, 21, 28, 18, 58, 32, 20, 30, 38, 48, 52, 28, 31, 38, 19, 30, 28, 20, 31, 30, 28, 16, 33, 2, 1, 38, 17, 30, 28, 20, 33, 28, 16, 31, 38, 58, 17, 30, 28, 8, 20, 28, 20, 31, 30, 28, 39, 38, 40, 28, 40, 33, 2, 28, 39, 38, 58, 20, 28, 8, 20, 28, 20, 33, 28, 46, 30, 21, 28, 26, 33, 58, 13, 20, 28, 46, 30, 17, 60, 15, 33, 1, 60, 20, 31, 8, 58, 17, 32, 21, 28, 26, 33, 60, 8, 20, 28, 40, 33, 2, 1, 32, 30, 42, 15, 52, 28, 33, 1, 28, 30, 42, 32, 30, 28, 40, 33, 2, 28, 39, 33, 58, 13, 20, 60, 17, 30, 20, 28, 38, 58, 40, 20, 31, 8, 58, 17, 21, 28, 18, 28, 1, 30, 15, 2, 32, 30, 28, 20, 33, 28, 42, 30, 20, 28, 3, 40, 28, 15, 30, 38, 1, 28, 16, 33, 58, 20, 1, 33, 42, 28, 3, 30, 28, 38, 58, 40, 3, 33, 1, 30, 21, 51, 28, 18, 15, 28, 40, 33, 2, 28, 16, 38, 58, 13, 20, 28, 15, 8, 58, 48, 28, 38, 28, 1, 30, 38, 32, 33, 58, 28, 20, 33, 28, 15, 8, 17, 31, 20, 52, 28, 20, 31, 30, 58, 28, 40, 33, 2, 28, 32, 31, 33, 2, 42, 48, 58, 13, 20, 28, 46, 30, 28, 15, 8, 17, 31, 20, 8, 58, 17, 21, 51, 28, 34, 33, 2, 28, 32, 31, 33, 2, 42, 48, 28, 58, 30, 19, 30, 1, 28, 17, 8, 19, 30, 28, 2, 0, 28, 33, 58, 28, 42, 8, 15, 30, 52, 28, 58, 33, 28, 3, 38, 20, 20, 30, 1, 28, 31, 33, 39, 28, 40, 33, 2, 28, 15, 30, 30, 42, 21, 28, 56, 33, 28, 3, 38, 20, 20, 30, 1, 28, 31, 33, 39, 28, 46, 38, 48, 42, 40, 28, 40, 33, 2, 28, 39, 38, 58, 20, 28, 20, 33, 28, 17, 8, 19, 30, 28, 2, 0, 21, 51, 28, 55, 30, 33, 0, 42, 30, 28, 39, 31, 33, 28, 16, 38, 58, 13, 20, 28, 20, 31, 1, 33, 39, 28, 32, 33, 3, 30, 20, 31, 8, 58, 17, 28, 8, 3, 0, 33, 1, 20, 38, 58, 20, 28, 38, 39, 38, 40, 52, 28, 16, 38, 58, 28, 58, 30, 19, 30, 1, 28, 31, 33, 0, 30, 28, 20, 33, 28, 16, 31, 38, 58, 17, 30, 28, 38, 58, 40, 20, 31, 8, 58, 17, 21, 28, 41, 30, 28, 16, 38, 58, 13, 20, 28, 39, 38, 32, 20, 30, 28, 20, 8, 3, 30, 28, 39, 33, 1, 1, 40, 8, 58, 17, 28, 38, 46, 33, 2, 20, 28, 20, 31, 30, 28, 39, 31, 38, 20, 28, 8, 15, 13, 32, 21, 51, 28, 10, 33, 33, 42, 32, 28, 39, 31, 33, 28, 48, 33, 58, 13, 20, 28, 1, 30, 32, 0, 30, 16, 20, 28, 20, 31, 30, 28, 0, 38, 32, 20, 28, 38, 1, 30, 28, 42, 8, 54, 30, 42, 40, 28, 20, 33, 28, 1, 30, 0, 30, 38, 20, 28, 8, 20, 21, 28, 22, 31, 38, 20, 13, 32, 28, 39, 31, 40, 28, 18, 28, 16, 38, 58, 13, 20, 28, 3, 38, 54, 30, 28, 38, 28, 16, 31, 38, 58, 17, 30, 21, 28, 24, 19, 30, 1, 40, 20, 31, 8, 58, 17, 28, 18, 28, 48, 33, 28, 8, 32, 28, 32, 33, 36, 28, 6, 38, 42, 15, 57, 38, 32, 32, 30, 48, 21, 51, 28, 49, 33, 3, 30, 20, 8, 3, 30, 32, 28, 8, 20, 13, 32, 28, 58, 30, 16, 30, 32, 32, 38, 1, 40, 28, 20, 33, 28, 48, 33, 28, 2, 58, 58, 30, 16, 30, 32, 32, 38, 1, 40, 28, 20, 31, 8, 58, 17, 32, 21, 28, 14, 58, 28, 30, 35, 16, 30, 42, 42, 30, 58, 20, 28, 42, 30, 38, 48, 30, 1, 28, 3, 2, 32, 20, 28, 46, 30, 28, 0, 38, 32, 32, 8, 33, 58, 38, 20, 30, 28, 46, 30, 16, 38, 2, 32, 30, 28, 8, 20, 13, 32, 28, 20, 31, 30, 8, 1, 28, 48, 2, 20, 40, 28, 20, 33, 28, 54, 30, 30, 0, 28, 30, 19, 30, 1, 40, 33, 58, 30, 28, 3, 33, 19, 8, 58, 17, 28, 15, 33, 1, 39, 38, 1, 48, 21, 28, 55, 1, 33, 20, 30, 16, 20, 8, 58, 17, 28, 32, 33, 3, 30, 33, 58, 30, 28, 3, 30, 38, 58, 32, 28, 17, 8, 19, 8, 58, 17, 28, 20, 31, 30, 3, 28, 38, 28, 0, 42, 38, 16, 30, 28, 20, 33, 28, 46, 30, 42, 33, 58, 17, 21, 28, 12, 8, 19, 8, 58, 17, 28, 20, 31, 30, 3, 28, 38, 28, 0, 42, 38, 16, 30, 28, 39, 31, 30, 1, 30, 28, 20, 31, 30, 40, 28, 16, 38, 58, 28, 46, 30, 28, 31, 38, 0, 0, 40, 21, 28, 22, 31, 8, 58, 54, 8, 58, 17, 28, 40, 33, 2, 13, 1, 30, 28, 58, 33, 57, 17, 33, 33, 48, 28, 38, 58, 48, 28, 39, 33, 1, 20, 31, 42, 30, 32, 32, 28, 8, 32, 28, 20, 31, 30, 28, 39, 33, 1, 32, 20, 28, 20, 31, 8, 58, 17, 28, 40, 33, 2, 28, 16, 38, 58, 28, 48, 33, 28, 49, 33, 3, 30, 20, 8, 3, 30, 32, 28, 18, 28, 48, 33, 28, 15, 30, 30, 42, 28, 42, 8, 54, 30, 28, 18, 13, 3, 28, 38, 28, 15, 38, 8, 42, 2, 1, 30, 21, 28, 7, 8, 54, 30, 28, 20, 31, 30, 1, 30, 13, 32, 28, 58, 33, 28, 31, 33, 0, 30, 28, 15, 33, 1, 28, 3, 30, 21, 28, 11, 2, 20, 28, 30, 19, 30, 58, 28, 32, 33, 52, 28, 18, 13, 3, 28, 58, 33, 20, 28, 17, 33, 58, 58, 38, 28, 17, 8, 19, 30, 28, 2, 0, 21, 28, 24, 19, 30, 1, 50, 51, 28, 18, 15, 28, 40, 33, 2, 28, 16, 38, 58, 13, 20, 28, 48, 33, 28, 32, 33, 3, 30, 20, 31, 8, 58, 17, 52, 28, 20, 31, 30, 58, 28, 48, 33, 58, 13, 20, 21, 28, 10, 33, 16, 2, 32, 28, 33, 58, 28, 39, 31, 38, 20, 28, 40, 33, 2, 28, 16, 38, 58, 28, 48, 33, 21, 51, 28, 41, 31, 30, 58, 28, 40, 33, 2, 28, 42, 33, 32, 30, 28, 32, 8, 17, 31, 20, 28, 33, 15, 28, 40, 33, 2, 1, 28, 0, 38, 20, 31, 52, 28, 42, 8, 32, 20, 30, 58, 28, 15, 33, 1, 28, 20, 31, 30, 28, 48, 30, 32, 20, 8, 58, 38, 20, 8, 33, 58, 28, 8, 58, 28, 40, 33, 2, 1, 28, 31, 30, 38, 1, 20, 21, 28, 22, 31, 30, 28, 3, 33, 3, 30, 58, 20, 28, 40, 33, 2, 28, 20, 31, 8, 58, 54, 28, 33, 15, 28, 17, 8, 19, 8, 58, 17, 28, 2, 0, 52, 28, 20, 31, 8, 58, 54, 28, 33, 15, 28, 20, 31, 30, 28, 1, 30, 38, 32, 33, 58, 28, 39, 31, 40, 28, 40, 33, 2, 28, 31, 30, 42, 48, 28, 33, 58, 28, 32, 33, 28, 42, 33, 58, 17, 21, 51, 28, 26, 33, 58, 13, 20, 28, 17, 8, 19, 30, 28, 2, 0, 52, 28, 20, 31, 30, 1, 30, 13, 32, 28, 58, 33, 28, 32, 31, 38, 3, 30, 28, 8, 58, 28, 15, 38, 42, 42, 8, 58, 17, 28, 48, 33, 39, 58, 50, 28, 22, 1, 2, 30, 28, 32, 31, 38, 3, 30, 28, 8, 32, 28, 20, 33, 28, 58, 33, 20, 28, 32, 20, 38, 58, 48, 28, 2, 0, 28, 38, 17, 38, 8, 58, 50, 28, 56, 33, 28, 3, 38, 20, 20, 30, 1, 28, 31, 33, 39, 28, 31, 38, 1, 48, 28, 33, 1, 28, 8, 3, 0, 33, 32, 32, 8, 46, 42, 30, 28, 8, 20, 28, 8, 32, 52, 28, 58, 30, 19, 30, 1, 28, 42, 33, 32, 30, 28, 32, 8, 17, 31, 20, 28, 33, 15, 28, 40, 33, 2, 1, 28, 17, 33, 38, 42, 21, 51, 28, 7, 8, 15, 30, 28, 8, 32, 28, 58, 33, 20, 28, 38, 28, 17, 38, 3, 30, 28, 33, 15, 28, 42, 2, 16, 54, 21, 28, 18, 15, 28, 40, 33, 2, 28, 39, 38, 58, 58, 38, 28, 39, 8, 58, 52, 28, 39, 33, 1, 54, 28, 31, 38, 1, 48, 21, 28, 22, 31, 30, 28, 39, 33, 1, 42, 48, 28, 8, 32, 58, 13, 20, 28, 0, 30, 1, 15, 30, 16, 20, 21, 28, 11, 2, 20, 28, 8, 20, 13, 32, 28, 20, 31, 30, 1, 30, 28, 15, 33, 1, 28, 2, 32, 52, 28, 48, 33, 8, 58, 17, 28, 20, 31, 30, 28, 46, 30, 32, 20, 28, 8, 20, 28, 16, 38, 58, 36, 21, 20, 31, 38, 20, 13, 32, 28, 39, 31, 38, 20, 28, 3, 38, 54, 30, 32, 28, 8, 20, 28, 32, 33, 28, 48, 38, 3, 58, 28, 46, 30, 38, 2, 20, 8, 15, 2, 42, 21, 28, 10, 30, 38, 1, 28, 8, 32, 28, 58, 33, 20, 28, 30, 19, 8, 42, 21, 28, 18, 20, 28, 20, 30, 42, 42, 32, 28, 40, 33, 2, 28, 39, 31, 38, 20, 28, 40, 33, 2, 1, 28, 39, 30, 38, 54, 58, 30, 32, 32, 28, 8, 32, 21, 28, 14, 58, 48, 28, 33, 58, 16, 30, 28, 40, 33, 2, 28, 54, 58, 33, 39, 28, 40, 33, 2, 1, 28, 39, 30, 38, 54, 58, 30, 32, 32, 52, 28, 40, 33, 2, 28, 16, 38, 58, 28, 46, 30, 16, 33, 3, 30, 28, 32, 20, 1, 33, 58, 17, 30, 1, 28, 38, 32, 28, 39, 30, 42, 42, 28, 38, 32, 28, 54, 8, 58, 48, 30, 1, 21, 28, 22, 33, 28, 54, 58, 33, 39, 28, 32, 33, 1, 1, 33, 39, 28, 8, 32, 28, 58, 33, 20, 28, 20, 30, 1, 1, 8, 15, 40, 8, 58, 17, 21, 28, 41, 31, 38, 20, 28, 8, 32, 28, 20, 30, 1, 1, 8, 15, 40, 8, 58, 17, 28, 8, 32, 28, 20, 33, 28, 54, 58, 33, 39, 28, 40, 33, 2, 28, 16, 38, 58, 13, 20, 28, 17, 33, 28, 46, 38, 16, 54, 28, 20, 33, 28, 31, 38, 0, 0, 8, 58, 30, 32, 32, 28, 40, 33, 2, 28, 16, 33, 2, 42, 48, 28, 31, 38, 19, 30, 21, 28, 27, 58, 33, 39, 8, 58, 17, 28, 40, 33, 2, 13, 1, 30, 28, 48, 8, 15, 15, 30, 1, 30, 58, 20, 28, 8, 32, 28, 33, 58, 42, 40, 28, 20, 31, 30, 28, 46, 30, 17, 8, 58, 58, 8, 58, 17, 21, 28, 18, 15, 28, 40, 33, 2, 28, 38, 16, 16, 30, 0, 20, 28, 20, 31, 30, 32, 30, 28, 48, 8, 15, 15, 30, 1, 30, 58, 16, 30, 32, 28, 40, 33, 2, 13, 42, 42, 28, 46, 30, 28, 38, 46, 42, 30, 28, 20, 33, 28, 17, 30, 20, 28, 0, 38, 32, 20, 28, 20, 31, 30, 3, 28, 38, 58, 48, 28, 17, 1, 33, 39, 28, 30, 19, 30, 58, 28, 16, 42, 33, 32, 30, 1, 21, 28, 26, 33, 58, 13, 20, 28, 46, 30, 28, 32, 33, 28, 43, 2, 8, 16, 54, 28, 20, 33, 28, 20, 31, 1, 33, 39, 28, 38, 39, 38, 40, 28, 40, 33, 2, 1, 28, 42, 8, 15, 30, 21, 28, 56, 33, 28, 3, 38, 20, 20, 30, 1, 28, 31, 33, 39, 28, 48, 8, 32, 17, 1, 38, 16, 30, 15, 2, 42, 28, 33, 1, 28, 30, 3, 46, 38, 1, 1, 38, 32, 32, 8, 58, 17, 28, 8, 20, 28, 3, 38, 40, 28, 46, 30, 52, 28, 40, 33, 2, 28, 58, 30, 30, 48, 28, 20, 33, 28, 54, 30, 30, 0, 28, 32, 20, 1, 2, 17, 17, 42, 8, 58, 17, 28, 20, 33, 28, 15, 8, 58, 48, 28, 40, 33, 2, 1, 28, 39, 38, 40, 28, 33, 2, 20, 28, 2, 58, 20, 8, 42, 28, 20, 31, 30, 28, 19, 30, 1, 40, 28, 30, 58, 48, 21, 28, 22, 31, 30, 28, 39, 33, 1, 42, 48, 13, 32, 28, 58, 33, 20, 28, 0, 30, 1, 15, 30, 16, 20, 52, 28, 46, 2, 20, 28, 8, 20, 13, 32, 28, 20, 31, 30, 1, 30, 28, 15, 33, 1, 28, 2, 32, 28, 20, 1, 40, 8, 58, 17, 28, 20, 31, 30, 28, 46, 30, 32, 20, 28, 8, 20, 28, 16, 38, 58, 21, 28, 22, 31, 38, 20, 13, 32, 28, 39, 31, 38, 20, 28, 3, 38, 54, 30, 32, 28, 8, 20, 28, 32, 33, 28, 48, 38, 3, 58, 28, 46, 30, 38, 2, 20, 8, 15, 2, 42, 21, 28, 41, 30, 28, 38, 1, 30, 28, 38, 42, 42, 28, 42, 8, 54, 30, 28, 15, 8, 1, 30, 39, 33, 1, 54, 32, 4, 28, 39, 30, 28, 16, 42, 8, 3, 46, 52, 28, 39, 30, 28, 32, 31, 8, 58, 30, 28, 38, 58, 48, 28, 38, 42, 39, 38, 40, 32, 28, 17, 33, 28, 33, 2, 1, 28, 32, 30, 0, 38, 1, 38, 20, 30, 28, 39, 38, 40, 32, 28, 38, 58, 48, 28, 46, 30, 16, 33, 3, 30, 28, 15, 2, 1, 20, 31, 30, 1, 28, 38, 0, 38, 1, 20, 21, 28, 11, 2, 20, 28, 30, 19, 30, 58, 28, 39, 31, 30, 58, 28, 20, 31, 38, 20, 28, 20, 8, 3, 30, 28, 16, 33, 3, 30, 32, 52, 28, 42, 30, 20, 13, 32, 28, 58, 33, 20, 28, 48, 8, 32, 38, 0, 0, 30, 38, 1, 28, 42, 8, 54, 30, 28, 38, 28, 15, 8, 1, 30, 39, 33, 1, 54, 28, 38, 58, 48, 28, 16, 33, 58, 20, 8, 58, 2, 30, 28, 20, 33, 28, 32, 31, 8, 58, 30, 21, 21, 28, 15, 33, 1, 30, 19, 30, 1, 21, 28, 18, 15, 28, 58, 33, 46, 33, 48, 40, 28, 16, 38, 1, 30, 32, 28, 20, 33, 28, 38, 16, 16, 30, 0, 20, 28, 40, 33, 2, 28, 38, 58, 48, 28, 39, 38, 58, 20, 32, 28, 40, 33, 2, 28, 8, 58, 28, 20, 31, 8, 32, 28, 39, 33, 1, 42, 48, 52, 28, 38, 16, 16, 30, 0, 20, 28, 40, 33, 2, 1, 32, 30, 42, 15, 28, 38, 58, 48, 28, 40, 33, 2, 28, 39, 8, 42, 42, 28, 32, 30, 30, 28, 20, 31, 38, 20, 28, 40, 33, 2, 28, 48, 33, 58, 13, 20, 28, 58, 30, 30, 48, 28, 20, 31, 30, 3, 28, 38, 58, 48, 28, 20, 31, 30, 8, 1, 28, 32, 30, 42, 15, 8, 32, 31, 28, 8, 48, 30, 38, 32, 21, 28, 41, 31, 30, 58, 28, 40, 33, 2, 28, 31, 8, 20, 28, 20, 31, 30, 28, 0, 33, 8, 58, 20, 28, 33, 15, 28, 58, 33, 28, 1, 30, 20, 2, 1, 58, 52, 28, 20, 31, 38, 20, 13, 32, 28, 20, 31, 30, 28, 3, 33, 3, 30, 58, 20, 28, 8, 20, 28, 20, 1, 2, 42, 40, 28, 46, 30, 16, 33, 3, 30, 32, 28, 38, 28, 25, 33, 2, 1, 58, 30, 40, 21, 28, 18, 15, 28, 40, 33, 2, 28, 16, 38, 58, 28, 32, 20, 8, 42, 42, 28, 20, 2, 1, 58, 28, 46, 38, 16, 54, 52, 28, 8, 20, 13, 32, 28, 58, 33, 20, 28, 1, 30, 38, 42, 42, 40, 28, 38, 28, 25, 33, 2, 1, 58, 30, 40, 21, 28, 22, 31, 33, 32, 30, 28, 39, 31, 33, 28, 32, 20, 38, 58, 48, 28, 38, 20, 28, 20, 31, 30, 28, 20, 33, 0, 28, 48, 30, 20, 30, 1, 3, 8, 58, 30, 28, 39, 31, 38, 20, 13, 32, 28, 39, 1, 33, 58, 17, 28, 38, 58, 48, 28, 39, 31, 38, 20, 13, 32, 28, 1, 8, 17, 31, 20, 50, 28, 22, 31, 8, 32, 28, 19, 30, 1, 40, 28, 0, 42, 38, 16, 30, 28, 8, 32, 28, 58, 30, 2, 20, 1, 38, 42, 28, 17, 1, 33, 2, 58, 48, 50, 28, 5, 2, 32, 20, 8, 16, 30, 28, 39, 8, 42, 42, 28, 0, 1, 30, 19, 38, 8, 42, 52, 28, 40, 33, 2, 28, 32, 38, 40, 23, 28, 11, 2, 20, 28, 33, 15, 28, 16, 33, 2, 1, 32, 30, 28, 8, 20, 28, 39, 8, 42, 42, 50, 28, 41, 31, 33, 30, 19, 30, 1, 28, 39, 8, 58, 32, 28, 20, 31, 8, 32, 28, 39, 38, 1, 28, 46, 30, 16, 33, 3, 30, 32, 28, 25, 2, 32, 20, 8, 16, 30, 50, 28, 14, 28, 0, 30, 1, 32, 33, 58, 28, 17, 1, 33, 39, 32, 28, 2, 0, 28, 39, 31, 30, 58, 28, 31, 30, 13, 32, 28, 38, 46, 42, 30, 28, 20, 33, 28, 33, 19, 30, 1, 16, 33, 3, 30, 28, 31, 38, 1, 48, 32, 31, 8, 0, 32, 21, 28, 55, 1, 33, 20, 30, 16, 20, 8, 33, 58, 28, 8, 32, 28, 8, 3, 0, 33, 1, 20, 38, 58, 20, 52, 28, 46, 2, 20, 28, 20, 31, 30, 1, 30, 28, 38, 1, 30, 28, 32, 33, 3, 30, 28, 20, 31, 8, 58, 17, 32, 28, 20, 31, 38, 20, 28, 38, 28, 0, 30, 1, 32, 33, 58, 28, 3, 2, 32, 20, 28, 42, 30, 38, 1, 58, 28, 33, 58, 28, 31, 8, 32, 28, 33, 39, 58, 21, 28, 41, 31, 33, 28, 48, 30, 16, 8, 48, 30, 32, 28, 42, 8, 3, 8, 20, 32, 23, 28, 14, 58, 48, 28, 46, 38, 32, 30, 48, 28, 33, 58, 28, 39, 31, 38, 20, 23, 28, 34, 33, 2, 28, 32, 38, 8, 48, 28, 40, 33, 2, 28, 39, 33, 1, 54, 30, 48, 28, 31, 38, 1, 48, 23, 28, 41, 30, 42, 42, 52, 28, 3, 38, 40, 46, 30, 28, 40, 33, 2, 28, 58, 30, 30, 48, 28, 20, 33, 28, 39, 33, 1, 54, 28, 38, 28, 42, 8, 20, 20, 42, 30, 28, 31, 38, 1, 48, 30, 1, 21, 28, 18, 32, 28, 20, 31, 38, 20, 28, 1, 30, 38, 42, 42, 40, 28, 20, 31, 30, 28, 42, 8, 3, 8, 20, 28, 33, 15, 28, 40, 33, 2, 1, 28, 32, 20, 1, 30, 58, 17, 20, 31, 23, 28, 37, 33, 2, 42, 48, 28, 40, 33, 2, 28, 33, 15, 28, 20, 33, 3, 33, 1, 1, 33, 39, 28, 46, 30, 38, 20, 28, 40, 33, 2, 28, 20, 33, 48, 38, 40, 23, 28, 18, 58, 32, 20, 30, 38, 48, 28, 33, 15, 28, 17, 8, 19, 8, 58, 17, 28, 8, 58, 52, 28, 3, 33, 19, 30, 28, 15, 33, 1, 39, 38, 1, 48, 21, 28, 9, 8, 32, 20, 38, 54, 30, 32, 28, 38, 1, 30, 28, 58, 33, 20, 28, 32, 31, 38, 16, 54, 42, 30, 32, 28, 20, 31, 38, 20, 28, 31, 38, 42, 20, 28, 33, 58, 30, 28, 15, 1, 33, 3, 28, 32, 20, 30, 0, 0, 8, 58, 17, 28, 15, 33, 1, 39, 38, 1, 48, 21, 28, 29, 38, 20, 31, 30, 1, 52, 28, 20, 31, 30, 40, 28, 38, 1, 30, 28, 20, 31, 38, 20, 28, 39, 31, 8, 16, 31, 28, 32, 2, 32, 20, 38, 8, 58, 28, 38, 58, 48, 28, 17, 1, 33, 39, 28, 33, 58, 30, 13, 32, 28, 31, 30, 38, 1, 20, 21, 28, 10, 30, 38, 1, 28, 8, 32, 28, 15, 1, 30, 30, 48, 33, 3, 50, 28, 49, 2, 46, 25, 2, 17, 38, 20, 8, 33, 58, 28, 8, 32, 28, 42, 8, 46, 30, 1, 38, 20, 8, 33, 58, 50, 28, 37, 33, 58, 20, 1, 38, 48, 8, 16, 20, 8, 33, 58, 28, 8, 32, 28, 20, 31, 30, 28, 20, 1, 2, 20, 31, 50, 28, 22, 31, 33, 32, 30, 28, 38, 1, 30, 28, 20, 31, 30, 28, 15, 38, 16, 20, 32, 28, 33, 15, 28, 20, 31, 8, 32, 28, 39, 33, 1, 42, 48, 50, 28, 14, 58, 48, 28, 40, 33, 2, 28, 39, 8, 42, 42, 28, 38, 42, 42, 28, 32, 2, 1, 1, 30, 58, 48, 30, 1, 28, 20, 33, 28, 20, 31, 30, 3, 52, 28, 40, 33, 2, 28, 0, 8, 17, 32, 28, 8, 58, 28, 31, 2, 3, 38, 58, 28, 16, 42, 33, 20, 31, 8, 58, 17, 50, 28, 6, 38, 20, 1, 30, 48, 28, 38, 58, 48, 28, 49, 33, 1, 1, 33, 39, 28, 38, 1, 30, 28, 0, 33, 39, 30, 1, 21, 28, 22, 31, 30, 40, 28, 38, 1, 30, 28, 40, 33, 2, 1, 32, 28, 20, 33, 28, 16, 33, 58, 20, 1, 33, 42, 21, 28, 14, 42, 42, 28, 40, 33, 2, 28, 31, 38, 19, 30, 28, 20, 33, 28, 48, 33, 28, 8, 32, 28, 20, 33, 28, 20, 2, 1, 58, 28, 20, 31, 30, 3, 28, 8, 58, 20, 33, 28, 32, 20, 1, 30, 58, 17, 20, 31, 28, 38, 58, 48, 28, 2, 32, 30, 28, 20, 31, 38, 20, 28, 32, 20, 1, 30, 58, 17, 20, 31, 28, 20, 33, 28, 3, 33, 19, 30, 28, 15, 33, 1, 39, 38, 1, 48, 21, 28, 18, 20, 13, 32, 28, 58, 33, 20, 28, 38, 42, 39, 38, 40, 32, 28, 0, 33, 32, 32, 8, 46, 42, 30, 28, 20, 33, 28, 48, 33, 28, 39, 31, 38, 20, 28, 39, 30, 28, 39, 38, 58, 20, 28, 20, 33, 28, 48, 33, 52, 28, 46, 2, 20, 28, 8, 20, 13, 32, 28, 8, 3, 0, 33, 1, 20, 38, 58, 20, 28, 20, 33, 28, 46, 30, 42, 8, 30, 19, 30, 28, 8, 58, 28, 32, 33, 3, 30, 20, 31, 8, 58, 17, 28, 46, 30, 15, 33, 1, 30, 28, 40, 33, 2, 28, 38, 16, 20, 2, 38, 42, 42, 40, 28, 48, 33, 28, 8, 20, 21, 28, 7, 8, 15, 30, 28, 38, 58, 48, 28, 48, 30, 38, 20, 31, 28, 38, 1, 30, 28, 42, 8, 54, 30, 28, 42, 8, 17, 31, 20, 28, 38, 58, 48, 28, 32, 31, 38, 48, 33, 39, 21, 28, 22, 31, 30, 40, 13, 1, 30, 28, 46, 33, 20, 31, 28, 38, 42, 39, 38, 40, 32, 28, 20, 31, 30, 1, 30, 21, 28, 11, 2, 20, 28, 0, 30, 33, 0, 42, 30, 28, 48, 33, 58, 13, 20, 28, 42, 8, 54, 30, 28, 20, 31, 8, 58, 54, 8, 58, 17, 28, 38, 46, 33, 2, 20, 28, 48, 30, 38, 20, 31, 52, 28, 32, 33, 28, 32, 2, 46, 16, 33, 58, 32, 16, 8, 33, 2, 32, 42, 40, 52, 28, 20, 31, 30, 40, 28, 38, 42, 39, 38, 40, 32, 28, 42, 33, 33, 54, 28, 38, 39, 38, 40, 28, 15, 1, 33, 3, 28, 8, 20, 21, 28, 18, 20, 13, 32, 28, 3, 33, 1, 30, 28, 8, 3, 0, 33, 1, 20, 38, 58, 20, 28, 20, 33, 28, 3, 38, 32, 20, 30, 1, 28, 20, 31, 30, 28, 16, 38, 1, 48, 32, 28, 40, 33, 2, 13, 1, 30, 28, 31, 33, 42, 48, 8, 58, 17, 28, 20, 31, 38, 58, 28, 20, 33, 28, 16, 33, 3, 0, 42, 38, 8, 58, 28, 38, 46, 33, 2, 20, 28, 20, 31, 30, 28, 33, 58, 30, 32, 28, 40, 33, 2, 1, 28, 33, 0, 0, 33, 58, 30, 58, 20, 28, 39, 38, 32, 28, 48, 30, 38, 42, 20, 21, 51, 28, 18, 28, 38, 3, 28, 20, 31, 30, 28, 31, 33, 0, 30, 28, 33, 15, 28, 20, 31, 30, 28, 2, 58, 8, 19, 30, 1, 32, 30, 21, 28, 18, 28, 38, 3, 28, 20, 31, 30, 28, 38, 58, 32, 39, 30, 1, 28, 20, 33, 28, 38, 42, 42, 28, 42, 8, 19, 8, 58, 17, 28, 20, 31, 8, 58, 17, 32, 28, 20, 31, 38, 20, 28, 16, 1, 40, 28, 33, 2, 20, 28, 15, 33, 1, 28, 0, 30, 38, 16, 30, 21, 28, 18, 28, 38, 3, 28, 20, 31, 30, 28, 0, 1, 33, 20, 30, 16, 20, 33, 1, 28, 33, 15, 28, 20, 31, 30, 28, 8, 58, 58, 33, 16, 30, 58, 20, 21, 28, 18, 28, 38, 3, 28, 20, 31, 30, 28, 42, 8, 17, 31, 20, 28, 8, 58, 28, 20, 31, 30, 28, 48, 38, 1, 54, 58, 30, 32, 32, 21, 28, 18, 28, 38, 3, 28, 20, 31, 30, 28, 20, 1, 2, 20, 31, 21, 28, 14, 42, 42, 40, 28, 20, 33, 28, 17, 33, 33, 48, 50, 28, 56, 8, 17, 31, 20, 3, 38, 1, 30, 28, 20, 33, 28, 40, 33, 2, 50, 28, 18, 15, 28, 40, 33, 2, 13, 1, 30, 28, 17, 33, 58, 58, 38, 28, 8, 58, 32, 8, 32, 20, 28, 33, 58, 28, 17, 38, 3, 46, 42, 8, 58, 17, 28, 38, 58, 48, 28, 20, 31, 30, 58, 28, 16, 33, 3, 0, 42, 38, 8, 58, 28, 39, 31, 30, 58, 28, 40, 33, 2, 28, 42, 33, 32, 30, 52, 28, 40, 33, 2, 28, 31, 38, 48, 28, 46, 30, 20, 20, 30, 1, 28, 39, 33, 1, 54, 28, 33, 58, 28, 40, 33, 2, 1, 28, 17, 38, 3, 30, 21, 51, 28, 9, 33, 19, 8, 58, 17, 28, 33, 58, 28, 48, 33, 30, 32, 58, 13, 20, 28, 3, 30, 38, 58, 28, 40, 33, 2, 28, 15, 33, 1, 17, 30, 20, 28, 38, 46, 33, 2, 20, 28, 20, 31, 8, 58, 17, 32, 21, 28, 18, 20, 28, 25, 2, 32, 20, 28, 3, 30, 38, 58, 32, 28, 40, 33, 2, 28, 31, 38, 19, 30, 28, 20, 33, 28, 38, 16, 16, 30, 0, 20, 28, 39, 31, 38, 20, 13, 32, 28, 31, 38, 0, 0, 30, 58, 30, 48, 28, 38, 58, 48, 28, 16, 33, 58, 20, 8, 58, 2, 30, 28, 42, 8, 19, 8, 58, 17, 21, 28, 18, 15, 28, 58, 33, 46, 33, 48, 40, 28, 16, 38, 1, 30, 32, 28, 20, 33, 28, 38, 16, 16, 30, 0, 20, 28, 40, 33, 2, 28, 38, 58, 48, 28, 39, 38, 58, 20, 32, 28, 40, 33, 2, 28, 8, 58, 28, 20, 31, 8, 32, 28, 39, 33, 1, 42, 48, 52, 28, 38, 16, 16, 30, 0, 20, 28, 40, 33, 2, 1, 32, 30, 42, 15, 28, 38, 58, 48, 28, 40, 33, 2, 28, 39, 8, 42, 42, 28, 32, 30, 30, 28, 20, 31, 38, 20, 28, 40, 33, 2, 28, 48, 33, 58, 13, 20, 28, 58, 30, 30, 48, 28, 20, 31, 30, 3, 28, 38, 58, 48, 28, 20, 31, 30, 8, 1, 28, 32, 30, 42, 15, 8, 32, 31, 28, 8, 48, 30, 38, 32, 21, 28, 18, 15, 28, 40, 33, 2, 28, 54, 30, 30, 0, 28, 33, 58, 28, 31, 8, 48, 8, 58, 17, 28, 40, 33, 2, 1, 28, 20, 1, 2, 30, 28, 15, 30, 30, 42, 8, 58, 17, 32, 52, 28, 39, 31, 33, 28, 8, 32, 28, 17, 33, 8, 58, 17, 28, 20, 33, 28, 46, 30, 28, 31, 38, 0, 0, 40, 23, 28, 18, 15, 28, 40, 33, 2, 28, 38, 1, 30, 28, 32, 38, 48, 52, 28, 40, 33, 2, 28, 32, 31, 33, 2, 42, 48, 28, 32, 38, 40, 28, 8, 20, 28, 33, 2, 20, 28, 42, 33, 2, 48, 50, 28, 29, 30, 42, 8, 17, 8, 33, 58, 52, 28, 8, 48, 30, 33, 42, 33, 17, 40, 52, 28, 1, 30, 32, 33, 2, 1, 16, 30, 32, 52, 28, 42, 38, 58, 48, 52, 28, 32, 0, 8, 20, 30, 52, 28, 42, 33, 19, 30, 28, 33, 1, 28, 25, 2, 32, 20, 28, 46, 30, 16, 38, 2, 32, 30, 36, 28, 56, 33, 28, 3, 38, 20, 20, 30, 1, 28, 31, 33, 39, 28, 0, 38, 20, 31, 30, 20, 8, 16, 28, 20, 31, 30, 28, 1, 30, 38, 32, 33, 58, 52, 28, 8, 20, 13, 32, 28, 30, 58, 33, 2, 17, 31, 28, 20, 33, 28, 32, 20, 38, 1, 20, 28, 38, 28, 39, 38, 1, 21, 28, 41, 38, 1, 28, 39, 8, 42, 42, 28, 58, 30, 19, 30, 1, 28, 16, 30, 38, 32, 30, 28, 20, 33, 28, 30, 35, 8, 32, 20, 36, 28, 1, 30, 38, 32, 33, 58, 32, 28, 16, 38, 58, 28, 46, 30, 28, 20, 31, 33, 2, 17, 31, 20, 28, 2, 0, 28, 38, 15, 20, 30, 1, 28, 20, 31, 30, 28, 15, 38, 16, 20, 36, 28, 6, 2, 3, 38, 58, 28, 58, 38, 20, 2, 1, 30, 28, 0, 2, 1, 32, 2, 30, 32, 28, 32, 20, 1, 8, 15, 30, 21, 28, 26, 33, 58, 13, 20, 28, 46, 30, 28, 2, 0, 32, 30, 20, 28, 46, 30, 16, 38, 2, 32, 30, 28, 33, 15, 28, 39, 31, 38, 20, 28, 40, 33, 2, 28, 16, 38, 58, 13, 20, 28, 48, 33, 21, 28, 26, 33, 28, 39, 31, 38, 20, 28, 40, 33, 2, 28, 48, 33, 28, 46, 30, 32, 20, 52, 28, 42, 8, 19, 30, 28, 38, 32, 28, 16, 38, 1, 30, 15, 1, 30, 30, 28, 38, 58, 48, 28, 33, 0, 20, 8, 3, 8, 32, 20, 8, 16, 38, 42, 42, 40, 28, 38, 32, 28, 40, 33, 2, 28, 16, 38, 58, 52, 28, 46, 30, 16, 38, 2, 32, 30, 28, 32, 33, 3, 30, 28, 0, 30, 33, 0, 42, 30, 28, 38, 1, 30, 58, 13, 20, 28, 38, 46, 42, 30, 28, 20, 33, 28, 48, 33, 28, 20, 31, 38, 20, 21, 28, 18, 15, 28, 40, 33, 2, 28, 46, 30, 17, 8, 58, 28, 20, 33, 28, 1, 30, 17, 1, 30, 20, 52, 28, 40, 33, 2, 13, 42, 42, 28, 48, 2, 42, 42, 28, 40, 33, 2, 1, 28, 15, 2, 20, 2, 1, 30, 28, 48, 30, 16, 8, 32, 8, 33, 58, 32, 28, 38, 58, 48, 28, 42, 30, 20, 28, 33, 20, 31, 30, 1, 32, 28, 3, 38, 54, 30, 28, 40, 33, 2, 1, 28, 16, 31, 33, 8, 16, 30, 32, 28, 15, 33, 1, 28, 40, 33, 2, 21, 28, 14, 42, 42, 28, 20, 31, 38, 20, 13, 32, 28, 42, 30, 15, 20, 28, 15, 33, 1, 28, 40, 33, 2, 28, 20, 31, 30, 58, 28, 8, 32, 28, 20, 33, 28, 48, 8, 30, 21, 28, 56, 33, 46, 33, 48, 40, 28, 16, 38, 58, 28, 15, 33, 1, 30, 20, 30, 42, 42, 28, 20, 31, 30, 28, 33, 2, 20, 16, 33, 3, 30, 21, 28, 24, 38, 16, 31, 28, 48, 30, 16, 8, 32, 8, 33, 58, 28, 40, 33, 2, 28, 3, 38, 54, 30, 28, 31, 33, 42, 48, 32, 28, 3, 30, 38, 58, 8, 58, 17, 28, 33, 58, 42, 40, 28, 46, 40, 28, 38, 15, 15, 30, 16, 20, 8, 58, 17, 28, 40, 33, 2, 1, 28, 58, 30, 35, 20, 28, 48, 30, 16, 8, 32, 8, 33, 58, 21, 28, 24, 19, 30, 1, 40, 20, 31, 8, 58, 17, 28, 31, 38, 32, 28, 38, 28, 46, 30, 17, 8, 58, 58, 8, 58, 17, 28, 38, 58, 48, 28, 38, 58, 28, 30, 58, 48, 21, 28, 7, 8, 15, 30, 28, 8, 32, 28, 25, 2, 32, 20, 28, 38, 28, 16, 40, 16, 42, 30, 28, 33, 15, 28, 32, 20, 38, 1, 20, 32, 28, 38, 58, 48, 28, 32, 20, 33, 0, 32, 21, 28, 22, 31, 30, 1, 30, 28, 38, 1, 30, 28, 30, 58, 48, 32, 28, 39, 30, 28, 48, 33, 58, 13, 20, 28, 48, 30, 32, 8, 1, 30, 52, 28, 46, 2, 20, 28, 20, 31, 30, 40, 13, 1, 30, 28, 8, 58, 30, 19, 8, 20, 38, 46, 42, 30, 52, 28, 39, 30, 28, 31, 38, 19, 30, 28, 20, 33, 28, 15, 38, 16, 30, 28, 20, 31, 30, 3, 21, 28, 18, 20, 13, 32, 28, 39, 31, 38, 20, 28, 46, 30, 8, 58, 17, 28, 31, 2, 3, 38, 58, 28, 8, 32, 28, 38, 42, 42, 28, 38, 46, 33, 2, 20, 21, 28, 14, 58, 40, 20, 31, 8, 58, 17, 28, 16, 38, 58, 28, 31, 38, 0, 0, 30, 58, 21, 28, 56, 33, 28, 33, 58, 30, 28, 30, 19, 30, 1, 28, 20, 31, 8, 58, 54, 32, 28, 8, 20, 28, 39, 8, 42, 42, 28, 2, 58, 20, 8, 42, 28, 8, 20, 28, 48, 33, 30, 32, 21, 28, 41, 31, 38, 20, 28, 39, 8, 42, 42, 28, 31, 38, 0, 0, 30, 58, 52, 28, 31, 38, 0, 0, 30, 58, 32, 21, 28, 22, 31, 38, 20, 13, 32, 28, 31, 33, 39, 28, 20, 31, 30, 28, 39, 33, 1, 42, 48, 28, 8, 32, 21, 28, 22, 31, 30, 28, 3, 33, 32, 20, 28, 8, 3, 0, 33, 1, 20, 38, 58, 20, 28, 20, 31, 8, 58, 17, 28, 8, 32, 28, 20, 33, 28, 58, 33, 20, 28, 42, 30, 20, 28, 20, 31, 30, 28, 20, 1, 38, 17, 30, 48, 40, 28, 48, 30, 15, 30, 38, 20, 28, 40, 33, 2, 21, 28, 22, 33, 28, 46, 30, 42, 8, 30, 19, 30, 28, 20, 31, 38, 20, 28, 40, 33, 2, 28, 16, 38, 58, 28, 17, 30, 20, 28, 20, 31, 1, 33, 2, 17, 31, 28, 8, 20, 21, 28, 34, 33, 2, 13, 42, 42, 28, 33, 58, 42, 40, 28, 1, 30, 38, 42, 8, 59, 30, 28, 20, 31, 38, 20, 28, 40, 33, 2, 28, 20, 1, 2, 42, 40, 28, 42, 33, 19, 30, 28, 32, 33, 3, 30, 33, 58, 30, 28, 8, 15, 28, 20, 31, 30, 40, 28, 38, 42, 1, 30, 38, 48, 40, 28, 16, 38, 2, 32, 30, 48, 28, 40, 33, 2, 28, 30, 58, 33, 1, 3, 33, 2, 32, 28, 0, 38, 8, 58, 21, 28, 34, 33, 2, 1, 28, 30, 58, 30, 3, 8, 30, 32, 28, 16, 38, 58, 28, 58, 30, 19, 30, 1, 28, 31, 2, 1, 20, 28, 40, 33, 2, 28, 20, 31, 30, 28, 39, 38, 40, 28, 40, 33, 2, 1, 28, 42, 33, 19, 30, 48, 28, 33, 58, 30, 32, 28, 16, 38, 58, 21, 28, 18, 20, 13, 32, 28, 20, 31, 30, 28, 0, 30, 33, 0, 42, 30, 28, 16, 42, 33, 32, 30, 28, 20, 33, 28, 40, 33, 2, 1, 28, 31, 30, 38, 1, 20, 28, 20, 31, 38, 20, 28, 16, 38, 58, 28, 17, 8, 19, 30, 28, 40, 33, 2, 28, 20, 31, 30, 28, 3, 33, 32, 20, 28, 0, 8, 30, 1, 16, 8, 58, 17, 28, 39, 33, 2, 58, 48, 21, 28, 7, 33, 19, 30, 28, 8, 32, 28, 38, 28, 48, 33, 2, 46, 42, 30, 57, 30, 48, 17, 30, 48, 28, 32, 39, 33, 1, 48, 52, 28, 8, 20, 28, 16, 38, 58, 28, 31, 30, 38, 42, 28, 20, 31, 30, 28, 39, 33, 2, 58, 48, 28, 15, 38, 32, 20, 30, 1, 28, 33, 1, 28, 8, 20, 28, 16, 38, 58, 28, 32, 8, 58, 54, 28, 20, 31, 30, 28, 46, 42, 38, 48, 30, 28, 30, 19, 30, 58, 28, 48, 30, 30, 0, 30, 1, 21, 28, 18, 28, 39, 38, 58, 20, 28, 40, 33, 2, 28, 20, 33, 28, 46, 30, 28, 31, 38, 0, 0, 40, 21, 28, 18, 28, 39, 38, 58, 20, 28, 40, 33, 2, 28, 20, 33, 28, 42, 38, 2, 17, 31, 28, 38, 28, 42, 33, 20, 21, 28, 18, 28, 48, 33, 58, 13, 20, 28, 54, 58, 33, 39, 28, 39, 31, 38, 20, 28, 30, 35, 38, 16, 20, 42, 40, 28, 18, 13, 42, 42, 28, 46, 30, 28, 38, 46, 42, 30, 28, 20, 33, 28, 48, 33, 28, 15, 33, 1, 28, 40, 33, 2, 52, 28, 46, 2, 20, 28, 18, 13, 42, 42, 28, 38, 42, 39, 38, 40, 32, 28, 46, 30, 28, 46, 40, 28, 40, 33, 2, 1, 28, 32, 8, 48, 30, 21, 28, 47, 14, 28, 42, 30, 32, 32, 33, 58, 28, 39, 8, 20, 31, 33, 2, 20, 28, 0, 38, 8, 58, 28, 8, 32, 28, 3, 30, 38, 58, 8, 58, 17, 42, 30, 32, 32, 21, 28, 22, 31, 38, 20, 13, 32, 28, 46, 30, 16, 38, 2, 32, 30, 28, 58, 33, 28, 33, 58, 30, 28, 16, 38, 58, 28, 17, 38, 8, 58, 28, 39, 8, 20, 31, 33, 2, 20, 28, 32, 38, 16, 1, 8, 15, 8, 16, 8, 58, 17, 28, 32, 33, 3, 30, 20, 31, 8, 58, 17, 21, 28, 11, 2, 20, 28, 46, 40, 28, 30, 58, 48, 2, 1, 8, 58, 17, 28, 20, 31, 38, 20, 28, 0, 38, 8, 58, 28, 38, 58, 48, 28, 33, 19, 30, 1, 16, 33, 3, 8, 58, 17, 28, 8, 20, 52, 28, 31, 30, 28, 32, 31, 38, 42, 42, 28, 33, 46, 20, 38, 8, 58, 28, 38, 28, 0, 33, 39, 30, 1, 15, 2, 42, 52, 28, 2, 58, 3, 38, 20, 16, 31, 30, 48, 28, 31, 30, 38, 1, 20, 21, 51, 28, 34, 33, 2, 28, 58, 30, 30, 48, 28, 20, 33, 28, 38, 16, 16, 30, 0, 20, 28, 20, 31, 30, 28, 15, 38, 16, 20, 28, 20, 31, 38, 20, 28, 40, 33, 2, 13, 1, 30, 28, 58, 33, 20, 28, 20, 31, 30, 28, 46, 30, 32, 20, 28, 38, 58, 48, 28, 31, 38, 19, 30, 28, 38, 42, 42, 28, 20, 31, 30, 28, 39, 8, 42, 42, 28, 20, 33, 28, 32, 20, 1, 8, 19, 30, 28, 20, 33, 28, 46, 30, 28, 46, 30, 20, 20, 30, 1, 28, 20, 31, 38, 58, 28, 38, 58, 40, 33, 58, 30, 28, 40, 33, 2, 28, 15, 38, 16, 30, 21, 28, 18, 28, 20, 33, 33, 28, 39, 8, 42, 42, 28, 33, 46, 20, 38, 8, 58, 28, 30, 19, 30, 1, 40, 20, 31, 8, 58, 17, 28, 20, 31, 38, 20, 28, 18, 28, 48, 30, 32, 8, 1, 30, 21, 28, 56, 33, 20, 28, 46, 30, 16, 38, 2, 32, 30, 28, 32, 33, 3, 30, 33, 58, 30, 28, 38, 32, 54, 30, 48, 28, 3, 30, 28, 20, 33, 28, 48, 33, 28, 8, 20, 52, 28, 46, 2, 20, 28, 46, 30, 16, 38, 2, 32, 30, 28, 18, 28, 54, 58, 33, 39, 28, 8, 58, 28, 3, 40, 28, 31, 30, 38, 1, 20, 28, 20, 31, 38, 20, 28, 18, 28, 31, 38, 19, 30, 28, 32, 33, 3, 30, 20, 31, 8, 58, 17, 28, 39, 33, 1, 20, 31, 28, 15, 8, 17, 31, 20, 8, 58, 17, 28, 15, 33, 1, 21, 28, 34, 33, 2, 28, 16, 38, 58, 13, 20, 28, 39, 8, 58, 28, 38, 28, 17, 38, 3, 30, 28, 46, 40, 28, 48, 33, 8, 58, 17, 28, 58, 33, 20, 31, 8, 58, 17, 21, 28, 14, 58, 48, 28, 8, 15, 28, 32, 33, 3, 30, 33, 58, 30, 28, 30, 42, 32, 30, 28, 39, 8, 58, 32, 28, 8, 20, 28, 15, 33, 1, 28, 40, 33, 2, 28, 20, 31, 30, 58, 28, 40, 33, 2, 28, 31, 38, 19, 30, 58, 13, 20, 28, 38, 16, 16, 33, 3, 0, 42, 8, 32, 31, 30, 48, 28, 38, 58, 40, 20, 31, 8, 58, 17, 21, 28, 7, 8, 15, 30, 28, 8, 32, 28, 20, 31, 30, 28, 32, 38, 3, 30, 28, 39, 38, 40, 21, 28, 26, 33, 28, 58, 33, 20, 28, 20, 31, 8, 58, 54, 28, 38, 46, 33, 2, 20, 28, 33, 20, 31, 30, 1, 28, 20, 31, 8, 58, 17, 32, 52, 28, 20, 31, 30, 1, 30, 28, 8, 32, 28, 33, 58, 42, 40, 28, 33, 58, 30, 28, 20, 31, 8, 58, 17, 28, 40, 33, 2, 28, 16, 38, 58, 28, 48, 33, 21, 28, 49, 33, 28, 3, 38, 32, 20, 30, 1, 28, 20, 31, 38, 20, 28, 33, 58, 30, 28, 20, 31, 8, 58, 17, 21, 28, 26, 33, 28, 58, 33, 20, 28, 15, 33, 1, 17, 30, 20, 21, 28, 41, 31, 38, 20, 28, 40, 33, 2, 28, 3, 2, 32, 20, 28, 8, 3, 38, 17, 8, 58, 30, 28, 8, 32, 28, 38, 42, 39, 38, 40, 32, 28, 20, 31, 38, 20, 28, 40, 33, 2, 52, 28, 40, 33, 2, 1, 32, 30, 42, 15, 52, 28, 38, 1, 30, 28, 20, 31, 30, 28, 32, 20, 1, 33, 58, 17, 30, 32, 20, 21, 28, 34, 33, 2, 28, 48, 33, 28, 58, 33, 20, 28, 58, 30, 30, 48, 28, 33, 2, 20, 32, 8, 48, 30, 28, 30, 58, 30, 3, 8, 30, 32, 21, 28, 10, 33, 1, 28, 40, 33, 2, 52, 28, 20, 31, 30, 28, 33, 58, 30, 28, 40, 33, 2, 28, 31, 38, 19, 30, 28, 20, 33, 28, 15, 8, 17, 31, 20, 28, 8, 32, 28, 58, 33, 58, 30, 28, 33, 20, 31, 30, 1, 28, 20, 31, 38, 58, 28, 40, 33, 2, 1, 28, 33, 39, 58, 28, 8, 3, 38, 17, 30, 21, 28, 7, 8, 15, 30, 28, 8, 32, 28, 42, 8, 54, 30, 28, 38, 28, 20, 2, 46, 30, 28, 33, 15, 28, 20, 33, 33, 20, 31, 0, 38, 32, 20, 30, 21, 28, 41, 31, 30, 58, 28, 40, 33, 2, 13, 19, 30, 28, 2, 32, 30, 48, 28, 38, 42, 42, 28, 20, 31, 30, 28, 20, 33, 33, 20, 31, 0, 38, 32, 20, 30, 28, 48, 33, 39, 58, 28, 20, 33, 28, 20, 31, 30, 28, 42, 38, 32, 20, 28, 32, 43, 2, 30, 30, 59, 30, 52, 28, 20, 31, 38, 20, 13, 32, 28, 39, 31, 30, 58, 28, 40, 33, 2, 13, 19, 30, 28, 1, 30, 38, 42, 42, 40, 28, 42, 8, 19, 30, 48, 21, 28, 7, 8, 19, 30, 28, 39, 8, 20, 31, 28, 38, 42, 42, 28, 40, 33, 2, 1, 28, 3, 8, 17, 31, 20, 52, 28, 38, 58, 48, 28, 32, 20, 1, 2, 17, 17, 42, 30, 28, 38, 32, 28, 42, 33, 58, 17, 28, 38, 32, 28, 40, 33, 2, 28, 31, 38, 19, 30, 28, 42, 8, 15, 30, 21, 51, 28, 5, 2, 32, 20, 28, 42, 8, 54, 30, 60, 17, 38, 3, 30, 32, 52, 28, 58, 33, 28, 3, 38, 20, 20, 30, 1, 28, 31, 33, 39, 28, 39, 30, 42, 42, 28, 40, 33, 2, 28, 31, 38, 19, 30, 28, 20, 31, 8, 58, 17, 32, 28, 42, 8, 58, 30, 48, 28, 2, 0, 28, 8, 58, 28, 40, 33, 2, 1, 28, 42, 8, 15, 30, 52, 28, 20, 31, 30, 1, 30, 13, 32, 28, 38, 42, 39, 38, 40, 32, 28, 32, 33, 3, 30, 20, 31, 8, 58, 17, 28, 20, 33, 28, 54, 30, 30, 0, 28, 40, 33, 2, 28, 33, 58, 28, 40, 33, 2, 1, 28, 20, 33, 30, 32, 21, 28, 26, 33, 28, 30, 35, 38, 16, 20, 42, 40, 28, 38, 32, 28, 40, 33, 2, 28, 42, 8, 54, 30, 21, 28, 22, 31, 38, 20, 28, 8, 32, 28, 20, 31, 30, 28, 20, 1, 2, 30, 28, 3, 30, 38, 58, 8, 58, 17, 28, 33, 15, 28, 0, 42, 30, 38, 32, 2, 1, 30, 21, 28, 55, 42, 30, 38, 32, 2, 1, 30, 28, 42, 30, 38, 48, 32, 28, 20, 33, 28, 25, 33, 40, 28, 38, 58, 48, 28, 25, 33, 40, 28, 42, 30, 38, 48, 32, 28, 20, 33, 28, 31, 38, 0, 0, 8, 58, 30, 32, 32, 21, 28, 18, 20, 28, 26, 33, 30, 32, 58, 28, 20, 28, 9, 38, 20, 20, 30, 1, 28, 6, 33, 39, 28, 49, 20, 1, 33, 58, 17, 28, 22, 31, 30, 28, 53, 0, 0, 33, 32, 8, 20, 8, 33, 58, 28, 18, 32, 28, 18, 20, 28, 26, 33, 30, 32, 58, 28, 20, 28, 9, 38, 20, 20, 30, 1, 28, 6, 33, 39, 28, 10, 30, 38, 1, 32, 33, 3, 30, 28, 22, 31, 30, 28, 41, 33, 1, 42, 48, 28, 18, 32, 28, 18, 20, 28, 26, 33, 30, 32, 58, 28, 20, 28, 9, 38, 20, 20, 30, 1, 28, 6, 33, 39, 28, 37, 1, 2, 30, 42, 28, 22, 31, 30, 28, 41, 33, 1, 42, 48, 28, 18, 32, 28, 10, 8, 17, 31, 20, 28, 18, 15, 28, 22, 31, 30, 1, 30, 28, 14, 1, 30, 28, 6, 2, 3, 38, 58, 32, 28, 41, 31, 33, 28, 37, 38, 58, 28, 11, 1, 8, 58, 17, 28, 14, 46, 33, 2, 20, 28, 37, 31, 38, 58, 17, 30, 28, 22, 31, 30, 40, 28, 1, 30, 28, 22, 31, 33, 32, 30, 28, 41, 31, 33, 28, 14, 1, 30, 28, 37, 38, 0, 38, 46, 42, 30, 28, 53, 15, 28, 14, 46, 38, 58, 48, 33, 58, 8, 58, 17, 28, 24, 19, 30, 1, 40, 20, 31, 8, 58, 17, 28, 55, 30, 33, 0, 42, 30, 28, 41, 31, 33, 28, 41, 31, 30, 58, 28, 29, 30, 43, 2, 8, 1, 30, 48, 28, 22, 33, 28, 49, 2, 1, 0, 38, 32, 32, 28, 24, 19, 30, 58, 28, 9, 33, 58, 32, 20, 30, 1, 32, 28, 14, 1, 30, 28, 37, 38, 0, 38, 46, 42, 30, 28, 53, 15, 28, 22, 33, 32, 32, 8, 58, 17, 28, 14, 32, 8, 48, 30, 28, 22, 31, 30, 8, 1, 28, 44, 30, 1, 40, 28, 6, 2, 3, 38, 58, 8, 20, 40, 28, 18, 28, 26, 33, 58, 28, 20, 28, 7, 8, 54, 30, 28, 22, 31, 30, 28, 22, 30, 1, 3, 32, 28, 12, 33, 33, 48, 28, 55, 30, 1, 32, 33, 58, 28, 33, 1, 28, 11, 38, 48, 28, 55, 30, 1, 32, 33, 58, 28, 18, 20, 28, 18, 32, 28, 18, 3, 0, 33, 32, 32, 8, 46, 42, 30, 28, 22, 33, 28, 11, 30, 28, 24, 58, 20, 8, 1, 30, 42, 40, 28, 12, 33, 33, 48, 28, 22, 33, 28, 24, 19, 30, 1, 40, 33, 58, 30, 28, 22, 33, 28, 49, 33, 3, 30, 28, 34, 33, 2, 28, 14, 1, 30, 28, 14, 28, 12, 33, 33, 48, 28, 55, 30, 1, 32, 33, 58, 28, 41, 31, 8, 42, 30, 28, 22, 33, 28, 53, 20, 31, 30, 1, 32, 28, 34, 33, 2, 28, 14, 1, 30, 28, 14, 28, 11, 38, 48, 28, 55, 30, 1, 32, 33, 58, 28, 14, 32, 28, 7, 33, 58, 17, 28, 14, 32, 28, 41, 30, 28, 37, 33, 58, 20, 8, 58, 2, 30, 28, 22, 33, 28, 10, 8, 17, 31, 20, 28, 41, 30, 28, 14, 1, 30, 28, 56, 33, 20, 28, 26, 30, 15, 30, 38, 20, 30, 48, 28, 18, 15, 28, 34, 33, 2, 28, 41, 8, 58, 28, 34, 33, 2, 28, 7, 8, 19, 30, 28, 18, 15, 28, 34, 33, 2, 28, 7, 33, 32, 30, 28, 34, 33, 2, 28, 26, 8, 30, 28, 18, 15, 28, 34, 33, 2, 28, 26, 33, 58, 28, 20, 28, 10, 8, 17, 31, 20, 28, 34, 33, 2, 28, 37, 38, 58, 28, 20, 28, 41, 8, 58, 28, 34, 33, 2, 28, 45, 58, 48, 30, 1, 32, 20, 38, 58, 48, 28, 26, 33, 58, 28, 20, 28, 34, 33, 2, 28, 53, 58, 30, 28, 26, 38, 40, 28, 53, 1, 28, 14, 58, 33, 20, 31, 30, 1, 28, 24, 19, 30, 1, 40, 33, 58, 30, 28, 34, 33, 2, 28, 37, 38, 1, 30, 28, 14, 46, 33, 2, 20, 28, 24, 19, 30, 58, 20, 2, 38, 42, 42, 40, 28, 26, 8, 30, 32, 28, 18, 20, 28, 32, 28, 49, 33, 3, 30, 20, 31, 8, 58, 17, 28, 41, 30, 28, 49, 8, 3, 0, 42, 40, 28, 37, 38, 58, 28, 20, 28, 14, 16, 16, 30, 0, 20, 28, 18, 20, 28, 32, 28, 14, 28, 29, 30, 38, 42, 8, 59, 38, 20, 8, 33, 58, 28, 22, 31, 38, 20, 28, 37, 33, 2, 42, 48, 28, 26, 1, 8, 19, 30, 28, 34, 33, 2, 28, 18, 58, 32, 38, 58, 30, 28, 34, 33, 2, 28, 1, 30, 28, 12, 33, 58, 58, 38, 28, 37, 38, 1, 30, 28, 41, 31, 38, 20, 28, 53, 20, 31, 30, 1, 28, 55, 30, 33, 0, 42, 30, 28, 22, 31, 8, 58, 54, 28, 14, 58, 48, 28, 11, 30, 28, 49, 33, 3, 30, 33, 58, 30, 28, 34, 33, 2, 28, 1, 30, 28, 56, 33, 20, 28, 34, 33, 2, 1, 28, 41, 31, 33, 42, 30, 28, 7, 8, 15, 30, 28, 34, 33, 2, 28, 1, 30, 28, 10, 8, 58, 30, 28, 14, 32, 28, 34, 33, 2, 28, 14, 1, 30, 28, 49, 33, 28, 22, 38, 42, 54, 28, 18, 58, 28, 34, 33, 2, 1, 28, 53, 39, 58, 28, 41, 33, 1, 48, 32, 28, 24, 19, 30, 1, 40, 33, 58, 30, 28, 6, 38, 48, 28, 22, 33, 28, 11, 30, 28, 26, 1, 2, 58, 54, 28, 53, 58, 28, 49, 33, 3, 30, 20, 31, 8, 58, 28, 22, 33, 28, 27, 30, 30, 0, 28, 55, 2, 32, 31, 8, 58, 17, 28, 53, 58, 28, 24, 19, 30, 1, 40, 33, 58, 30, 28, 41, 38, 32, 28, 14, 28, 49, 42, 38, 19, 30, 28, 22, 33, 28, 49, 33, 3, 30, 20, 31, 8, 58, 28, 22, 31, 8, 32, 28, 41, 33, 1, 42, 48, 28, 18, 32, 28, 37, 1, 2, 30, 42, 28, 14, 58, 48, 28, 18, 20, 28, 32, 28, 14, 42, 32, 33, 28, 44, 30, 1, 40, 28, 11, 30, 38, 2, 20, 8, 15, 2, 42, 28, 56, 33, 28, 53, 58, 30, 28, 27, 58, 33, 39, 32, 28, 41, 31, 38, 20, 28, 22, 31, 30, 28, 53, 2, 20, 16, 33, 3, 30, 28, 41, 8, 42, 42, 28, 11, 30, 28, 49, 33, 28, 37, 31, 33, 33, 32, 30, 28, 41, 31, 38, 20, 30, 19, 30, 1, 28, 34, 33, 2, 28, 42, 42, 28, 29, 30, 17, 1, 30, 20, 28, 22, 31, 30, 28, 7, 30, 38, 32, 20, 28, 26, 33, 28, 40, 33, 2, 28, 58, 30, 30, 48, 28, 38, 28, 1, 30, 38, 32, 33, 58, 28, 20, 33, 28, 58, 33, 20, 28, 39, 38, 58, 20, 28, 20, 33, 28, 42, 33, 32, 30, 28, 11, 30, 8, 58, 17, 28, 20, 31, 30, 28, 46, 30, 32, 20, 28, 48, 30, 16, 33, 40, 28, 30, 19, 30, 1, 28, 8, 32, 28, 38, 32, 28, 16, 33, 33, 42, 28, 38, 32, 28, 46, 30, 8, 58, 17, 28, 20, 31, 30, 28, 38, 16, 30, 28, 34, 33, 2, 28, 16, 38, 58, 28, 15, 42, 40, 28, 30, 19, 30, 58, 28, 31, 8, 17, 31, 30, 1, 28, 18, 15, 28, 20, 31, 30, 40, 28, 38, 48, 25, 2, 32, 20, 28, 20, 33, 28, 3, 30, 28, 18, 28, 31, 38, 19, 30, 28, 20, 33, 28, 38, 48, 25, 2, 32, 20, 28, 8, 58, 28, 20, 2, 1, 58, 28, 41, 31, 33, 30, 19, 30, 1, 28, 32, 20, 33, 0, 32, 28, 38, 48, 25, 2, 32, 20, 8, 58, 17, 28, 39, 33, 58, 28, 20, 28, 46, 30, 28, 38, 46, 42, 30, 28, 20, 33, 28, 16, 33, 58, 20, 8, 58, 2, 30, 28, 15, 33, 1, 39, 38, 1, 48, 28, 22, 31, 30, 28, 42, 38, 32, 20, 28, 33, 58, 30, 32, 28, 32, 20, 38, 58, 48, 8, 58, 17, 28, 38, 1, 30, 28, 20, 31, 30, 28, 19, 8, 16, 20, 33, 1, 32, 28, 53, 58, 42, 40, 28, 20, 31, 30, 28, 32, 20, 1, 33, 58, 17, 30, 32, 20, 28, 18, 15, 28, 40, 33, 2, 28, 39, 38, 58, 20, 28, 20, 33, 28, 46, 30, 28, 20, 31, 30, 28, 42, 38, 32, 20, 28, 33, 58, 30, 28, 32, 20, 38, 58, 48, 8, 58, 17, 28, 46, 30, 16, 33, 3, 30, 28, 32, 20, 1, 33, 58, 17, 28, 7, 8, 15, 30, 28, 32, 28, 38, 28, 46, 33, 1, 30, 28, 8, 15, 28, 40, 33, 2, 28, 48, 33, 58, 28, 20, 28, 16, 31, 38, 42, 42, 30, 58, 17, 30, 28, 40, 33, 2, 1, 32, 30, 42, 15, 28, 22, 31, 30, 1, 30, 28, 38, 1, 30, 28, 32, 33, 3, 30, 28, 15, 42, 33, 39, 30, 1, 32, 28, 40, 33, 2, 28, 33, 58, 42, 40, 28, 32, 30, 30, 28, 39, 31, 30, 58, 28, 40, 33, 2, 28, 20, 38, 54, 30, 28, 48, 30, 20, 33, 2, 1, 32, 28, 11, 30, 8, 58, 17, 28, 39, 30, 38, 54, 28, 3, 30, 38, 58, 32, 28, 20, 31, 38, 20, 28, 20, 31, 30, 1, 30, 28, 8, 32, 28, 1, 33, 33, 3, 28, 20, 33, 28, 17, 1, 33, 39, 28, 22, 33, 48, 38, 40, 28, 3, 8, 17, 31, 20, 28, 46, 30, 28, 20, 31, 30, 28, 16, 31, 38, 58, 16, 30, 28, 20, 33, 28, 17, 1, 38, 32, 0, 28, 20, 31, 30, 28, 16, 31, 38, 58, 16, 30, 28, 20, 33, 28, 42, 30, 20, 28, 40, 33, 2, 1, 28, 20, 38, 42, 30, 58, 20, 28, 46, 42, 33, 33, 3, 28, 18, 15, 28, 40, 33, 2, 28, 1, 30, 28, 17, 33, 58, 58, 38, 28, 31, 8, 20, 28, 8, 20, 28, 31, 8, 20, 28, 8, 20, 28, 2, 58, 20, 8, 42, 28, 8, 20, 28, 46, 1, 30, 38, 54, 32]\n","Length of sequence: 12501\n"]}],"source":["# Convert the text data into sequences\n","sequences = []\n","for char in all_anime_quotes:\n","  token = char_to_token[char]\n","  sequences.append(token)\n","\n","print(sequences)\n","print(f\"Length of sequence: {len(sequences)}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x0nhxpTS300t"},"outputs":[],"source":["# From the sequence_data create a list containing\n","sequence_length = 100\n","sequences_as_tf_data = tf.data.Dataset.from_tensor_slices(sequences).batch(sequence_length+1, drop_remainder=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":474,"status":"ok","timestamp":1661590478111,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"},"user_tz":-60},"id":"52eLBp2r-NKB","outputId":"481ff95d-86fd-41b3-ac52-fb2e09f9175c"},"outputs":[{"output_type":"stream","name":"stdout","text":["People’s lives don’t end when they die, it ends when they lose faith. If you don’t take risks, you ca\n","n’t create a future! If you don’t like your destiny, don’t accept it. When you give up, that’s when t\n"]}],"source":["# display the 2 samples from the dataset\n","for sample in sequences_as_tf_data.take(2):\n","  print(\"\".join([token_to_char[token] for token in sample.numpy()]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ow8IY9-d_jnL"},"outputs":[],"source":["# Split sequences into features and labels\n","def split_sequence(sequence):\n","  feature = sequence[:-1]\n","  label = sequence[1:]\n","  return feature, label\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1661590484117,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"},"user_tz":-60},"id":"QVdTfXhn_9h3","outputId":"4b7ddbcc-da6e-4092-8594-c8a366462e79"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Feature, Label pair\n","People’s lives don’t end when they die, it ends when they lose faith. If you don’t take risks, you c\n","eople’s lives don’t end when they die, it ends when they lose faith. If you don’t take risks, you ca\n","\n","Feature, Label pair\n","n’t create a future! If you don’t like your destiny, don’t accept it. When you give up, that’s when \n","’t create a future! If you don’t like your destiny, don’t accept it. When you give up, that’s when t\n"]}],"source":["# try it out on the 2 samples\n","for sample in sequences_as_tf_data.take(2):\n","  (feature, label) = split_sequence(sample.numpy())\n","  print(\"\\nFeature, Label pair\")\n","  print(\"\".join([token_to_char[token] for token in feature]))\n","  print(\"\".join([token_to_char[token] for token in label]))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":503,"status":"ok","timestamp":1661590491899,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"},"user_tz":-60},"id":"gtMyzHZPBrdl","outputId":"a2e318d9-fc8d-46f6-c939-6d5049e41d10"},"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[55 30 33  0 42 30 13 32 28 42  8 19 30 32 28 48 33 58 13 20 28 30 58 48\n"," 28 39 31 30 58 28 20 31 30 40 28 48  8 30 52 28  8 20 28 30 58 48 32 28\n"," 39 31 30 58 28 20 31 30 40 28 42 33 32 30 28 15 38  8 20 31 21 28 18 15\n"," 28 40 33  2 28 48 33 58 13 20 28 20 38 54 30 28  1  8 32 54 32 52 28 40\n"," 33  2 28 16], shape=(100,), dtype=int32)\n","tf.Tensor(\n","[30 33  0 42 30 13 32 28 42  8 19 30 32 28 48 33 58 13 20 28 30 58 48 28\n"," 39 31 30 58 28 20 31 30 40 28 48  8 30 52 28  8 20 28 30 58 48 32 28 39\n"," 31 30 58 28 20 31 30 40 28 42 33 32 30 28 15 38  8 20 31 21 28 18 15 28\n"," 40 33  2 28 48 33 58 13 20 28 20 38 54 30 28  1  8 32 54 32 52 28 40 33\n","  2 28 16 38], shape=(100,), dtype=int32)\n"]}],"source":["# Apply the split_sequence function to the dataset\n","feature_label_data = sequences_as_tf_data.map(split_sequence)\n","\n","for feature, label in feature_label_data.take(1):\n","  print(feature)\n","  print(label)\n"]},{"cell_type":"markdown","metadata":{"id":"wg-agsE_CipS"},"source":["We have our text data prepared. Inputs to the model is a sequence of tokens and the label is also the same sequence shifted by 1 to the right."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F3jloXi2CWUt"},"outputs":[],"source":["# might be easier to convert sequences to strings if we define a function to convert it\n","def convert_sequence_to_string(sequence):\n","  string = \"\".join([token_to_char[token] for token in sequence])\n","  return string\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1661590510411,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"},"user_tz":-60},"id":"HTAShoOJEUs2","outputId":"254713d7-4b67-430e-bc0f-00a0f0e11c86"},"outputs":[{"output_type":"stream","name":"stdout","text":["People’s lives don’t end when they die, it ends when they lose faith. If you don’t take risks, you c\n","eople’s lives don’t end when they die, it ends when they lose faith. If you don’t take risks, you ca\n"]}],"source":["for feature, label in feature_label_data.take(1):\n","  print(convert_sequence_to_string(feature.numpy()))\n","  print(convert_sequence_to_string(label.numpy()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_yuzZP2BNgub"},"outputs":[],"source":["# create a batched dataset\n","batched_dataset = (feature_label_data.batch(1))"]},{"cell_type":"markdown","metadata":{"id":"G1m9iy6pRXI_"},"source":["Althought this seems un-necessary considering that, there is really only 124 samples, RNN models expect a batch dimension. "]},{"cell_type":"markdown","metadata":{"id":"6UmqtMZAEmK7"},"source":["# **Define the RNN model**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0fTe2asMKOUg"},"outputs":[],"source":["vocab_size = 61\n","Embedding_dim = 128\n","GRU_units = 256\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2191,"status":"ok","timestamp":1661590565871,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"},"user_tz":-60},"id":"SeimhMxgEtmI","outputId":"886977ed-a829-451d-b4f5-a50cd199f040"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]}],"source":["# define a text generation model\n","Anime_qoutes_model = tf.keras.Sequential([tf.keras.layers.Embedding(vocab_size, Embedding_dim),\n","                                         tf.keras.layers.GRU(units=GRU_units, dropout=0.5, \n","                                                             recurrent_dropout=0.25,\n","                                                             return_sequences=True),\n","                                         tf.keras.layers.Dense(units=vocab_size, activation=\"softmax\")])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33,"status":"ok","timestamp":1661590568532,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"},"user_tz":-60},"id":"ZK6n-foDU4kQ","outputId":"a8ad89e4-5563-48d0-e95d-9d869ed7fd1d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, None, 128)         7808      \n","                                                                 \n"," gru (GRU)                   (None, None, 256)         296448    \n","                                                                 \n"," dense (Dense)               (None, None, 61)          15677     \n","                                                                 \n","=================================================================\n","Total params: 319,933\n","Trainable params: 319,933\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["# Compile the model\n","Anime_qoutes_model.compile(optimizer='adam',\n","                           loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","                           )\n","\n","Anime_qoutes_model.summary()"]},{"cell_type":"markdown","metadata":{"id":"AO_-TfITPX5A"},"source":["Some notes missed out from an unsaved version\n","- Batch dimension in the data is needed for RNN \n","- SparseCategoricalCrossentropy used for multiclass classification when expected labels are integers and not one-hot encoded labels.\n","- Use categoricalCrossentropy loss for multiclass classifications with one-hot encoded labels"]},{"cell_type":"markdown","metadata":{"id":"ssFrk2CkN6YY"},"source":["# **Train the model**"]},{"cell_type":"markdown","metadata":{"id":"U6fFiMQwR_pX"},"source":["**Run forward pass and get the loss**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":613,"status":"ok","timestamp":1661590575919,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"},"user_tz":-60},"id":"uILJB7GHR-r3","outputId":"dc73190c-f6e5-4a5a-d341-d2670759977c"},"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[55 30 33  0 42 30 13 32 28 42  8 19 30 32 28 48 33 58 13 20 28 30 58 48\n"," 28 39 31 30 58 28 20 31 30 40 28 48  8 30 52 28  8 20 28 30 58 48 32 28\n"," 39 31 30 58 28 20 31 30 40 28 42 33 32 30 28 15 38  8 20 31 21 28 18 15\n"," 28 40 33  2 28 48 33 58 13 20 28 20 38 54 30 28  1  8 32 54 32 52 28 40\n"," 33  2 28 16], shape=(100,), dtype=int32)\n","tf.Tensor(\n","[30 33  0 42 30 13 32 28 42  8 19 30 32 28 48 33 58 13 20 28 30 58 48 28\n"," 39 31 30 58 28 20 31 30 40 28 48  8 30 52 28  8 20 28 30 58 48 32 28 39\n"," 31 30 58 28 20 31 30 40 28 42 33 32 30 28 15 38  8 20 31 21 28 18 15 28\n"," 40 33  2 28 48 33 58 13 20 28 20 38 54 30 28  1  8 32 54 32 52 28 40 33\n","  2 28 16 38], shape=(100,), dtype=int32)\n"]}],"source":["# get a single feature and label from the batch dataset\n","for batch_feature, batch_label in batched_dataset.take(1):\n","  print(batch_feature[0])\n","  print(batch_label[0])\n","  "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1661590580722,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"},"user_tz":-60},"id":"ZYHpm8GuSiQy","outputId":"0f048dc6-f993-44bc-d5b2-1bf9cd56755d"},"outputs":[{"output_type":"stream","name":"stdout","text":["People’s lives don’t end when they die, it ends when they lose faith. If you don’t take risks, you c\n","eople’s lives don’t end when they die, it ends when they lose faith. If you don’t take risks, you ca\n"]}],"source":["# display the string\n","print(convert_sequence_to_string(batch_feature[0].numpy()))\n","print(convert_sequence_to_string(batch_label[0].numpy()))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2978,"status":"ok","timestamp":1661590588394,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"},"user_tz":-60},"id":"Hzqv_33TS2TW","outputId":"0e0a48a7-2d86-4655-ba79-6f8bb9679bb2"},"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[[[0.01644353 0.01639114 0.01645644 ... 0.01631887 0.01625522 0.0166002 ]\n","  [0.01636711 0.01647367 0.01622433 ... 0.01640512 0.01645475 0.01650914]\n","  [0.01642953 0.01659862 0.01609304 ... 0.01649837 0.01635189 0.01639101]\n","  ...\n","  [0.01637354 0.01678303 0.01618241 ... 0.01650596 0.01639222 0.01627393]\n","  [0.01636053 0.01669525 0.01630641 ... 0.01667272 0.0164395  0.01614342]\n","  [0.01665466 0.01635142 0.01626649 ... 0.01645242 0.01649253 0.01620634]]], shape=(1, 100, 61), dtype=float32)\n"]}],"source":["# pass the feature to the untrained model and get the prediction\n","batch_prediction = Anime_qoutes_model(batch_feature)\n","print(batch_prediction)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":430,"status":"ok","timestamp":1661590599638,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"},"user_tz":-60},"id":"5iY2uc9hTK-m","outputId":"3d596342-931f-42c8-f17c-5483bb4192e9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sorry that's a no no\n","Exception encountered when calling layer \"sequential\" (type Sequential).\n","\n","Input 0 of layer \"gru\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (100, 128)\n","\n","Call arguments received:\n","  • inputs=tf.Tensor(shape=(100,), dtype=int32)\n","  • training=False\n","  • mask=None\n"]}],"source":["# something intresting to show\n","# try passing just the feature and not the batch feature.\n","try:\n","  batch_prediction = Anime_qoutes_model(batch_feature[0])\n","  print(batch_prediction)\n","except Exception as e:\n","  print(\"Sorry that's a no no\")\n","  print(f\"{e}\")"]},{"cell_type":"markdown","metadata":{"id":"pjFPOKL7TxLP"},"source":["The GRU layer expects a feature with 3 dimensions: `[batch dimension, time steps, time step dimension]`"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":457,"status":"ok","timestamp":1661590604461,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"},"user_tz":-60},"id":"fRINYjtKTtVT","outputId":"0e254bf9-1753-4ad3-ef5d-0e498c72fc89"},"outputs":[{"output_type":"stream","name":"stdout","text":["['-', '!', ':', '“', '?', 'B', 'Y', 'O', 'i', '?', 'k', 'r', 'B', 's', 'i', 'i', 'i', '-', 'f', 'a', 'i', 'B', 'l', 'l', 'i', 'i', 'i', 'B', 'l', 'i', 'a', 'i', 'B', '!', 'i', 'i', 'i', 'B', 'M', 'i', 'i', 'r', 'i', 'B', '’', 'T', 'l', 'i', 'F', 'i', 'B', 'l', 'i', 'a', 'i', 'B', '!', 'i', '?', ':', ':', 'B', 'i', '’', '’', 'k', 'a', 'i', 'Y', 'i', 'i', 'g', 'i', 'g', ':', 'i', 'i', 'i', 'i', '-', 'f', 'a', 'i', 'a', 'a', 'd', 'B', 'i', 'M', 'i', 'k', 'Y', 'o', 'F', 'i', 'g', ':', 'i', 'i', 'i']\n"]}],"source":["# convert the prediction into a readable text\n","predicted_char_list = []\n","for prob_distribution in batch_prediction[0].numpy():\n","  char_id = np.argmax(prob_distribution)\n","  predicted_char_list.append(token_to_char[char_id])\n","\n","print(predicted_char_list)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":395,"status":"ok","timestamp":1661590624278,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"},"user_tz":-60},"id":"pkS7DWa1YwYT","outputId":"3bdf2e02-3719-4d65-d6cb-fb16ad184642"},"outputs":[{"output_type":"stream","name":"stdout","text":["-!:“?BYOi?krBsiii-faiBlliiiBliaiB!iiiBMiiriB’TliFiBliaiB!i?::Bi’’kaiYiigig:iiii-faiaadBiMikYoFig:iii\n","100\n"]}],"source":["predicted_text = \"\".join(predicted_char_list)\n","print(predicted_text)\n","print(len(predicted_text))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":578,"status":"ok","timestamp":1661590630590,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"},"user_tz":-60},"id":"rLD34GvYZC7d","outputId":"f92f9ef2-4254-4817-b3a5-e7ffc0418c82"},"outputs":[{"output_type":"stream","name":"stdout","text":["4.106488\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n","  return dispatch_target(*args, **kwargs)\n"]}],"source":["# get the loss of the model\n","loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","example_loss = loss(batch_label, batch_prediction).numpy()\n","print(example_loss)\n"]},{"cell_type":"markdown","metadata":{"id":"x1R3ueTUbdCF"},"source":["Sort of need to make sense of the warning. I've found this [thread](https://stackoverflow.com/questions/67848962/selecting-loss-and-metrics-for-tensorflow-model) on stackoverflow that provides some better guidance on selecting loss, metrics and difference between softmax and sigmoid activation.\n","\n","**TLDR Summary**\n","- Use **sparse_categorical_accuracy as a metric for classification task**, where the **label is an integer** and not a one-hot encoded label.\n","- Similarly, we can use **spare_categorical_crossentropy** as a **loss function for classification task** in the same scenario as above.\n","\n","<br>\n","\n","- In cases, where we have our **labels represented as one-hot encoded vectors** we could use **categorical_accuracy as a metric** and **categorical_crossentropy as a loss function**.\n","\n","<br>\n","\n","- **softmax activation functions** are commonly used as the activation function in the output layer for the **classification task**. These functions produce a **probabilitiy distribution, so the sum of the output from the layer = 1**.\n","Generally if the model outputs a probability distribution, **you'll need to set the from_logits = False**.\n","\n","<br>\n","\n","So what are Logits???   \n","[Another stack overflow thread](https://stackoverflow.com/questions/34240703/what-are-logits-what-is-the-difference-between-softmax-and-softmax-cross-entrop)\n","\n","**Summary**\n","\n"]},{"cell_type":"markdown","source":["-- **Calculate the loss**"],"metadata":{"id":"8f_zvh_biAKx"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":849,"status":"ok","timestamp":1661590858073,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"},"user_tz":-60},"id":"D9xzHS5Ubc33","outputId":"9b77bc93-b9f5-42a9-fcfc-61e5802f3ccb"},"outputs":[{"output_type":"stream","name":"stdout","text":["4.106488\n"]}],"source":["# define the loss without setting the from_logits argument to be true\n","loss=tf.keras.losses.SparseCategoricalCrossentropy()\n","example_loss = loss(batch_label, batch_prediction).numpy()\n","print(example_loss)\n"]},{"cell_type":"markdown","metadata":{"id":"YgTXh5LIcEl9"},"source":["Happy days.\n","\n","As annoying as it is i think it is best i keep the errors in the notebook so that i and anyone who might be reading this can easily see the issues, lessons and solutions i came across.\n"]},{"cell_type":"markdown","source":["## **Redefine the model and train it**"],"metadata":{"id":"iBNjWywniaTc"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":532,"status":"ok","timestamp":1661590903632,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"},"user_tz":-60},"id":"460N_x7SgbAA","outputId":"eb21acd8-8dbd-4251-b2a1-5b157efda313"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]}],"source":["Anime_qoutes_model = tf.keras.Sequential([tf.keras.layers.Embedding(vocab_size,\n","                                                                    Embedding_dim),\n","                                          tf.keras.layers.GRU(units=GRU_units,\n","                                                              dropout=0.5,\n","                                                              recurrent_dropout=0.25,\n","                                                              return_sequences=True),\n","                                          tf.keras.layers.Dense(units=vocab_size, activation=\"softmax\")])\n","\n","Anime_qoutes_model.compile(optimizer='adam',\n","                           loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), #from_logits is set to False by default\n","                           metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Gq2u284OEeD"},"outputs":[],"source":["# define the model call backs\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=\"./model_checkpoints/model_epoch_{epoch}_loss_{loss}\",\n","                                                               monitor='loss',\n","                                                               save_best_only=True)\n","early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta=0.1, patience=4)"]},{"cell_type":"markdown","source":["increased epoch from 22 to 60, to see if we can get a better accuracy and performance when generating text"],"metadata":{"id":"Q2agbfYpjB_j"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x6qd0RXwO5zS","executionInfo":{"status":"ok","timestamp":1661593625438,"user_tz":-60,"elapsed":2529024,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"38162044-d623-4ea6-dc66-0f6dc8d8393d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/60\n","123/123 [==============================] - ETA: 0s - loss: 3.0775 - sparse_categorical_accuracy: 0.2193"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f40a0389950> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 52s 399ms/step - loss: 3.0775 - sparse_categorical_accuracy: 0.2193\n","Epoch 2/60\n","123/123 [==============================] - ETA: 0s - loss: 2.4744 - sparse_categorical_accuracy: 0.3305"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f40a0389950> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 51s 414ms/step - loss: 2.4744 - sparse_categorical_accuracy: 0.3305\n","Epoch 3/60\n","123/123 [==============================] - ETA: 0s - loss: 2.3224 - sparse_categorical_accuracy: 0.3513"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f40a0389950> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 50s 407ms/step - loss: 2.3224 - sparse_categorical_accuracy: 0.3513\n","Epoch 4/60\n","123/123 [==============================] - ETA: 0s - loss: 2.2301 - sparse_categorical_accuracy: 0.3702"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f40a0389950> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 49s 398ms/step - loss: 2.2301 - sparse_categorical_accuracy: 0.3702\n","Epoch 5/60\n","123/123 [==============================] - ETA: 0s - loss: 2.1493 - sparse_categorical_accuracy: 0.3875"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f40a0389950> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 49s 399ms/step - loss: 2.1493 - sparse_categorical_accuracy: 0.3875\n","Epoch 6/60\n","123/123 [==============================] - ETA: 0s - loss: 2.0734 - sparse_categorical_accuracy: 0.4056"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f40a0389950> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 49s 401ms/step - loss: 2.0734 - sparse_categorical_accuracy: 0.4056\n","Epoch 7/60\n","123/123 [==============================] - ETA: 0s - loss: 2.0078 - sparse_categorical_accuracy: 0.4274"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f40a0389950> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 49s 399ms/step - loss: 2.0078 - sparse_categorical_accuracy: 0.4274\n","Epoch 8/60\n","123/123 [==============================] - ETA: 0s - loss: 1.9416 - sparse_categorical_accuracy: 0.4441"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f40a0389950> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 49s 399ms/step - loss: 1.9416 - sparse_categorical_accuracy: 0.4441\n","Epoch 9/60\n","123/123 [==============================] - ETA: 0s - loss: 1.8789 - sparse_categorical_accuracy: 0.4539"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f40a0389950> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 50s 408ms/step - loss: 1.8789 - sparse_categorical_accuracy: 0.4539\n","Epoch 10/60\n","123/123 [==============================] - ETA: 0s - loss: 1.8062 - sparse_categorical_accuracy: 0.4754"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f40a0389950> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 50s 410ms/step - loss: 1.8062 - sparse_categorical_accuracy: 0.4754\n","Epoch 11/60\n","123/123 [==============================] - ETA: 0s - loss: 1.7432 - sparse_categorical_accuracy: 0.4907"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f40a0389950> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 51s 412ms/step - loss: 1.7432 - sparse_categorical_accuracy: 0.4907\n","Epoch 12/60\n","123/123 [==============================] - ETA: 0s - loss: 1.6821 - sparse_categorical_accuracy: 0.5124"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f40a0389950> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 51s 417ms/step - loss: 1.6821 - sparse_categorical_accuracy: 0.5124\n","Epoch 13/60\n","123/123 [==============================] - ETA: 0s - loss: 1.6206 - sparse_categorical_accuracy: 0.5221"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f40a0389950> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 50s 408ms/step - loss: 1.6206 - sparse_categorical_accuracy: 0.5221\n","Epoch 14/60\n","123/123 [==============================] - ETA: 0s - loss: 1.5700 - sparse_categorical_accuracy: 0.5365"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f40a0389950> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 51s 413ms/step - loss: 1.5700 - sparse_categorical_accuracy: 0.5365\n","Epoch 15/60\n","123/123 [==============================] - ETA: 0s - loss: 1.5170 - sparse_categorical_accuracy: 0.5507"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f40a0389950> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 50s 403ms/step - loss: 1.5170 - sparse_categorical_accuracy: 0.5507\n","Epoch 16/60\n","123/123 [==============================] - ETA: 0s - loss: 1.4618 - sparse_categorical_accuracy: 0.5704"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f40a0389950> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 49s 395ms/step - loss: 1.4618 - sparse_categorical_accuracy: 0.5704\n","Epoch 17/60\n","123/123 [==============================] - ETA: 0s - loss: 1.4176 - sparse_categorical_accuracy: 0.5783"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f40a0389950> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 49s 397ms/step - loss: 1.4176 - sparse_categorical_accuracy: 0.5783\n","Epoch 18/60\n","123/123 [==============================] - ETA: 0s - loss: 1.3711 - sparse_categorical_accuracy: 0.5884"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f40a0389950> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 49s 398ms/step - loss: 1.3711 - sparse_categorical_accuracy: 0.5884\n","Epoch 19/60\n","123/123 [==============================] - ETA: 0s - loss: 1.3271 - sparse_categorical_accuracy: 0.5974"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f40a0389950> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 49s 400ms/step - loss: 1.3271 - sparse_categorical_accuracy: 0.5974\n","Epoch 20/60\n","123/123 [==============================] - ETA: 0s - loss: 1.2931 - sparse_categorical_accuracy: 0.6078"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f40a0389950> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 48s 393ms/step - loss: 1.2931 - sparse_categorical_accuracy: 0.6078\n","Epoch 21/60\n","123/123 [==============================] - ETA: 0s - loss: 1.2606 - sparse_categorical_accuracy: 0.6171"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f40a0389950> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 51s 411ms/step - loss: 1.2606 - sparse_categorical_accuracy: 0.6171\n","Epoch 22/60\n","123/123 [==============================] - ETA: 0s - loss: 1.2230 - sparse_categorical_accuracy: 0.6246"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f40a0389950> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 50s 409ms/step - loss: 1.2230 - sparse_categorical_accuracy: 0.6246\n","Epoch 23/60\n","123/123 [==============================] - ETA: 0s - loss: 1.1896 - sparse_categorical_accuracy: 0.6350"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f40a0389950> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 49s 397ms/step - loss: 1.1896 - sparse_categorical_accuracy: 0.6350\n","Epoch 24/60\n","123/123 [==============================] - ETA: 0s - loss: 1.1490 - sparse_categorical_accuracy: 0.6426"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f40a0389950> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 49s 395ms/step - loss: 1.1490 - sparse_categorical_accuracy: 0.6426\n","Epoch 25/60\n","123/123 [==============================] - ETA: 0s - loss: 1.1266 - sparse_categorical_accuracy: 0.6540"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f40a0389950> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 49s 396ms/step - loss: 1.1266 - sparse_categorical_accuracy: 0.6540\n","Epoch 26/60\n","123/123 [==============================] - ETA: 0s - loss: 1.1084 - sparse_categorical_accuracy: 0.6546"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f40a0389950> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 48s 391ms/step - loss: 1.1084 - sparse_categorical_accuracy: 0.6546\n","Epoch 27/60\n","123/123 [==============================] - ETA: 0s - loss: 1.0726 - sparse_categorical_accuracy: 0.6682"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f40a0389950> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 50s 406ms/step - loss: 1.0726 - sparse_categorical_accuracy: 0.6682\n","Epoch 28/60\n","123/123 [==============================] - ETA: 0s - loss: 1.0471 - sparse_categorical_accuracy: 0.6707"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f40a0389950> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 50s 410ms/step - loss: 1.0471 - sparse_categorical_accuracy: 0.6707\n","Epoch 29/60\n","123/123 [==============================] - ETA: 0s - loss: 1.0357 - sparse_categorical_accuracy: 0.6764"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f40a0389950> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 50s 408ms/step - loss: 1.0357 - sparse_categorical_accuracy: 0.6764\n","Epoch 30/60\n","123/123 [==============================] - ETA: 0s - loss: 1.0101 - sparse_categorical_accuracy: 0.6811"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f40a0389950> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 50s 411ms/step - loss: 1.0101 - sparse_categorical_accuracy: 0.6811\n","Epoch 31/60\n","123/123 [==============================] - ETA: 0s - loss: 0.9904 - sparse_categorical_accuracy: 0.6850"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f40a0389950> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 50s 410ms/step - loss: 0.9904 - sparse_categorical_accuracy: 0.6850\n","Epoch 32/60\n","123/123 [==============================] - ETA: 0s - loss: 0.9764 - sparse_categorical_accuracy: 0.6921"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f40a0389950> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 50s 410ms/step - loss: 0.9764 - sparse_categorical_accuracy: 0.6921\n"]}],"source":["history = Anime_qoutes_model.fit(batched_dataset, epochs=60,\n","                                 callbacks=[model_checkpoint_callback, early_stopping_callback])"]},{"cell_type":"markdown","metadata":{"id":"5k5gXIEUSZ8R"},"source":["i have a feeling the final model is going to overfit onto the dataset, might be best to stop at the 10th epoch.\n","\n","I'm not quite sure what is going on with this Warning   \n","- 0.3391WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f3a90345450> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","\n","Found related [issue](https://github.com/keras-team/keras/issues/15964) **Correct, the warnings have to do with the saving only and are indeed not related to model.fit**"]},{"cell_type":"markdown","metadata":{"id":"CapE3UfPieww"},"source":["# **Generate text using the trained model**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KuEoSAQqipc3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661593803614,"user_tz":-60,"elapsed":653,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"1b887548-9001-47b0-ecc4-f847c8387c6d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Never going to take me down\n","[56, 30, 19, 30, 1, 28, 17, 33, 8, 58, 17, 28, 20, 33, 28, 20, 38, 54, 30, 28, 3, 30, 28, 48, 33, 39, 58]\n","27\n"]}],"source":["# if you know, you know\n","Seed_word = \"Never going to take me down\"\n","Seed_word_id = []\n","for char in Seed_word:\n","  id = char_to_token[char]\n","  Seed_word_id.append(id)\n","\n","print(Seed_word)\n","print(Seed_word_id)\n","print(len(Seed_word_id))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7DA2dPydutt-"},"outputs":[],"source":["for i in range(100):\n","  # get the model prediction\n","  prediction = Anime_qoutes_model.predict([Seed_word_id])\n","  # print(prediction.shape)\n","\n","  # use the final prediction\n","  final_prediction_distribution = prediction[0][-1]\n","  predicted_char_id = np.argmax(final_prediction_distribution)\n","  predicted_char = token_to_char[predicted_char_id]\n","  # print(f\"predicted_char_id: {predicted_char_id}\")\n","  # print(f\"predicted_char: {predicted_char}\")\n","  \n","  Seed_word_id.append(predicted_char_id)\n","\n"]},{"cell_type":"code","source":["print(Seed_word_id)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9gmDxAMRedfO","executionInfo":{"status":"ok","timestamp":1661593830422,"user_tz":-60,"elapsed":339,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"46d30cd3-aa79-41b7-953c-ef57be8db016"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[56, 30, 19, 30, 1, 28, 17, 33, 8, 58, 17, 28, 20, 33, 28, 20, 38, 54, 30, 28, 3, 30, 28, 48, 33, 39, 58, 28, 41, 30, 28, 49, 8, 3, 0, 42, 30, 28, 32, 20, 30, 0, 21, 28, 41, 30, 28, 25, 2, 32, 20, 28, 8, 3, 0, 33, 1, 20, 38, 58, 20, 28, 20, 33, 28, 46, 30, 28, 31, 38, 0, 0, 40, 23, 28, 18, 28, 38, 3, 28, 20, 31, 30, 28, 20, 33, 1, 28, 20, 31, 30, 28, 42, 8, 17, 31, 20, 28, 18, 15, 28, 40, 33, 2, 28, 39, 38, 58, 20, 28, 20, 33, 28, 46, 30, 28, 31, 38, 0, 0, 40, 23, 28, 18, 28, 38, 3]\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7GqkCIfUwRDK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661593837684,"user_tz":-60,"elapsed":857,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"73b3dba5-cc69-4a53-c929-055042e83321"},"outputs":[{"output_type":"stream","name":"stdout","text":["Initial seed text:  Never going to take me down\n","Never going to take me down We Simple step. We just important to be happy? I am the tor the light If you want to be happy? I am\n"]}],"source":["print(\"Initial seed text: \", Seed_word)\n","list_of_generated_char = [token_to_char[token] for token in Seed_word_id]\n","generated_text = \"\".join(list_of_generated_char)\n","print(generated_text)"]},{"cell_type":"markdown","source":["well that is slightly better compared to before, but it looks like it gots stuck in a loop towards the end and keeps predicting the same set of texts.\n","\n","One more try with a different set of input"],"metadata":{"id":"rsdugYC8XfRW"}},{"cell_type":"code","source":["# if you know, you know\n","Seed_word = \"I feel like anything is possible now. I can keep fighting a bit longer. My heartbeat sounds funny. This is my peak, this is my fifth gear\"\n","Seed_word_id = []\n","for char in Seed_word:\n","  id = char_to_token[char]\n","  Seed_word_id.append(id)\n","\n","print(Seed_word)\n","print(Seed_word_id)\n","print(len(Seed_word_id))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YEf7EbHCXfGf","executionInfo":{"status":"ok","timestamp":1661593969808,"user_tz":-60,"elapsed":584,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"da099987-77b6-4153-9281-ca49f1882751"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["I feel like anything is possible now. I can keep fighting a bit longer. My heartbeat sounds funny. This is my peak, this is my fifth gear\n","[18, 28, 15, 30, 30, 42, 28, 42, 8, 54, 30, 28, 38, 58, 40, 20, 31, 8, 58, 17, 28, 8, 32, 28, 0, 33, 32, 32, 8, 46, 42, 30, 28, 58, 33, 39, 21, 28, 18, 28, 16, 38, 58, 28, 54, 30, 30, 0, 28, 15, 8, 17, 31, 20, 8, 58, 17, 28, 38, 28, 46, 8, 20, 28, 42, 33, 58, 17, 30, 1, 21, 28, 9, 40, 28, 31, 30, 38, 1, 20, 46, 30, 38, 20, 28, 32, 33, 2, 58, 48, 32, 28, 15, 2, 58, 58, 40, 21, 28, 22, 31, 8, 32, 28, 8, 32, 28, 3, 40, 28, 0, 30, 38, 54, 52, 28, 20, 31, 8, 32, 28, 8, 32, 28, 3, 40, 28, 15, 8, 15, 20, 31, 28, 17, 30, 38, 1]\n","137\n"]}]},{"cell_type":"code","source":["for i in range(200):\n","  # get the model prediction\n","  prediction = Anime_qoutes_model.predict([Seed_word_id])\n","  # print(prediction.shape)\n","\n","  # use the final prediction\n","  final_prediction_distribution = prediction[0][-1]\n","  predicted_char_id = np.argmax(final_prediction_distribution)\n","  predicted_char = token_to_char[predicted_char_id]\n","  # print(f\"predicted_char_id: {predicted_char_id}\")\n","  # print(f\"predicted_char: {predicted_char}\")\n","  \n","  Seed_word_id.append(predicted_char_id)"],"metadata":{"id":"MTMJU1Toh3tf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(Seed_word_id)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gs0VvitBiq2Z","executionInfo":{"status":"ok","timestamp":1661594008561,"user_tz":-60,"elapsed":40,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"cb07dbdc-9473-42b0-838b-1fef00fb7848"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[18, 28, 15, 30, 30, 42, 28, 42, 8, 54, 30, 28, 38, 58, 40, 20, 31, 8, 58, 17, 28, 8, 32, 28, 0, 33, 32, 32, 8, 46, 42, 30, 28, 58, 33, 39, 21, 28, 18, 28, 16, 38, 58, 28, 54, 30, 30, 0, 28, 15, 8, 17, 31, 20, 8, 58, 17, 28, 38, 28, 46, 8, 20, 28, 42, 33, 58, 17, 30, 1, 21, 28, 9, 40, 28, 31, 30, 38, 1, 20, 46, 30, 38, 20, 28, 32, 33, 2, 58, 48, 32, 28, 15, 2, 58, 58, 40, 21, 28, 22, 31, 8, 32, 28, 8, 32, 28, 3, 40, 28, 0, 30, 38, 54, 52, 28, 20, 31, 8, 32, 28, 8, 32, 28, 3, 40, 28, 15, 8, 15, 20, 31, 28, 17, 30, 38, 1, 20, 28, 20, 31, 30, 28, 46, 30, 32, 20, 28, 38, 58, 48, 28, 32, 20, 33, 0, 32, 28, 38, 58, 48, 28, 16, 38, 58, 28, 58, 30, 19, 30, 1, 28, 31, 33, 39, 28, 0, 38, 20, 31, 30, 20, 8, 16, 28, 20, 31, 30, 28, 46, 30, 32, 20, 28, 38, 58, 48, 28, 32, 20, 33, 0, 32, 28, 38, 58, 48, 28, 16, 38, 58, 28, 58, 30, 19, 30, 1, 28, 31, 33, 39, 28, 0, 38, 20, 31, 30, 20, 8, 16, 28, 20, 31, 30, 28, 46, 30, 32, 20, 28, 38, 58, 48, 28, 32, 20, 33, 0, 32, 28, 38, 58, 48, 28, 16, 38, 58, 28, 58, 30, 19, 30, 1, 28, 31, 33, 39, 28, 0, 38, 20, 31, 30, 20, 8, 16, 28, 20, 31, 30, 28, 46, 30, 32, 20, 28, 38, 58, 48, 28, 32, 20, 33, 0, 32, 28, 38, 58, 48, 28, 16, 38, 58, 28, 58, 30, 19, 30, 1, 28, 31, 33, 39, 28, 0, 38, 20, 31, 30, 20, 8, 16, 28, 20, 31, 30, 28, 46, 30, 32, 20, 28, 38, 58, 48, 28, 32]\n"]}]},{"cell_type":"code","source":["print(\"Initial seed text: \", Seed_word)\n","list_of_generated_char = [token_to_char[token] for token in Seed_word_id]\n","generated_text = \"\".join(list_of_generated_char)\n","print(generated_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"08FaA6uFiuVc","executionInfo":{"status":"ok","timestamp":1661594008563,"user_tz":-60,"elapsed":35,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"1bfc0f97-435a-423d-cdca-df4d10e19d2a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Initial seed text:  I feel like anything is possible now. I can keep fighting a bit longer. My heartbeat sounds funny. This is my peak, this is my fifth gear\n","I feel like anything is possible now. I can keep fighting a bit longer. My heartbeat sounds funny. This is my peak, this is my fifth geart the best and stops and can never how pathetic the best and stops and can never how pathetic the best and stops and can never how pathetic the best and stops and can never how pathetic the best and s\n"]}]},{"cell_type":"markdown","source":["yeah it just ends up with the same set of texts towards the end"],"metadata":{"id":"iTQK3u7ri0Eq"}},{"cell_type":"markdown","source":["i wonder if it's because it's doing nothing with the states, as the  model goes through the sequence, it generates an output probability distribution"],"metadata":{"id":"6TPWo-OpjSmo"}},{"cell_type":"markdown","source":["# **Another attempt with a different model**"],"metadata":{"id":"PDQC0C0LkKtD"}},{"cell_type":"code","source":["vocab_szie = 61\n","Embedding_dim = 128\n","GRU_units = 128"],"metadata":{"id":"Nsoq9EvOlw3N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Anime_qoutes_model_2 = tf.keras.Sequential([tf.keras.layers.Embedding(vocab_size,\n","                                                                    Embedding_dim),\n","                                          tf.keras.layers.GRU(units=GRU_units,\n","                                                              dropout=0.5,\n","                                                              recurrent_dropout=0.25,\n","                                                              return_sequences=True),\n","                                          tf.keras.layers.GRU(units=GRU_units,\n","                                                              dropout=0.5,\n","                                                              recurrent_dropout=0.25,\n","                                                              return_sequences=False),\n","                                          tf.keras.layers.Dense(units=vocab_size, activation=\"softmax\")])\n","\n","Anime_qoutes_model_2.compile(optimizer='adam',\n","                           loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n","                           metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qovr75-XjPI5","executionInfo":{"status":"ok","timestamp":1660854378803,"user_tz":-60,"elapsed":690,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"944e304f-cad0-4d33-d474-dc121a38bf48"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layer gru_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]}]},{"cell_type":"code","source":["# define the model call backs\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=\"./model_checkpoints/model_epoch_{epoch}_loss_{loss}\",\n","                                                               monitor='loss',\n","                                                               save_best_only=True)\n","early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta=0.1, patience=4)"],"metadata":{"id":"J2CgJIbQmLjn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["since the model no longer generates a sequence it would fail if we attempt to train it with the current batched dataset that we have, so the label the model tries to predict should no longer be another sequence but just the final characther."],"metadata":{"id":"Rv3SZJCmnBP-"}},{"cell_type":"code","source":["sequences_as_tf_data\n","\n","def split_sequence(sequence):\n","  feature = sequence[:-1]\n","  label = sequence[-1]\n","  return feature, label\n","\n","for sample in sequences_as_tf_data.take(2):\n","  (feature, label) = split_sequence(sample.numpy())\n","  print(\"\\nFeature, Label pair\")\n","  print(\"\".join([token_to_char[token] for token in feature]))\n","  print(f\"{token_to_char[label]}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mzRuBCFhnRZR","executionInfo":{"status":"ok","timestamp":1660854273448,"user_tz":-60,"elapsed":270,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"68c9b8b4-46bc-496d-e4da-d8b26a67b3b5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Feature, Label pair\n","People’s lives don’t end when they die, it ends when they lose faith. If you don’t take risks, you c\n","a\n","\n","Feature, Label pair\n","n’t create a future! If you don’t like your destiny, don’t accept it. When you give up, that’s when \n","t\n"]}]},{"cell_type":"code","source":["# Apply the split_sequence function to the dataset\n","feature_label_data = sequences_as_tf_data.map(split_sequence)\n","\n","for feature, label in feature_label_data.take(1):\n","  print(feature)\n","  print(label)\n","  "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LhXuP72tobJn","executionInfo":{"status":"ok","timestamp":1660854324170,"user_tz":-60,"elapsed":263,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"8292f124-9188-4fe8-b50a-184d1575ca93"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[33 19 46 15 54 19 36 60 58 54  8  1 19 60 58  6 46  3 36 25 58 19  3  6\n"," 58 32 20 19  3 58 25 20 19 29 58  6  8 19 23 58  8 25 58 19  3  6 60 58\n"," 32 20 19  3 58 25 20 19 29 58 54 46 60 19 58 21 39  8 25 20 41 58 22 21\n"," 58 29 46 59 58  6 46  3 36 25 58 25 39 34 19 58 31  8 60 34 60 23 58 29\n"," 46 59 58 26], shape=(100,), dtype=int32)\n","tf.Tensor(39, shape=(), dtype=int32)\n"]}]},{"cell_type":"code","source":["# create a batched_dataset to train the model on\n","batched_dataset = (feature_label_data.batch(1))"],"metadata":{"id":"2t5ThNteoeNA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = Anime_qoutes_model_2.fit(batched_dataset, epochs=15,\n","                                 callbacks=[model_checkpoint_callback, early_stopping_callback])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MxSP2Do1mO0Q","executionInfo":{"status":"ok","timestamp":1660856420847,"user_tz":-60,"elapsed":2035760,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"e39c6d76-7b8d-437f-f95d-11259b8ccac1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/15\n","123/123 [==============================] - ETA: 0s - loss: 3.4342 - sparse_categorical_accuracy: 0.0976"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f0cbf61dd10> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f0cce30c650> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 96s 749ms/step - loss: 3.4342 - sparse_categorical_accuracy: 0.0976\n","Epoch 2/15\n","123/123 [==============================] - ETA: 0s - loss: 2.9345 - sparse_categorical_accuracy: 0.1789"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f0cbf61dd10> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f0cce30c650> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 92s 747ms/step - loss: 2.9345 - sparse_categorical_accuracy: 0.1789\n","Epoch 3/15\n","123/123 [==============================] - ETA: 0s - loss: 2.8366 - sparse_categorical_accuracy: 0.1789"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f0cbf61dd10> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f0cce30c650> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 90s 728ms/step - loss: 2.8366 - sparse_categorical_accuracy: 0.1789\n","Epoch 4/15\n","123/123 [==============================] - ETA: 0s - loss: 2.6637 - sparse_categorical_accuracy: 0.1951"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f0cbf61dd10> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f0cce30c650> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 92s 745ms/step - loss: 2.6637 - sparse_categorical_accuracy: 0.1951\n","Epoch 5/15\n","123/123 [==============================] - ETA: 0s - loss: 2.3883 - sparse_categorical_accuracy: 0.2846"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f0cbf61dd10> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f0cce30c650> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 91s 743ms/step - loss: 2.3883 - sparse_categorical_accuracy: 0.2846\n","Epoch 6/15\n","123/123 [==============================] - ETA: 0s - loss: 2.1118 - sparse_categorical_accuracy: 0.3902"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f0cbf61dd10> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f0cce30c650> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 91s 740ms/step - loss: 2.1118 - sparse_categorical_accuracy: 0.3902\n","Epoch 7/15\n","123/123 [==============================] - ETA: 0s - loss: 1.8650 - sparse_categorical_accuracy: 0.3984"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f0cbf61dd10> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f0cce30c650> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 90s 734ms/step - loss: 1.8650 - sparse_categorical_accuracy: 0.3984\n","Epoch 8/15\n","123/123 [==============================] - ETA: 0s - loss: 1.6138 - sparse_categorical_accuracy: 0.4715"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f0cbf61dd10> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f0cce30c650> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 92s 746ms/step - loss: 1.6138 - sparse_categorical_accuracy: 0.4715\n","Epoch 9/15\n","123/123 [==============================] - ETA: 0s - loss: 1.3277 - sparse_categorical_accuracy: 0.5854"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f0cbf61dd10> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f0cce30c650> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 92s 748ms/step - loss: 1.3277 - sparse_categorical_accuracy: 0.5854\n","Epoch 10/15\n","123/123 [==============================] - ETA: 0s - loss: 1.0429 - sparse_categorical_accuracy: 0.6748"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f0cbf61dd10> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f0cce30c650> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 91s 736ms/step - loss: 1.0429 - sparse_categorical_accuracy: 0.6748\n","Epoch 11/15\n","123/123 [==============================] - ETA: 0s - loss: 0.8703 - sparse_categorical_accuracy: 0.6911"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f0cbf61dd10> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f0cce30c650> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 91s 741ms/step - loss: 0.8703 - sparse_categorical_accuracy: 0.6911\n","Epoch 12/15\n","123/123 [==============================] - ETA: 0s - loss: 0.6424 - sparse_categorical_accuracy: 0.8211"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f0cbf61dd10> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f0cce30c650> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 94s 761ms/step - loss: 0.6424 - sparse_categorical_accuracy: 0.8211\n","Epoch 13/15\n","123/123 [==============================] - ETA: 0s - loss: 0.4840 - sparse_categorical_accuracy: 0.8862"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f0cbf61dd10> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f0cce30c650> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 95s 777ms/step - loss: 0.4840 - sparse_categorical_accuracy: 0.8862\n","Epoch 14/15\n","123/123 [==============================] - ETA: 0s - loss: 0.4090 - sparse_categorical_accuracy: 0.8780"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f0cbf61dd10> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f0cce30c650> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 99s 809ms/step - loss: 0.4090 - sparse_categorical_accuracy: 0.8780\n","Epoch 15/15\n","123/123 [==============================] - ETA: 0s - loss: 0.3002 - sparse_categorical_accuracy: 0.9431"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f0cbf61dd10> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f0cce30c650> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/123 [==============================] - 91s 744ms/step - loss: 0.3002 - sparse_categorical_accuracy: 0.9431\n"]}]},{"cell_type":"markdown","source":["Try out this model"],"metadata":{"id":"J7Ozzx4lu_HI"}},{"cell_type":"code","source":["# if you know, you know\n","Seed_word = \"I feel like anything is possible now. I can keep fighting a bit longer. My heartbeat sounds funny. This is my peak, this is gear fifth\"\n","Seed_word_id = []\n","for char in Seed_word:\n","  id = char_to_token[char]\n","  Seed_word_id.append(id)\n","\n","print(Seed_word)\n","print(Seed_word_id)\n","print(len(Seed_word_id))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Valvaeczvdu6","executionInfo":{"status":"ok","timestamp":1660856429707,"user_tz":-60,"elapsed":257,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"57c3652c-3c1b-4795-e0da-91f12b1b3426"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["I feel like anything is possible now. I can keep fighting a bit longer. My heartbeat sounds funny. This is my peak, this is gear fifth\n","[22, 58, 21, 19, 19, 54, 58, 54, 8, 34, 19, 58, 39, 3, 29, 25, 20, 8, 3, 47, 58, 8, 60, 58, 15, 46, 60, 60, 8, 2, 54, 19, 58, 3, 46, 32, 41, 58, 22, 58, 26, 39, 3, 58, 34, 19, 19, 15, 58, 21, 8, 47, 20, 25, 8, 3, 47, 58, 39, 58, 2, 8, 25, 58, 54, 46, 3, 47, 19, 31, 41, 58, 28, 29, 58, 20, 19, 39, 31, 25, 2, 19, 39, 25, 58, 60, 46, 59, 3, 6, 60, 58, 21, 59, 3, 3, 29, 41, 58, 11, 20, 8, 60, 58, 8, 60, 58, 16, 29, 58, 15, 19, 39, 34, 23, 58, 25, 20, 8, 60, 58, 8, 60, 58, 47, 19, 39, 31, 58, 21, 8, 21, 25, 20]\n","134\n"]}]},{"cell_type":"code","source":["for i in range(100):\n","  # get the model prediction\n","  prediction = Anime_qoutes_model_2.predict([Seed_word_id])\n","  # print(prediction.shape)\n","\n","  # use the final prediction\n","  final_prediction_distribution = prediction[0][-1]\n","  predicted_char_id = np.argmax(final_prediction_distribution)\n","  predicted_char = token_to_char[predicted_char_id]\n","  # print(f\"predicted_char_id: {predicted_char_id}\")\n","  # print(f\"predicted_char: {predicted_char}\")\n","  \n","  Seed_word_id.append(predicted_char_id)\n"],"metadata":{"id":"Y9947er9v03Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Initial seed text: \", Seed_word)\n","list_of_generated_char = [token_to_char[token] for token in Seed_word_id]\n","generated_text = \"\".join(list_of_generated_char)\n","print(generated_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-6LLyCs4wglx","executionInfo":{"status":"ok","timestamp":1660856590475,"user_tz":-60,"elapsed":467,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"f8730d48-f388-456b-c050-626c11be0d5e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Initial seed text:  I feel like anything is possible now. I can keep fighting a bit longer. My heartbeat sounds funny. This is my peak, this is gear fifth\n","I feel like anything is possible now. I can keep fighting a bit longer. My heartbeat sounds funny. This is my peak, this is gear fifthKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK\n"]}]},{"cell_type":"markdown","source":["I've had a look at the Text generation code using RNN and the Udacity notebook on text generation.\n","\n","One thing i could try to do to resolve the repeated block of text generated is to randomly select the next char from the categorical distribution. To avoid making this notebook to big, i'll attempt this in a different notebook."],"metadata":{"id":"7j5eghV1u-3X"}}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["WdSvTrv9oo-3","sKSlbYTX1C1B"],"name":"Text Generation 3rd Attempt.ipynb","provenance":[],"mount_file_id":"1mWNZkI4Vstz1JogsTVGbWa8f4KG3WqGT","authorship_tag":"ABX9TyONAISh+jn9SGf7fqPOrcDe"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}