{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Text Generation using RNN.ipynb","provenance":[],"authorship_tag":"ABX9TyPvLkb0jsHvxvMR+FDFznuU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# **Text generation with an RNN**\n","\n","following [tensorflow tutorial](https://www.tensorflow.org/text/tutorials/text_generation).\n","\n","This tutorial looks at training an RNN model to predict the next character in a sequence. The model is trained on text written by shakespeare.\n","\n","Something to keep in mind. Text generation process demonstrated in Udacity.\n","- Tokenization, followed by converting the texts to sequences.\n","\n","- With each sequences having a set length. From each sequences, we use the last token as the label and the remaining sequences as the feature vector.\n","\n","- Convert the labels into one-hot vectors, with it's length being the vocabulary size\n","\n","- Train a classification model on the sequences and one-hot labels.\n","\n","- We would then generate text by providing a seed word followed by multiple inference.\n"],"metadata":{"id":"fhLXjY4bLaue"}},{"cell_type":"markdown","source":["##**Import dependencies**"],"metadata":{"id":"yiHsY9gYoTKL"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"rFLuAWMjJUjE","executionInfo":{"status":"ok","timestamp":1659881361977,"user_tz":-60,"elapsed":3880,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}}},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","import os\n","import time\n","\n","print(tf.__version__)"]},{"cell_type":"markdown","source":["## **Get the dataset**"],"metadata":{"id":"Zm98stqCodZr"}},{"cell_type":"code","source":["path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-cLRkrGcohJ4","executionInfo":{"status":"ok","timestamp":1659881466090,"user_tz":-60,"elapsed":373,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"9eb199c4-e89d-45a6-cad4-559379226de0"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n","1122304/1115394 [==============================] - 0s 0us/step\n","1130496/1115394 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["# decode the text\n","text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n","print(text)"],"metadata":{"id":"iCBWlJCppUpm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"Number of characters in the text: {len(text)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hZgnWxdKpsi3","executionInfo":{"status":"ok","timestamp":1659881602873,"user_tz":-60,"elapsed":396,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"4c750c0a-f499-4e9d-f411-c8405d90c842"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of characters in the text: 1115394\n"]}]},{"cell_type":"markdown","source":["ðŸ˜… This is so much more efficient way to get the text, compared to what i did. In fairness i removed the names of the person saying each line of dialog from the text"],"metadata":{"id":"cqGp1-yxp07P"}},{"cell_type":"code","source":["# find the number of unique characters in the file\n","vocab = sorted(set(text))\n","print(vocab)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fHTHgiL5p0bX","executionInfo":{"status":"ok","timestamp":1659881866288,"user_tz":-60,"elapsed":380,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"cfd8919c-779c-4c65-a91c-322e5abdd0df"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"]}]},{"cell_type":"code","source":["print(f\"Number of unique charachter in the text is {len(vocab)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AwLD6BSUq1pf","executionInfo":{"status":"ok","timestamp":1659881877524,"user_tz":-60,"elapsed":401,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"c8bad1f4-5d18-45da-9967-0077877c2e58"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of unique charachter in the text is 65\n"]}]},{"cell_type":"markdown","source":["Where does $ come up in the text?"],"metadata":{"id":"z1e8jUpdrFhv"}},{"cell_type":"markdown","source":["## **Process the text**"],"metadata":{"id":"CC4g2LEArRQG"}},{"cell_type":"code","source":["# encode sample string into utf-8 format\n","example_texts = [\"megasxlr\", \"theweekend\"]\n","\n","example_text_chars = tf.strings.unicode_split(example_texts, input_encoding=\"UTF-8\")\n","print(example_text_chars)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sOUDLS05rL8E","executionInfo":{"status":"ok","timestamp":1659882889263,"user_tz":-60,"elapsed":626,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"d847991e-8fdb-4631-a58e-703ef834c8d8"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["<tf.RaggedTensor [[b'm', b'e', b'g', b'a', b's', b'x', b'l', b'r'],\n"," [b't', b'h', b'e', b'w', b'e', b'e', b'k', b'e', b'n', b'd']]>\n"]}]},{"cell_type":"code","source":["for index, char_ in enumerate(list(vocab)):\n","  print(f\"index:{index}, character:{char_}\")"],"metadata":{"id":"6P8FD7DZu1y6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Define a text encoder**"],"metadata":{"id":"0ZScqz5b6ig4"}},{"cell_type":"code","source":["# create an encoder to convert the string into token\n","ids_from_chars = tf.keras.layers.StringLookup(vocabulary=list(vocab),\n","                                              mask_token=None)\n"],"metadata":{"id":"6WiHkOyduR_d","executionInfo":{"status":"ok","timestamp":1659882861040,"user_tz":-60,"elapsed":446,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["ids = ids_from_chars(example_text_chars)\n","print(ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_30JjnATunoN","executionInfo":{"status":"ok","timestamp":1659882904700,"user_tz":-60,"elapsed":349,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"a6357dfd-bd58-436e-a384-53183ac3fcb6"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["<tf.RaggedTensor [[52, 44, 46, 40, 58, 63, 51, 57],\n"," [59, 47, 44, 62, 44, 44, 50, 44, 53, 43]]>\n"]}]},{"cell_type":"markdown","source":["it seems like it's encoded the text using the index from the initial vocab (with a slight offset)."],"metadata":{"id":"y1G0bLX0valy"}},{"cell_type":"markdown","source":["**Define a text decoder**"],"metadata":{"id":"jrHsi_oS6bm0"}},{"cell_type":"code","source":["# create a text decoder\n","chars_from_ids = tf.keras.layers.StringLookup(vocabulary=ids_from_chars.get_vocabulary(),\n","                                              invert=True,\n","                                              mask_token=None)\n"],"metadata":{"id":"57bIaqxouwDx","executionInfo":{"status":"ok","timestamp":1659883244524,"user_tz":-60,"elapsed":506,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["decoded_chars = chars_from_ids(ids)\n","print(decoded_chars)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TDYqSrLOwGXt","executionInfo":{"status":"ok","timestamp":1659883363620,"user_tz":-60,"elapsed":10,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"9e03f434-b514-4e62-d261-aba4479e72ed"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["<tf.RaggedTensor [[b'm', b'e', b'g', b'a', b's', b'x', b'l', b'r'],\n"," [b't', b'h', b'e', b'w', b'e', b'e', b'k', b'e', b'n', b'd']]>\n"]}]},{"cell_type":"code","source":["# the decoded chars are returns as list of char. We can join the individual\n","# chars back into a string\n","tf.strings.reduce_join(decoded_chars, axis=-1).numpy()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sScbJxSDwf3G","executionInfo":{"status":"ok","timestamp":1659883528741,"user_tz":-60,"elapsed":12,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"7bc57a90-7f8e-4685-b659-0199399a7434"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([b'megasxlr', b'theweekend'], dtype=object)"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["print(decoded_chars)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Nfo5imlxFIG","executionInfo":{"status":"ok","timestamp":1659883533011,"user_tz":-60,"elapsed":600,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"d843d188-c8bd-4950-a1c5-879a995a158c"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["<tf.RaggedTensor [[b'm', b'e', b'g', b'a', b's', b'x', b'l', b'r'],\n"," [b't', b'h', b'e', b'w', b'e', b'e', b'k', b'e', b'n', b'd']]>\n"]}]},{"cell_type":"code","source":["def text_from_ids(ids):\n","  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"],"metadata":{"id":"GOzuCYOC06z0","executionInfo":{"status":"ok","timestamp":1659886032689,"user_tz":-60,"elapsed":427,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}}},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":["The trained model would be able to predict the next probable character given an initial characther or sequence of characther.\n","\n","Towards this\n","- our training dataset needs to contain text where the input contain parts of the text and label contains the remaining parts of it.\n","- Example: Input: Megas, Label: Megasx\n"],"metadata":{"id":"ZrgT2gB9yRhm"}},{"cell_type":"code","source":["# convert the individual text in the dialog into chars\n","text_split_into_individual_chars = tf.strings.unicode_split(text, 'UTF-8')\n","print(text_split_into_individual_chars)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X9qwEvGD0wpy","executionInfo":{"status":"ok","timestamp":1659884911715,"user_tz":-60,"elapsed":1661,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"649a5374-1871-4979-fde3-6df4d14fb189"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor([b'F' b'i' b'r' ... b'g' b'.' b'\\n'], shape=(1115394,), dtype=string)\n"]}]},{"cell_type":"code","source":["# convert each characthers into tokens\n","text_ids = ids_from_chars(text_split_into_individual_chars)\n","print(text_ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QBE2QR0n2bCJ","executionInfo":{"status":"ok","timestamp":1659884974440,"user_tz":-60,"elapsed":626,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"96beda7d-7423-4559-f0e5-88d77de16f4c"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor([19 48 57 ... 46  9  1], shape=(1115394,), dtype=int64)\n"]}]},{"cell_type":"code","source":["ids_dataset = tf.data.Dataset.from_tensor_slices(text_ids)\n","print(ids_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IOyGyPYm2uXQ","executionInfo":{"status":"ok","timestamp":1659885112420,"user_tz":-60,"elapsed":17,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"d6e434d6-1d8a-4021-ecff-cc163b50c22b"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["<TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>\n"]}]},{"cell_type":"code","source":["for ids in ids_dataset.take(10):\n","  print(chars_from_ids(ids).numpy().decode('utf-8'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9WhOEPJO3PKS","executionInfo":{"status":"ok","timestamp":1659885170788,"user_tz":-60,"elapsed":402,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"e0c05802-34eb-4dd6-9f9c-aa0b61a0db04"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["F\n","i\n","r\n","s\n","t\n"," \n","C\n","i\n","t\n","i\n"]}]},{"cell_type":"code","source":["# define the max_length of the sequences\n","seq_length = 100\n"],"metadata":{"id":"SbOSc8Zf3e5k","executionInfo":{"status":"ok","timestamp":1659885221119,"user_tz":-60,"elapsed":401,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["# from the dataset generate a batch with a length of 101\n","sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n","\n","# display a single batch\n","for seq in sequences.take(5):\n","  print(text_from_ids(seq).numpy())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rIdQDdyS3oev","executionInfo":{"status":"ok","timestamp":1659886077403,"user_tz":-60,"elapsed":430,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"139e37db-9f0c-4f7c-d472-a8cb38a63c4f"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n","b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n","b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n","b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n","b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"]}]},{"cell_type":"code","source":["# define a function to split a sequence into a feature vector and a label\n","def split_input_target(sequence):\n","  input_text = sequence[:-1]\n","  target_text = sequence[1:]\n","  return input_text, target_text\n","\n","# example\n","split_input_target(list(\"Megasxlr\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"soe7AwwQ7FLe","executionInfo":{"status":"ok","timestamp":1659886329432,"user_tz":-60,"elapsed":708,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"0d4b1a26-b0a3-44bf-ebbf-054bf3c2968f"},"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(['M', 'e', 'g', 'a', 's', 'x', 'l'], ['e', 'g', 'a', 's', 'x', 'l', 'r'])"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["# Apply the function into the batched sequence\n","dataset = sequences.map(split_input_target)\n","print(dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CMpmNnZ9748I","executionInfo":{"status":"ok","timestamp":1659886550860,"user_tz":-60,"elapsed":580,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"64eea764-30cc-4edd-b592-18be8fc23873"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["<MapDataset element_spec=(TensorSpec(shape=(100,), dtype=tf.int64, name=None), TensorSpec(shape=(100,), dtype=tf.int64, name=None))>\n"]}]},{"cell_type":"code","source":["for input_example, target_example in dataset.take(1):\n","  print(f\"input: {text_from_ids(input_example).numpy()}\")\n","  print(f\"label: {text_from_ids(target_example).numpy()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"50YXB4v78srF","executionInfo":{"status":"ok","timestamp":1659886636077,"user_tz":-60,"elapsed":274,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"7c621226-68bf-4b9c-9b88-0a1bc23c3390"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["input: b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n","label: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"]}]},{"cell_type":"markdown","source":["wow, the feature and label are not so different."],"metadata":{"id":"dxiVm1ZI9EhL"}},{"cell_type":"markdown","source":["**Create training batches from the mapped dataset**"],"metadata":{"id":"kHBywQH2-W6-"}},{"cell_type":"code","source":["BATCH_SIZE = 64\n","BUFFER_SIZE = 10000\n","\n","dataset = (dataset\n","           .shuffle(BUFFER_SIZE)\n","           .batch(BATCH_SIZE, drop_remainder=True)\n","           .prefetch(tf.data.experimental.AUTOTUNE))\n","\n","dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZPlvqMx3-Wa2","executionInfo":{"status":"ok","timestamp":1659887247737,"user_tz":-60,"elapsed":460,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"00148adf-e750-4a07-af42-cadf6ef2d2dd"},"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"]},"metadata":{},"execution_count":56}]},{"cell_type":"markdown","source":["Summary of text processing pipeline and generating feature and labels\n","1. Split the text into individual chars\n","2. Convert the individual chars into tokens\n","3. From the list of tokens generate a batch containing sequences of 101 tokens.\n","4. Split each batch into a feature vector and label\n","  - feature is the batch sequence excluding the last char\n","  - label is the batch sequence excluding the first char\n","5. Generate a new dataset containing batchs of 64 samples (feature vectors and labels)"],"metadata":{"id":"PVvfgQOw_kET"}},{"cell_type":"markdown","source":["## **Define the text generation model**"],"metadata":{"id":"hLunlV1UBj5P"}},{"cell_type":"code","source":["# define the model parameters\n","vocab_size = len(ids_from_chars.get_vocabulary())\n","print(vocab_size)\n","\n","embedding_dim = 256\n","rnn_units = 1024"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cYzker-iBngu","executionInfo":{"status":"ok","timestamp":1659889056414,"user_tz":-60,"elapsed":373,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"19980b2f-6672-4d4a-e7a6-6344d2cff730"},"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["66\n"]}]},{"cell_type":"code","source":["# define the model\n","class MyModel(tf.keras.Model):\n","\n","  # define class constructor to initialise the layers with the parameters\n","  def __init__(self, vocab_size, embedding_dim, rnn_units):\n","    super().__init__(self)\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","    self.gru = tf.keras.layers.GRU(rnn_units, return_sequences=True,\n","                                   return_state=True)\n","    self.dense = tf.keras.layers.Dense(vocab_size)\n","  \n","\n","  # What are the requirement for defining sub class models derived from the Model class\n","  def call(self, inputs, states=None, return_state=False, training=False):\n","    x = inputs\n","\n","    # pass input to the embedding layer\n","    x = self.embedding(x, training=training)\n","\n","    # set initial state if provided,\n","    if states is None:\n","      states = self.gru.get_initial_state(x)\n","    \n","    # call the GRU layer with the embedding, initial state and training\n","    # what is training?\n","    x, states = self.gru(x, initial_state=states, training=training)\n","\n","    # Call the dense layer with the output of the GRU layer\n","    x = self.dense(x, training=training)\n","\n","    # dense output and state if specified.\n","    if return_state:\n","      return x, states\n","    else:\n","      return x\n","     "],"metadata":{"id":"wu5mB0FzB-Mg","executionInfo":{"status":"ok","timestamp":1659888940931,"user_tz":-60,"elapsed":298,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}}},"execution_count":59,"outputs":[]},{"cell_type":"code","source":["# define an instance of the model\n","model = MyModel(vocab_size, embedding_dim, rnn_units)"],"metadata":{"id":"PoCTLoy0FfV2","executionInfo":{"status":"ok","timestamp":1659889058675,"user_tz":-60,"elapsed":313,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}}},"execution_count":64,"outputs":[]},{"cell_type":"markdown","source":["try the model on a single sample from the dataset"],"metadata":{"id":"UPyzw67KHnKE"}},{"cell_type":"code","source":["for batch_feature_vector, batch_label in dataset.take(1):\n","  example_batch_predictions = model(batch_feature_vector)\n","  print(example_batch_predictions)\n","  print(example_batch_predictions.shape, \"(batch size, sequence_length, vocab_size)\")"],"metadata":{"id":"SMYx7X3PHfVn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The next probable word would be determined from the output distribution produced by the dense layer."],"metadata":{"id":"mggq1npdJWBM"}},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_WCtAEcTHwFi","executionInfo":{"status":"ok","timestamp":1659889709355,"user_tz":-60,"elapsed":321,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"29121d76-0944-49df-8b9b-f9b301dfaa4a"},"execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"my_model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       multiple                  16896     \n","                                                                 \n"," gru (GRU)                   multiple                  3938304   \n","                                                                 \n"," dense (Dense)               multiple                  67650     \n","                                                                 \n","=================================================================\n","Total params: 4,022,850\n","Trainable params: 4,022,850\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["print(example_batch_predictions[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Be60bPq-JjJm","executionInfo":{"status":"ok","timestamp":1659890166599,"user_tz":-60,"elapsed":298,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"d44a351b-e689-42bf-b38f-476a05d60273"},"execution_count":73,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[[ 0.00562176 -0.00374314 -0.01639711 ... -0.00193836  0.00166717\n","  -0.00250686]\n"," [-0.00671655 -0.0107293  -0.00898772 ... -0.00578413  0.00860768\n","   0.00137541]\n"," [-0.01193155 -0.00204952 -0.01788967 ... -0.00425291  0.00959354\n","  -0.0027385 ]\n"," ...\n"," [-0.01239498 -0.00092952  0.00505774 ... -0.01444685 -0.01578278\n","  -0.00837081]\n"," [-0.0053544   0.00378801 -0.00509801 ... -0.01159768  0.00221087\n","   0.00558506]\n"," [ 0.00099461 -0.00201884 -0.00211347 ... -0.00576868 -0.00381639\n","  -0.00275322]], shape=(100, 66), dtype=float32)\n"]}]},{"cell_type":"code","source":["sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n","print(sampled_indices)"],"metadata":{"id":"-2zeVRgFKicE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n","print(sampled_indices)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lqlwq1LpKzdL","executionInfo":{"status":"ok","timestamp":1659890385101,"user_tz":-60,"elapsed":291,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"fc104b8d-99f6-44fb-9f40-27ec5710ab72"},"execution_count":76,"outputs":[{"output_type":"stream","name":"stdout","text":["[14 34 17 27 20  5  9 55 50 30 15 31 15 21 64 55 31 33 32 48 35 64 38 32\n"," 40 11 37 35 49  8 23 17 39 23  3 47 22 21 37  2 33 42 53 20 42 46 58 44\n"," 29 26 58 50 12 63 22 17 19 56 63 11 10 36 34  5  3 11 62 30 21 53 29 51\n"," 48 17 64 31 58 33 58 42  3 47 51 61 48 38 56 25 18  2 22 64 19 29 32 34\n"," 30 34 39 55]\n"]}]},{"cell_type":"code","source":["# display the input and model prediction\n","print(\"Input:\\n\", text_from_ids(batch_feature_vector[0]).numpy())\n","print(\"Expected label: \\n\", text_from_ids(batch_label[0]).numpy())\n","print(\"Predicted label: \\n\", text_from_ids(sampled_indices).numpy())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mlt04gztLcqt","executionInfo":{"status":"ok","timestamp":1659890675299,"user_tz":-60,"elapsed":282,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"fbb238f0-2bfc-43dc-fa66-da9b99f537f2"},"execution_count":78,"outputs":[{"output_type":"stream","name":"stdout","text":["Input:\n"," b'. For the dearth,\\nThe gods, not the patricians, make it, and\\nYour knees to them, not arms, must help'\n","Expected label: \n"," b' For the dearth,\\nThe gods, not the patricians, make it, and\\nYour knees to them, not arms, must help.'\n","Predicted label: \n"," b'AUDNG&.pkQBRBHypRTSiVyYSa:XVj-JDZJ!hIHX TcnGcgsePMsk;xIDFqx:3WU&!:wQHnPliDyRsTsc!hlviYqLE IyFPSUQUZp'\n"]}]},{"cell_type":"markdown","source":["## **Train the model**"],"metadata":{"id":"CE0j4P1sMim4"}},{"cell_type":"code","source":["# define a loss function for the model\n","loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n","\n","# get the loss for the first batch in the dataset\n","example_batch_mean_loss = loss(batch_label, example_batch_predictions)\n","print(f\"Prediction shape: {example_batch_predictions.shape}\")\n","print(f\"Mean loss: {example_batch_mean_loss}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AoezGOm6MqA3","executionInfo":{"status":"ok","timestamp":1659891225522,"user_tz":-60,"elapsed":788,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"9ddbd6a1-d710-4617-c9d5-9ff981a20b72"},"execution_count":82,"outputs":[{"output_type":"stream","name":"stdout","text":["Prediction shape: (64, 100, 66)\n","Mean loss: 4.191046237945557\n"]}]},{"cell_type":"code","source":["tf.exp(example_batch_mean_loss).numpy()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A8fafNGJOhqB","executionInfo":{"status":"ok","timestamp":1659891277726,"user_tz":-60,"elapsed":267,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"52c2477e-4d3d-42ee-9433-1eb6016a5216"},"execution_count":83,"outputs":[{"output_type":"execute_result","data":{"text/plain":["66.0919"]},"metadata":{},"execution_count":83}]},{"cell_type":"markdown","source":["I'm not too sure about this, but \n","- *The exponential of the mean loss should be approximately equal to the vocabulary size*. As the output logits from the dense layer should have similar magnitudes."],"metadata":{"id":"SRRYc7RlPGho"}},{"cell_type":"code","source":["# define the loss and optimizer for the model\n","model.compile(optimizer='adam', loss=loss)\n"],"metadata":{"id":"YR4tMxeqO4oH","executionInfo":{"status":"ok","timestamp":1659891613602,"user_tz":-60,"elapsed":391,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}}},"execution_count":84,"outputs":[]},{"cell_type":"markdown","source":["**Define model callbacks**\n","\n","ModelCheckpoint\n","- Saves model/ weightd at a defined frequency. (So it saves the model or it's weight at different point during training)"],"metadata":{"id":"Fki_zjlDPoql"}},{"cell_type":"code","source":["# define a directory to store checkoints of the model during training\n","checkpoint_dir = \"./training_checkpoints\"\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n","\n","# define the model checkpoint\n","# Saves the model weight at the end of each epoch to the training_checkpoints dir\n","checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n","                                                         save_weights_only=True)\n"],"metadata":{"id":"aCCPru2nPmMv","executionInfo":{"status":"ok","timestamp":1659892113840,"user_tz":-60,"elapsed":307,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}}},"execution_count":85,"outputs":[]},{"cell_type":"code","source":["# Define the training epochs \n","EPOCHS = 20"],"metadata":{"id":"LNu4wQI5R5ZV","executionInfo":{"status":"ok","timestamp":1659892137664,"user_tz":-60,"elapsed":286,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}}},"execution_count":86,"outputs":[]},{"cell_type":"code","source":["history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ykwqoDcwR_gG","executionInfo":{"status":"ok","timestamp":1659892492184,"user_tz":-60,"elapsed":321635,"user":{"displayName":"Kayode Sonaike","userId":"14696411076652260026"}},"outputId":"522b5c34-e320-4b58-eda2-2744aa3e4593"},"execution_count":87,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","172/172 [==============================] - 15s 53ms/step - loss: 2.7108\n","Epoch 2/20\n","172/172 [==============================] - 12s 54ms/step - loss: 1.9882\n","Epoch 3/20\n","172/172 [==============================] - 12s 53ms/step - loss: 1.7158\n","Epoch 4/20\n","172/172 [==============================] - 12s 55ms/step - loss: 1.5574\n","Epoch 5/20\n","172/172 [==============================] - 12s 55ms/step - loss: 1.4593\n","Epoch 6/20\n","172/172 [==============================] - 12s 55ms/step - loss: 1.3906\n","Epoch 7/20\n","172/172 [==============================] - 12s 56ms/step - loss: 1.3388\n","Epoch 8/20\n","172/172 [==============================] - 12s 56ms/step - loss: 1.2941\n","Epoch 9/20\n","172/172 [==============================] - 12s 57ms/step - loss: 1.2540\n","Epoch 10/20\n","172/172 [==============================] - 12s 56ms/step - loss: 1.2154\n","Epoch 11/20\n","172/172 [==============================] - 12s 57ms/step - loss: 1.1778\n","Epoch 12/20\n","172/172 [==============================] - 12s 57ms/step - loss: 1.1362\n","Epoch 13/20\n","172/172 [==============================] - 12s 57ms/step - loss: 1.0952\n","Epoch 14/20\n","172/172 [==============================] - 13s 58ms/step - loss: 1.0518\n","Epoch 15/20\n","172/172 [==============================] - 12s 58ms/step - loss: 1.0054\n","Epoch 16/20\n","172/172 [==============================] - 13s 57ms/step - loss: 0.9555\n","Epoch 17/20\n","172/172 [==============================] - 12s 56ms/step - loss: 0.9064\n","Epoch 18/20\n","172/172 [==============================] - 12s 57ms/step - loss: 0.8537\n","Epoch 19/20\n","172/172 [==============================] - 13s 58ms/step - loss: 0.8026\n","Epoch 20/20\n","172/172 [==============================] - 12s 58ms/step - loss: 0.7526\n"]}]},{"cell_type":"markdown","source":["## **Generating Text**\n","\n","In generating text, we would provide a seed character and then run inference to predict the next probable characther, running this multiple times would allow us to generate larger pieces of text."],"metadata":{"id":"f2Vk2rqHT-6C"}},{"cell_type":"code","source":["class OneStep(tf.keras.Model):\n","  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n","    super().__init__()\n","    self.temperature = temperature\n","    self.model = model\n","    self.chars_fro"],"metadata":{"id":"fIRADR6nT9vH"},"execution_count":null,"outputs":[]}]}